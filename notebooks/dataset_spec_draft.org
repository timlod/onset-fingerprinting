#+TITLE: Percussive onset sound dataset specification draft
#+AUTHOR: Tim Loderhose
#+EMAIL: tim@loderhose.com
#+DATE: Friday, 23 June 2023
#+STARTUP: showall
:PROPERTIES:
OPTIONS: ^:nil
#+LATEX_COMPILER: xelatex
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [logo, color, author]
#+LATEX_HEADER: \insertauthor
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry}
:END:

* TODO
Should we restrict the specification to be about percussive onsets? One might
be able to use exactly the same specification to define datasets to classify
onsets of other instruments, e.g. piano or guitar.

* Goal

Create a specification that can be used to define datasets useful in MIR.

A dataset following the percussive onset sound dataset (POSD) specification can
be used to develop and rigorously evaluate state-of-the-art drum/percussion
onset/transient sound fingerprinting and classification algorithms.

Additionally, other types of tasks could conceivable learned using this type of
dataset (in the context of drums/percussion):
- onset detection
- drum expression/articulation classification
  - similar task as onset sound classification, but using more audio samples
    (larger context window)

POSD should be adaptable to different types of instruments, with common
attributes shared across a large class of instruments, and a defined structure
to add more specific atttributes.

* Audio onset fingerprinting/classification

Typical audio/sound classification involves training a model to classify a
sound as belonging to one of a number of pre-defined classes.

Onset sound fingerprinting/classification is more specific: developed
algorithms are used to accurately classify extremely short snippets of sound in
real-time, to allow the use of the classification result in live musical
performance.

In the context of the development of the Open Percussion Sensor (OP), the end
goal is the following:
#+begin_quote
Users place the sensor on a drum of interest, record a number of hits on 'zones
of interest' used to 'fingerprint' each hit zone such that classification of
hits during live performance can be performed in real-time.
#+end_quote

In this context the goal is not training a model on this dataset which users
can directly use to perform live, but rather discover a suitable processing
pipeline/set of choices which allows end users to efficiently train or
fine-tune their own, local model used in performance.

In other words, while typical machine learning (ML) development finds
parameters which allow training a model on given training data such that
performance generalizes well to a test set, in this case we try to find
parameters using one training set such that *the training procedure* will
generalize well to training a generalizable model on another (the end user's)
dataset.

* Nomenclature

Some terms that will show up several times throughout this document:

- Session :: one 'run' of training/testing data, with core elements such as
  drum/player/tuning/mic levels constant. One session contains enough
  information to fingerprint one instrument for live performance
- Hit :: striking instrument once, resulting in a single onset followed by an
  unspecified amount of samples of post-transient audio
- Channel :: audio channel, of which there will be one per measurement device
- isolated audio/data :: recordings where only the hit of interest is played,
  in isolation (no other hits played simultaneous by this or other instruments)
- in-context audio/data :: recordings of hits during natural performance, e.g.
  possibly including bleed/vibration from the entire drumkit or other
  instruments playing at the same time

* Specification

POSD is a collection of recorded percussive sound onsets. A percussive sound in
this context can be liberally defined as any sound with a clearly defined
attack, usually generated by hitting an object. An onset can refer to both the
beginning of the sound in general, as well as the exact moment in time
(relative to some origin) when we can identify that the sound has started.

Percussive sounds can characterized by a having broad frequency content,
including many high frequencies, at the note onset.

A POSD, at the most basic level, contains audio files of many note onsets,
which can be accessed by their location in the soundfile. We call individual
note onsets (including the audio directly following the onset) =hits=, and
arrange them in =sessions=, in which a large amount of metadata stays constant
across individual hits.

The specification contains a number of required attributes - when recording
these, make sure to follow the guideline directly. For optional attributes,
make sure to document clearly how data is/should be collected. For this, we
recommend a README file at the top-level of your project (.txt, .md or .org
files are recommended). This readme should make it easy to understand and parse
your additions to POSD.

** Metadata

POSD metadata consists of the =session= and =hit= levels forming a hierarchy,
and optional =instrument= metadata, which defines hitzones and auxiliary
metadata for individual instruments across sessions. In the hierarchy, a
=session= sits atop of =hits=, meaning that all descriptions about a session
can be attached to each hit contained in that session.

To allow for flexibility in the type of and manner in which an instrument is
recorded, and what metadata about that instrument is important, the POSD is
defined in such a way that additional metadata can be recorded as is needed.

POSD metadata is specified using JSON.

Do not include units for optional numerical metadata (e.g. do not record 440Hz
for an instrument tuned to A4, but rather 440), but rather document clearly
what unit each field is using!

Have a look at POSD-Drum-V1, which shows how POSD can be used to 

*** Instrument class

Instrument-level data lives out side of the session/hit hierarchy, and is not
strictly necessary, as the important bits (an instrument's hitzones) can be
implicitly derived from the instrument name in the session and hitzones used in
the hit-level data.

However, it is useful and recommended to collect this information at a global
level, to have a format to validate hit-level data against.

1. Instrument name
   - use this name in the [[*Instrument][Instrument]] section in the session metadata
   - use as JSON keys at the top level
2. =zones=: Hit zones
   - a list of all possible ways the instrument is recorded across all
     sessions, and a brief description thereof
   - names have to be the same as those specified in [[*Hit][Hit]] metadata
3. =conditions=: Hit-level conditions
   - list of possible conditions which could be present in hit-level data, as
     {"name": [possible values]} pairs
   - these are essentially categorical features which can be used to further
     split zones, if needed
4. =additional=: optional dictionary of additional instrument-level metadata
   - e.g. hit-level location data is stored as a 2D coordinate grid for
     non-circular instruments. You may want to place such information in the
     README instead (or as well).
     
**** Location data for 'round' drums
If location data is stored for hits on typical circular drums (snare, kick,
tambourine, timpani, etc.), please use a tuple of [[https://en.wikipedia.org/wiki/Polar_coordinate_system][polar coordinates]] using the
following system:
- Distance from center between 0 and 1 (0 meaning dead on center, 1 meaning on
  edge)
- Angle in degrees (0 to 360), where 0/360° are the top of the drum (from
  player's perspective), and angles increase clockwise

For example, hits toward top and bottom of a snare drum might be at (0.8, 0)
and (0.8, 180) respectively; hits towards center right/left might at (0.1, 90)
and (0.1, 270).
For a dead-center hit, the angle component does not matter - in that case, we
recommend recording 0°.

For other types of instruments, please document clearly how locations are
represented.

*** Session

Session metadata is split into technical information about the recording
session, the instrument that is played in the session, and optionally auxiliary
metadata about context in that session.

**** Recording

Required:
1. =sampling_rate= (in Hz)
2. =channels= - for each recording device/channel:
   - Name of the recording device
   Optional:
   - Additional details such as:
     - =location= of recording device around the instrument
       - you can use the coordinate system defined [[*Location data for 'round' drums][earlier]] to record sensor
         location around circular drums. Make sure to document how to record
         placement clearly, including distance to sound source
     - =pickup_pattern=: e.g. omni, cardioid, etc.

Channel names have to match the actual audio files stored as part of the
dataset.
         
**** Instrument

Required:
1. =name=: Instrument name
   - If present, has to match metadata in [[*Instrument class][Instrument class]]
   - use something informative, like 'snare' or 'kick'

Optional:
1. Additional session-level instrument metadata like the following:
   - =tuning=
   - =pitch=
   - =manufacturer=
   - =model=
   - =stick_type=, =beater_material= and similar
   - etc.

Use Hertz/Hz to record tuning or pitch, if present.

**** Context

This section is completely optional, and could record things like:
1. =player_id=: Player
   - Give an ID to each player in the dataset if multiple people recorded
     sessions
2. Musical context
   - on hits which are in-context, what context is this? This could be
     different instruments present, or similar

Think about what sort of data may aid the targeted (or other potential) machine
learning task(s).

*** Hit

Required:
1. =zone=
   - Hit zone matching those defined in [[*Instrument class][Instrument class]], if present
2. =onset_start=
   - integer index into the paired audio file
3. =velocity=
   - value between 0 and 1 (approximately) noting the strength of the hit, e.g.
     0 for the most silent possible hit, and 1 for the hardest possible hit
   - ?should we make this optional?
4. =isolated=
   - A boolean flag specifying whether the hit is isolated or in-context

Optional:
1. =location=
   - if useful/possible, think about storing the location of a hit within a
     zone, or globally around the instrument, see [[*Location data for 'round' drums][Location data for 'round'
     drums]]
2. =pitch=
   - more fine-grained pitch information (in Hz) than that recorded per
     session, useful for pitched instruments like timpani
3. Hit conditions
   - has to match those specified in [[*Instrument class][Instrument class]], if present

** TODO Example

The following is a small example detailing a simplistic POSD that contains
sessions recording snare and kick drum hits.

*** Folder structure

A POSD dataset has the following structure, with =instruments.json= present at
the top-level of the directory. Session and hit metadata need to be in the same
folder as the sound files they refer to. Nested directories are allowed to
introduce a hierarchy for ease of viewing - POSD loaders should visit all
sub-directories of a dataset to look for session data. For example, one could
create a folder for each instrument class.

#+begin_example
Dataset folder
- instruments.json
- session1.json
- session1_hits.json
- session1_SP.wav
- session1_OP.wav
- session2.json
- session2_hits.json
- session2_SP.wav
- session2_OP.wav
#+end_example

*** Instruments

~instruments.json~
#+begin_src json
{
    "snare": {
        "zones": [
            {
            "center": "Strike in the center of the drumhead"
        },
            {
            "edge": "Strike at the edge of the drumhead"
        }
        ],
        "conditions": [
            {
            "wires": [
                "on",
                "off"
            ]
        }
        ],
    },
    "kick": {
        "zones": [
            {
            "press": "Beater is not released upon striking drumhead"
        },
            {
            "release": "Beater is released immediately upon striking drumhead"
        }
        ],
        "conditions": {}
    }
}
#+end_src

*** TODO Sessions
Instead of having one session per file, we could have one large file containing
a list of all sessions. Each session should then have a name, where name +
channel + .wav should then exist somewhere in the folder structure to load.

In this example there are two sessions, one recording the snare, one the kick.
These JSON files will accompany .wav files, namely one for each channel, in the
same folder. Note: all data and metadata will share the same name. WAV files
will be post-fixed by _<channel>, where <channel> one of the channels specified
in the session metadata!

~session1.json~
#+begin_src json
{
    "sampling_rate": 96000,
    "channels": {
        "SP": {
            "location": [0.95, 0],
            "distance": 10
        },
        "OP": {
            "location": [0.95, 30],
            "distance": 8
        }
    },
    "instrument": "snare",
    "manufacturer": "sonor",
    "model": "BG SDW 2.0",
    "size": "13x5.75",    
    "head_top": "ambassador",
    "head_bottom": "ambassador_ss",
    "rim": "3f",
    "tuning": "low",
    "player": "rodrigo",
    "context": "full kit"
}
#+end_src

~session2.json~
#+begin_src json
{
    "sampling_rate": 96000,
    "channels": {
        "SP": {
            "location": [0.98, 45],
            "distance": 10
        },
        "OP": {
            "location": [0.98, 60],
            "distance": 8
        }
    },
    "instrument": "kick",
    "manufacturer": "sonor",
    "model": "SQ2",
    "size": "20x14",
    "head_front": "powerstroke-p3",
    "head_back": "ambassador-fiberskin",
    "rim": "wood",
    "player": "rodrigo",
    "context": "full kit"
}
#+end_src

*** Hits

~session1_hits.json~

Conditions are added flat to keep things simple. Note how this adds additional
data about the pitch of each hit.
#+begin_src json
[
    {
    "zone":"center",
    "onset_start":0,
    "velocity":0.0,
    "isolated":true,
    "pitch":220,
    "wires":"on"
},
    {
    "zone":"center",
    "onset_start":48000,
    "velocity":1.0,
    "isolated":true,
    "pitch":220,
    "wires":"on"
},
    {
    "zone":"edge",
    "onset_start":96000,
    "velocity":0.0,
    "isolated":true,
    "pitch":219,
    "wires":"off"
},
    {
    "zone":"edge",
    "onset_start":144000,
    "velocity":1.0,
    "isolated":true,
    "pitch":219,
    "wires":"off"
}
]
#+end_src

~session2_hits.json~
#+begin_src json
[
    {
    "zone":"press",
    "onset_start":0,
    "velocity":0.5,
    "isolated":true
},
    {
    "zone":"press",
    "onset_start":48000,
    "velocity":1.0,
    "isolated":true
},
    {
    "zone":"release",
    "onset_start":96000,
    "velocity":0.5,
    "isolated":true
},
    {
    "zone":"release",
    "onset_start":144000,
    "velocity":1.0,
    "isolated":true
}
]
#+end_src


* Conventions
POSD can refer to any dataset which adhers to the specification described in
this document. That means that anyone can create POSD datasets!

?Should we give recommendations here as to naming?

#+TITLE: Percussive onset sound dataset specification draft
#+AUTHOR: Tim Loderhose
#+EMAIL: tim@loderhose.com
#+DATE: Friday, 23 June 2023
#+STARTUP: showall
:PROPERTIES:
OPTIONS: ^:nil
#+LATEX_COMPILER: xelatex
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [logo, color, author]
#+LATEX_HEADER: \insertauthor
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry}
:END:

* TODO
Should we restrict the specification to be about percussive onsets? One might
be able to use exactly the same specification to define datasets to classify
onsets of other instruments, e.g. piano or guitar.

* Goal

Create a specification that can be used to define datasets useful in MIR.

A dataset following the percussive onset sound dataset (POSD) specification can
be used to develop and rigorously evaluate state-of-the-art drum/percussion
onset/transient sound fingerprinting and classification algorithms.

Additionally, other types of tasks could conceivable learned using this type of
dataset (in the context of drums/percussion):
- onset detection
- drum expression/articulation classification
  - similar task as onset sound classification, but using more audio samples
    (larger context window)

* Audio onset fingerprinting/classification

Typical audio/sound classification involves training a model to classify a
sound as belonging to one of a number of pre-defined classes.

Onset sound fingerprinting/classification is more specific: developed
algorithms are used to accurately classify extremely short snippets of sound in
real-time, to allow the use of the classification result in live musical
performance.

In the context of the development of the Open Percussion Sensor (OP), the end
goal is the following:
#+begin_quote
Users place the sensor on a drum of interest, record a number of hits on 'zones
of interest' used to 'fingerprint' each hit zone such that classification of
hits during live performance can be performed in real-time.
#+end_quote

In this context the goal is not training a model on this dataset which users
can directly use to perform live, but rather discover a suitable processing
pipeline/set of choices which allows end users to efficiently train or
fine-tune their own, local model used in performance.

In other words, while typical machine learning (ML) development finds
parameters which allow training a model on given training data such that
performance generalizes well to a test set, in this case we try to find
parameters using one training set such that *the training procedure* will
generalize well to training a generalizable model on another (the end user's)
dataset.

* Nomenclature

Some terms that will show up several times throughout this document:

- Session :: one 'run' of training/testing data, with core elements such as
  drum/player/tuning/mic levels constant. One session contains enough
  information to fingerprint one instrument for live performance
- Hit :: striking instrument once, resulting in a single onset followed by an
  unspecified amount of samples of post-transient audio
- Channel :: audio channel, of which there will be one per measurement device
- isolated audio/data :: recordings where only the hit of interest is played,
  in isolation (no other hits played simultaneous by this or other instruments)
- in-context audio/data :: recordings of hits during natural performance, e.g.
  possibly including bleed/vibration from the entire drumkit or other
  instruments playing at the same time

* Specification

POSD is a collection of recorded percussive sound onsets. A percussive sound in
this context can be liberally defined as any sound with a clearly defined
attack, usually generated by hitting an object. An onset can refer to both the
beginning of the sound in general, as well as the exact moment in time
(relative to some origin) when we can identify that the sound has started.

Percussive sounds can characterized by a having broad frequency content,
including many high frequencies, at the note onset.

A POSD, at the most basic level, contains audio files of many note onsets,
which can be accessed by their location in the soundfile. We call individual
note onsets (including the audio directly following the onset) =hits=, and
arrange them in =sessions=, in which a large amount of metadata stays constant
across individual hits.

** Metadata

POSD metadata consists of the =session= and =hit= levels forming a hierarchy,
and optional =instrument= metadata, which defines hitzones and auxiliary
metadata for individual instruments across sessions. In the hierarchy, a
=session= sits atop of =hits=, meaning that all descriptions about a session
can be attached to each hit contained in that session.

To allow for flexibility in the type of and manner in which an instrument is
recorded, and what metadata about that instrument is important, the POSD is
defined in such a way that additional metadata can be recorded as is needed.

POSD metadata is specified using JSON.

Have a look at POSD-Drum-V1, which shows how POSD can be used to 

*** Instruments (Instrument class?)

Instrument-level data lives out side of the session/hit hierarchy, and is not
strictly necessary, as the important bits (an instrument's hitzones) can be
implicitly derived from the instrument name in the session and hitzones used in
the hit-level data.

However, it is useful and recommended to collect this information at a global
level, to have a format to validate hit-level data against.

1. Instrument name
   - use this name in the [[*Instrument][Instrument]] section in the session metadata
   - this will be 
2. Hit zones
   - a list of all possible ways the instrument is recorded across all
     sessions, and a brief description thereof
   - names have to be the same as those specified in [[*Hit][Hit]] metadata
3. Hit-level conditions
   - possible conditions as that could be present in hit-level data, as a tuple
     of (name, possible values) pairs
4. Additional instrument-level metadata
   - e.g., could detail that hit-level location data is stored as a 2D
       coordinate grid

*** Session

Session metadata is split into technical information about the recording
session, the instrument that is played in the session, and optionally auxiliary
metadata about context in that session.

**** Recording

Required:
2. Sampling rate
3. For each recording device/channel:   
   - Name of the recording device
   Optional:
   - Additional details such as:
     - Placement/location of recording device around the instrument

These has to match the actual audio files stored as part of the dataset.
         
**** Instrument

Required:
1. Instrument name
   - If present, has to match metadata in [[*Instruments][Instruments]]
   - use something informative, like 'snare' or 'kick'

Optional:
1. Additional session-level instrument metadata
   - e.g. tuning, pitch, manufacturer, model, etc.   

**** Context

This section is completely optional, and could record things like:
1. Player
   - Give an ID to each player in the dataset if multiple people recorded
     sessions
2. Musical context
   - on hits which are in-context, what context is this? This could be
     different instruments present, or similar

Think about what sort of data may aid the targeted (or other potential) machine
learning task(s).

*** Hit

Required:
1. Zone
   - Hit zone matching those defined in [[*Instruments][Instruments]], if present
2. Onset start
   - integer index into the paired audio file
3. Velocity
   - value between 0 and 1 (approximately) noting the strength of the hit, e.g.
     0 for the most silent possible hit, and 1 for the hardest possible hit
   - ?should we make this optional?
4. isolated?
   - A boolean flag specifying whether the hit is isolated or in-context

Optional:
1. Location
   - if useful/possible, think about storing the location of a hit within a
     zone, or globally around the instrument
2. Hit conditions
   - has to match those specified in [[*Instruments][Instruments]], if present

** TODO Example

The following is a small example detailing a simplistic POSD that contains
sessions recording snare and kick drum hits.

*** TODO Folder structure

Currently a dataset would look like this. It would be possible to introduce
folders for different instruments or other other things, but I'm not currently
sure if this should be done. We could allow users to set their own hierarchies,
specifying that a dataset can have arbitrarily nested folders, and a loader
should visit everything recursively and load all session data that way.

#+begin_example
Dataset folder
- instruments.json
- session1.json
- session1_hits.json
- session1_SP.wav
- session1_OP.wav
- session2.json
- session2_hits.json
- session2_SP.wav
- session2_OP.wav
#+end_example

Further, session and hits json files could conceivably be in the same JSON
file. The only reason I'm not doing that currently is because the list of hits
may be very long, making it necessary to load a huge JSON file even though one
may just want to look at session-level data.

*** Instruments

?I don't like the 'additional' rubric, and perhaps JSON is not ideal here, as we
can't write comments explaining what this means. For example, I'm trying to
describe that snare drums can contain location information on an X/Y coordinate
grid, with X/Y values taking on values between 0 and 1.

~instruments.json~
#+begin_src json
{
    "snare": {
        "zones": [
            {
            "center": "Strike in the center of the drumhead"
        },
            {
            "edge": "Strike at the edge of the drumhead"
        }
        ],
        "conditions": [
            {
            "wires": [
                "on",
                "off"
            ]
        }
        ],
        "additional": {
            "location_ranges": {
                "x": [0, 1],
                "y": [0, 1]
            }
        }
    },
    "kick": {
        "zones": [
            {
            "press": "Beater is not released upon striking drumhead"
        },
            {
            "release": "Beater is released immediately upon striking drumhead"
        }
        ]
    }
}
#+end_src

*** Sessions

?Should we define certain optional options, like context, or add
instrument-class level metadata that is referenced? (we could populate with
options like full kit, music, band, etc., but there are probably too many
reasonable options to define in the spec)

There are two sessions, one recording the snare, one the kick. These JSON files
will accompany .wav files, namely one for each channel, in the same folder.
Note: all data and metadata will share the same name. WAV files will be
post-fixed by _<channel>, where <channel> one of the channels specified in the
session metadata!

~session1.json~
#+begin_src json
{
    "sampling_rate": 96000,
    "channels": {
        "SP": {
            "location": 12,
            "distance": 10
        },
        "OP": {
            "location": 13,
            "distance": 8
        }
    },
    "instrument": "snare",
    "manufacturer": "sonor",
    "model": "BG SDW 2.0",
    "size": "13x5.75",    
    "head_top": "ambassador",
    "head_bottom": "ambassador_ss",
    "rim": "3f",
    "tuning": "low",
    "player": "rodrigo",
    "context": "full kit"
}
#+end_src

~session2.json~
#+begin_src json
{
    "sampling_rate": 96000,
    "channels": {
        "SP": {
            "location": 15,
            "distance": 10
        },
        "OP": {
            "location": 16,
            "distance": 8
        }
    },
    "instrument": "kick",
    "manufacturer": "sonor",
    "model": "SQ2",
    "size": "20x14",
    "head_front": "powerstroke-p3",
    "head_back": "ambassador-fiberskin",
    "rim": "wood",
    "player": "rodrigo",
    "context": "full kit"
}
#+end_src

*** Hits

~session1_hits.json~

Note how this adds additional data about the pitch of each hit.
#+begin_src json
{
    "zone": ["center", "center", "edge", "edge"],
    "onset_start": [0, 48000, 96000, 144000],
    "velocity": [0.0, 1.0, 0.0, 1.0],
    "isolated": [True, True, True, True],
    "conditions": {
        "wires": ["on", "on", "off", "off"]
    }
    "pitch": [220, 220, 219, 219]
}
#+end_src

~session2_hits.json~
#+begin_src json
{
    "zone": ["press", "press", "release", "release"],
    "onset_start": [0, 48000, 96000, 144000],
    "velocity": [0.5, 1.0, 0.5, 1.0],
    "isolated": [True, True, True, True],
}
#+end_src


* Conventions
POSD can refer to any dataset which adhers to the specification described in
this document. That means that anyone can create POSD datasets!

?Should we give recommendations here as to naming?

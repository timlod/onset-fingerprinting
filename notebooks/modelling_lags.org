#+TITLE: Modelling lags
#+AUTHOR: Tim Loderhose
#+EMAIL: tim@loderhose.com
#+DATE: Wednesday, 12 June 2024
#+STARTUP: showall
#+PROPERTY: header-args :exports both :session lags :kernel lm :cache no
:PROPERTIES:
OPTIONS: ^:nil
#+LATEX_COMPILER: xelatex
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [logo, color, author]
#+LATEX_HEADER: \insertauthor
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry}
:END:

* Imports and Environment Variables
:PROPERTIES:
:visibility: folded
:END:

#+name: imports
#+begin_src python
import json
from importlib import reload
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import sounddevice as sd
import soundfile as sf
import torch
import torch.nn as nn
from onset_fingerprinting import (
    calibration,
    detection,
    model,
    multilateration,
    plots,
)
from torch import optim
from torch.nn import functional as F
#+end_src

#+name: env
#+begin_src python
device = "cuda"
#+end_src

* Introduction
I would like to move towards using NNs on windows of time-correlated audio. For
this, I need to be able to find a network architecture which can learn these
temporal relationships between signals. If the network can figure out the lag
between the different channels, then it should be able to learn the physical
model relating those to the location as well.

To this end, I will generate some impulse data for which I know the lags, and
plug in a number of architectures to see which one can learn this challenge.

* Generate data

The simplest version of this problem finds the lags between impulses occuring
in two signals of a length w.
#+begin_src python
def generate_data(w: int, c: int, n: int = 10000, device=None):
    signals = torch.zeros(n, c, w, device=device)
    impulses = torch.randint(0, w, (n, c), device=device)
    # Force some 0s
    impulses[0] = torch.tensor([0] * c)
    impulses[1] = torch.tensor([w // 2] * c)
    impulses[2] = torch.tensor([w - 1] * c)
    # Force the extremes
    z = torch.zeros((c, c), dtype=torch.long)
    for i in range(c):
        z[i, i] = w - 1
    impulses[3 : 3 + c] = z
    signals.scatter_(2, impulses[:, :, None], 1)
    return signals, torch.diff(impulses).to(torch.float32), impulses
#+end_src


* Learning

#+begin_src python
def train(
    x,
    y,
    model,
    lossfun,
    optimizer,
    scheduler,
    num_epochs=3000,
    x_val=None,
    y_val=None,
    patience=None,
    max_norm: float = 1.0,
    print_every: int = 100,
    print_examples: bool = True,
    device=None,
):
    model.to(device)
    x.to(device)
    y.to(device)
    errors = []
    last_loss = torch.inf
    best_model = None
    counter = 0
    for epoch in range(num_epochs):
        optimizer.zero_grad(set_to_none=True)
        pred = model(x)
        error = lossfun(pred, y)
        loss = error.mean()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)
        optimizer.step()
        scheduler.step()
        if x_val is not None:
            with torch.no_grad():
                vp = model(x_val)
                ve = lossfun(vp, y_val)
            errors.append((error.item(), ve.item()))
            if patience is not None:
                if ve < last_loss:
                    last_loss = ve
                    best_model = {
                        k: v.clone() for k, v in model.state_dict().items()
                    }
                    counter = 0
                elif counter < patience:
                    counter += 1
                else:
                    print(f"Stopping at epoch {epoch}!")
                    break
        else:
            errors.append(error.item())
        if epoch % print_every == 0:
            print(
                f"Epoch {epoch}, TL"
                f" {loss.item()} {f'VL: {ve.item()}' if x_val is not None else ''}"
            )
    print(f"Epoch {epoch}, Loss {loss.item()}")
    if print_examples:
        print(pred[:10], "\n", y[:10])
    return errors, best_model


def error_analysis(model, tx, ty, timp, n_samp=100):
    tp = model.cpu()(tx.cpu())
    e = F.l1_loss(tp, ty.cpu(), reduction="none").squeeze()
    print(
        f"Mean loss: {e.mean().item():4f}, Median loss:"
        f" {e.median().item():.4f}"
    )
    fig = plt.figure(figsize=(6, 3))
    fig.suptitle(f"First {n_samp} test samples")
    plt.plot(tp[:n_samp].detach().cpu(), label="Predictions")
    plt.plot(ty[:n_samp].cpu(), label="Truth")
    plt.legend()
    if e.ndim == 2:
        e = e.mean(1)
    sortidx = e.argsort()
    fig = plt.figure(figsize=(6, 3))
    ax = fig.add_subplot(111)
    (a,) = ax.plot(e[sortidx].detach(), label="Sorted test errors")
    ax.set_ylabel("Errors")
    (b,) = ax.twinx().plot(
        ty.max(1).values.abs().cpu()[sortidx],
        label="Max lag in prediction",
        color="tab:orange",
        alpha=0.7,
    )
    lines = [a, b]
    labels = [line.get_label() for line in lines]
    plt.legend(lines, labels)
    print(
        "Best:",
        ty.cpu()[sortidx][:20, 0],
        "\nWorst:",
        ty.cpu()[sortidx][-20:, 0],
    )
    print(timp[sortidx][-20:])
#+end_src

** 2 channels
Let's start with the simplest version:
#+begin_src python
w = 256
c = 2
lossfun = F.mse_loss
lr = 0.001 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 2000
print_every = 100

# m = model.CNN(w, c - 1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3).to(
#     device
# )
# m = model.RNN(w, c - 1, c, 16, 2, dropout_rate=0.6, rnn_type="GRU", share_input_weights=False).to(device)
# m = model.CNNRNN(
#     w,
#     c - 1,
#     c,
#     layer_sizes=[64],
#     kernel_size=7,
#     n_hidden=16,
#     n_rnn_layers=2,
#     dropout_rate=0.6,
# ).to(device)
m = model.LCCCNN(
    w,
    c - 1,
    c,
    layer_sizes=[3, 3, 3, 3],
    #kernel_sizes=[33, 15, 11, 7],
    kernel_sizes=33,
    strides=[1, 1, 1, 1],
    dropout_rate=0.0,
    batch_norm=True,
    loss=lossfun,
    lr=lr,
).to(device)
x, y, imp = generate_data(w, c, 100, device=device)
tx, ty, timp = generate_data(w, c, 1000, device=device)
y /= 255.0
ty /= 255.0

optimizer = optim.NAdam(m.parameters(), lr=lr)#, weight_decay=1e-8)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 2000)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
m.load_state_dict(bm)
bm = m
#+end_src

#+RESULTS:
#+begin_example
Linear(in_features=1, out_features=1, bias=False)
Epoch 0, TL 0.624150812625885 VL: 0.2959192097187042
Epoch 100, TL 0.0804477110505104 VL: 0.06677788496017456
Epoch 200, TL 0.03180927038192749 VL: 0.03622417524456978
Epoch 300, TL 0.027847349643707275 VL: 0.050633080303668976
Epoch 400, TL 0.017652427777647972 VL: 0.021772103384137154
Epoch 500, TL 0.01491717342287302 VL: 0.021991819143295288
Epoch 600, TL 0.012553679756820202 VL: 0.020237049087882042
Epoch 700, TL 0.011809048242866993 VL: 0.019400034099817276
Epoch 800, TL 0.008404175750911236 VL: 0.021956337615847588
Epoch 900, TL 0.006513411179184914 VL: 0.022793089970946312
Stopping at epoch 983!
Epoch 983, Loss 0.0053855618461966515
tensor([[-7.9346e-09],
        [ 1.9837e-09],
        [ 0.0000e+00],
        [-6.8692e-01],
        [ 6.8692e-01],
        [ 1.0126e-01],
        [ 6.1101e-01],
        [ 3.9157e-01],
        [ 6.7080e-01],
        [-4.9788e-03]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-1.0000],
        [ 1.0000],
        [ 0.1059],
        [ 0.6000],
        [ 0.4000],
        [ 0.6431],
        [ 0.0471]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 0.097127, Median loss: 0.0777
Best: tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.5686, -0.6078,  0.4039, -0.1333,  0.1333,  0.5882,  0.6392,  0.3569,
        -0.0039,  0.4000,  0.2392, -0.2118]) 
Worst: tensor([-0.2667,  0.9059,  0.1608, -0.4471,  0.0196,  0.2392, -0.8902, -0.9176,
        -0.5451,  0.1098, -0.0118, -0.9373,  0.9373,  0.9333,  0.7333, -0.9490,
        -0.0196, -0.9843,  1.0000, -1.0000])
tensor([[218, 150],
        [ 15, 246],
        [130, 171],
        [122,   8],
        [158, 163],
        [151, 212],
        [239,  12],
        [241,   7],
        [255, 116],
        [151, 179],
        [154, 151],
        [247,   8],
        [  8, 247],
        [  7, 245],
        [ 19, 206],
        [252,  10],
        [137, 132],
        [255,   4],
        [  0, 255],
        [255,   0]], device='cuda:0')
#+end_example
[[file:./.ob-jupyter/543b41aef73e723c6bff969466ee8b5acfa92013.png]]
[[file:./.ob-jupyter/3233d8f83f27f0ed0abb19aae60966623d32726a.png]]
:END:

Although it doesn't always converge, this works! Both RNN and CNN are able to
do this, in fact.

However, the loss on the full test set is still rather high! It looks like it's
primarily very large or very small/nonexisting lags which cause this issue.
Large lags make sense, as they're at the boundary and thus are closer to
require extrapolation.

Notes RNN:
- I needed to have a hidden size of 128+ to be able to learn this properly, at
  2 layers. More layers, and it becomes harder to learn. With smaller sizes, it
  appears that the lag is limited to the hidden size, showing that it is
  related to how far the network can look to find lags.
- Once I added the attention, it worked also with a hidden size of 64
Notes CNN:
- slightly worse at this than the RNN in convergence - it gets better at larger
  numbers of parameters, but then I'd need to tweak more to get it to converge

** 3 channels
Let's see if it can learn 2 lags at the same time. That's one step closer
towards what we need to learn.

#+begin_src python
w = 256
c = 3
lossfun = F.mse_loss
lr = 0.001 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 3000
print_every = 100

# m = model.CNN(
#     w, c-1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
# ).cuda()
m = model.RNN(w, c - 1, c, 16, 2, dropout_rate=0.6, share_input_weights=True).cuda()
device = m.device
x, y, imp = generate_data(w, c, 100, device=device)
tx, ty, timp = generate_data(w, c, 1000, device=device)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 9797.724609375 VL: 10937.0771484375
Epoch 100, TL 4533.7890625 VL: 9037.7470703125
Epoch 200, TL 2950.878173828125 VL: 3322.52294921875
Epoch 300, TL 356.5895080566406 VL: 1074.657470703125
Epoch 400, TL 202.80323791503906 VL: 867.0380859375
Epoch 500, TL 84.18399047851562 VL: 386.94635009765625
Epoch 600, TL 32.605918884277344 VL: 74.24748229980469
Epoch 700, TL 64.31904602050781 VL: 41.493675231933594
Epoch 800, TL 17.088197708129883 VL: 57.716644287109375
Epoch 900, TL 28.063058853149414 VL: 31.811717987060547
Epoch 1000, TL 13.49834156036377 VL: 28.634328842163086
Epoch 1100, TL 15.28337574005127 VL: 26.30498504638672
Epoch 1200, TL 11.294228553771973 VL: 26.616729736328125
Epoch 1300, TL 10.797918319702148 VL: 16.320541381835938
Epoch 1400, TL 7.7080979347229 VL: 15.624723434448242
Epoch 1500, TL 9.873404502868652 VL: 11.996635437011719
Epoch 1600, TL 5.244534969329834 VL: 13.392248153686523
Epoch 1700, TL 4.024059772491455 VL: 9.139055252075195
Epoch 1800, TL 4.523504257202148 VL: 13.074235916137695
Epoch 1900, TL 4.394941806793213 VL: 9.586922645568848
Epoch 2000, TL 4.473787307739258 VL: 9.338714599609375
Epoch 2100, TL 3.0711374282836914 VL: 10.5660400390625
Epoch 2200, TL 3.194096088409424 VL: 7.816829681396484
Epoch 2300, TL 2.5959553718566895 VL: 6.540218353271484
Epoch 2400, TL 2.9732067584991455 VL: 7.469451904296875
Epoch 2500, TL 2.7218360900878906 VL: 7.070628643035889
Epoch 2600, TL 2.3775062561035156 VL: 7.469150066375732
Epoch 2700, TL 2.0485284328460693 VL: 8.085326194763184
Epoch 2800, TL 2.4743940830230713 VL: 9.536794662475586
Epoch 2900, TL 2.2067036628723145 VL: 7.413653373718262
Epoch 2999, Loss 2.2365968227386475
tensor([[-1.8919e+00, -6.3282e-02],
        [ 1.1337e+00, -9.9705e-01],
        [-8.5596e-02, -1.4792e-01],
        [-2.5889e+02,  2.2042e-01],
        [ 2.5255e+02, -2.5264e+02],
        [ 6.9334e-01,  2.5559e+02],
        [-8.9901e+00,  1.6475e+02],
        [ 3.1594e+01, -5.2260e+01],
        [ 5.1377e+01,  3.8554e+01],
        [ 2.3470e+02, -2.6096e+01]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.,    0.],
        [   0.,    0.],
        [   0.,    0.],
        [-255.,    0.],
        [ 255., -255.],
        [   0.,  255.],
        [  -7.,  164.],
        [  32.,  -53.],
        [  51.,   38.],
        [ 236.,  -28.]], device='cuda:0')
#+end_example

Plot results on the test set:
#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 3.067169, Median loss: 1.9193
Best: tensor([-132.,   95.,    8.,   56.,    8., -208.,  -38.,   -2.,   16.,   43.,
          29., -164.,  -18.,  193.,   14.,   21.,  -48.,    6., -104.,  -59.]) 
Worst: tensor([ 37., 190., 255.,   5.,   0.,   4.,   5.,  -6., -60., 121., -26.,  31.,
        -81.,  73.,  71.,  59.,  43., 119.,   7.,  76.])
tensor([[  9,  46,  31],
        [ 18, 208, 254],
        [  0, 255,   0],
        [ 33,  38, 255],
        [246, 246, 191],
        [215, 219, 151],
        [220, 225, 170],
        [252, 246, 237],
        [163, 103, 254],
        [133, 254, 178],
        [146, 120, 255],
        [222, 253, 254],
        [237, 156, 255],
        [182, 255, 114],
        [184, 255, 242],
        [138, 197, 255],
        [204, 247, 253],
        [ 71, 190, 255],
        [248, 255,  94],
        [165, 241, 255]], device='cuda:0')
#+end_example
[[./.ob-jupyter/f68729cc5000a20cf33bed2d4bf8fb5f0a6d8c10.png]]
[[./.ob-jupyter/9b6d49aadc3afb461346e114ee8a746b8efd775b.png]]
:END:



#+RESULTS:
#+begin_example
Epoch 0, TL 12356.1396484375 VL: 11654.6298828125
Epoch 100, TL 7621.8505859375 VL: 8922.38671875
Epoch 200, TL 4692.791015625 VL: 4432.2724609375
Epoch 300, TL 3617.2890625 VL: 3960.30810546875
Epoch 400, TL 2975.39501953125 VL: 3386.6318359375
Epoch 500, TL 1673.6810302734375 VL: 1782.166015625
Epoch 600, TL 601.9627075195312 VL: 1070.9232177734375
Epoch 700, TL 438.4246826171875 VL: 714.2683715820312
Epoch 800, TL 252.6402130126953 VL: 660.646240234375
Epoch 900, TL 208.8948211669922 VL: 413.8019714355469
Epoch 1000, TL 163.1772918701172 VL: 311.8202819824219
Epoch 1100, TL 128.8693389892578 VL: 320.7862548828125
Epoch 1200, TL 112.0771255493164 VL: 292.47454833984375
Epoch 1300, TL 64.62334442138672 VL: 387.5838317871094
Epoch 1400, TL 86.0174560546875 VL: 215.64512634277344
Epoch 1500, TL 78.3893051147461 VL: 212.8132781982422
Epoch 1600, TL 58.031585693359375 VL: 217.86044311523438
Epoch 1700, TL 39.056209564208984 VL: 220.63156127929688
Epoch 1800, TL 32.34804916381836 VL: 189.09466552734375
Epoch 1900, TL 24.82532501220703 VL: 196.97238159179688
Epoch 2000, TL 24.550607681274414 VL: 175.1767120361328
Epoch 2100, TL 24.274049758911133 VL: 187.39707946777344
Epoch 2200, TL 15.048283576965332 VL: 170.42678833007812
Epoch 2300, TL 14.50401782989502 VL: 155.8015594482422
Epoch 2400, TL 14.956853866577148 VL: 164.1660919189453
Epoch 2500, TL 13.131484985351562 VL: 160.4081573486328
Epoch 2600, TL 11.323251724243164 VL: 155.822998046875
Epoch 2700, TL 11.416837692260742 VL: 158.9982147216797
Epoch 2800, TL 13.83969497680664 VL: 150.00393676757812
Epoch 2900, TL 9.069437980651855 VL: 163.32676696777344
Epoch 2999, Loss 11.212181091308594
tensor([[  -0.2927,   -3.0392],
        [  -0.7276,   -2.8642],
        [   0.6274,    0.3188],
        [-252.9344,   -1.5700],
        [ 256.4276, -252.8566],
        [   5.4303,  249.7804],
        [ 129.4544,  -98.4681],
        [-132.0554,   46.2599],
        [ -14.3961,   92.2857],
        [ -64.0335,    7.8503]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.,    0.],
        [   0.,    0.],
        [   0.,    0.],
        [-255.,    0.],
        [ 255., -255.],
        [   0.,  255.],
        [ 126.,  -96.],
        [-135.,   46.],
        [ -12.,   82.],
        [ -67.,    9.]], device='cuda:0')
#+end_example

#+begin_example
Mean loss: 9.929891, Median loss: 5.3763
Best: tensor([-236.,   86.,    0.,   -8.,   27.,  163.,   71.,  229.,   50.,  126.,
          82.,  -45.,  163.,  128.,    5.,   30.,  -27., -116.,   49.,  176.]) 
Worst: tensor([-178.,  123.,  159.,  162.,  152.,  184.,  195.,  176.,  158.,  178.,
         160.,  150.,  175.,  184.,  182.,  184.,  210.,  201.,  197.,  205.])
tensor([[202,  24,  45],
        [ 91, 214,  98],
        [ 86, 245,  90],
        [ 15, 177,  25],
        [ 51, 203,  55],
        [  7, 191,   6],
        [  5, 200,   2],
        [ 64, 240,  43],
        [ 37, 195,  22],
        [ 10, 188,  16],
        [ 87, 247, 106],
        [ 60, 210,  67],
        [ 40, 215,  29],
        [ 22, 206,  18],
        [ 61, 243,  79],
        [ 58, 242,  44],
        [ 16, 226,   3],
        [ 15, 216,  23],
        [ 51, 248,  65],
        [ 43, 248,  27]], device='cuda:0')
#+end_example
[[./.ob-jupyter/758e66ff4cd77bc94a894c5f05d9ba3ddd4ef35c.png]]
[[./.ob-jupyter/7fcba408499a538dea4778611957b1d615e06577.png]]

Error analysis:
The MSE is still very high on this, possibly because we overfit, having lowered
the dropout.
let's see at which values of lags the model struggles most:
#+begin_src python
e = (tp - ty.cpu()).square().sum(1)
sortidx = e.argsort()
print("Best:\n",ty.cpu()[sortidx][:10].T, "\nWorst:\n", ty.cpu()[sortidx][-10:].T)
#+end_src

#+RESULTS:
: Best:
:  tensor([[ -55., -136.,  -55.,  119., -185.,   88., -182.,  206.,  104., -106.],
:         [ 105.,  115.,  -46., -141.,   88., -140.,  122., -101., -169.,   58.]]) 
: Worst:
:  tensor([[ 254.,  244.,  246.,    5.,  -89.,  240.,   29.,  -76., -187.,  -45.],
:         [ -76.,  -31.,  -53.,    0.,  166.,  -16.,  158.,  201.,  251.,  233.]])

There are somewhat more extreme values at the large errors, but in general I
think it's just overfit.

** Non-binary impulses
This is a contrived case where we learn impulses, but in reality we'll never
have such data. Let's transform these into gaussian impulses for a further
step, and check whether it still works as well.

#+begin_src python
def transform_impulse1(x, n=11, ramp_up: int = 0):
    c = x.shape[1]
    ls = torch.linspace(-3 * np.e, 0, n, device=x.device)
    exp = torch.exp(ls)
    if ramp_up > 0:
        exp[-ramp_up:] = torch.exp(
            torch.linspace(ls[-ramp_up], 2 * -np.e, ramp_up, device=x.device)
        )
    return F.conv1d(F.pad(x, (n - 1, 0)), exp.repeat(c, 1, 1), groups=c)
#+end_src

#+begin_src python
w = 256
c = 3
lossfun = F.l1_loss
lr = 0.001 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 3000
print_every = 100

# m = model.CNN(
#     w, c-1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
# ).to(device)
# m = model.CNNRNN(
#     w,
#     c-1,
#     c,
#     layer_sizes=[8],
#     kernel_size=2,
#     n_hidden=128,
#     n_rnn_layers=1,
#     dropout_rate=0.6,
# ).to(device)
# m = model.RNN(w, c - 1, c, 64, 2, dropout_rate=0.5).to(device)
m = model.LCCCNN(
    w,
    c-1,
    c,
    layer_sizes=[8, 8, 8, 8],
    kernel_sizes=7,
    dropout_rate=0.0,
    batch_norm=True,
    loss=lossfun,
    lr=lr,
).to(device)
x, y, imp = generate_data(w, c, 100, device=device)
x = transform_impulse1(x, 200, 20)
tx, ty, timp = generate_data(w, c, 1000, device=device)
tx = transform_impulse1(tx, 200, 20)
y /= 255
ty /= 255
optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 5000, tx[:100], ty[:100], 500
)
m.load_state_dict(bm)
bm = m
#+end_src

#+RESULTS:
#+begin_example
/home/tim/projects/onset-fingerprinting/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
Epoch 0, TL 11471.6171875 VL: 10763.947265625
Epoch 100, TL 6300.701171875 VL: 4763.0048828125
Epoch 200, TL 1386.6453857421875 VL: 1241.863037109375
Epoch 300, TL 342.417724609375 VL: 723.0066528320312
Epoch 400, TL 250.0272216796875 VL: 510.8902893066406
Epoch 500, TL 55.00023651123047 VL: 379.0447998046875
Epoch 600, TL 57.27154541015625 VL: 424.559326171875
Epoch 700, TL 43.54613494873047 VL: 150.87136840820312
Epoch 800, TL 31.350616455078125 VL: 146.08096313476562
Epoch 900, TL 37.63465881347656 VL: 210.27972412109375
Epoch 1000, TL 59.4703254699707 VL: 61.12222671508789
Epoch 1100, TL 29.809720993041992 VL: 64.12410736083984
Epoch 1200, TL 15.877347946166992 VL: 97.62782287597656
Epoch 1300, TL 14.474164962768555 VL: 87.64909362792969
Epoch 1400, TL 13.176837921142578 VL: 86.94642639160156
Epoch 1500, TL 7.699976444244385 VL: 81.4412841796875
Epoch 1600, TL 5.240980625152588 VL: 65.48567199707031
Epoch 1700, TL 9.369585037231445 VL: 61.48301315307617
Epoch 1800, TL 11.597272872924805 VL: 55.46167755126953
Epoch 1900, TL 11.893485069274902 VL: 46.76387405395508
Epoch 2000, TL 5.205259323120117 VL: 56.14391326904297
Epoch 2100, TL 6.685842037200928 VL: 60.57660675048828
Epoch 2200, TL 2.979496955871582 VL: 47.39455795288086
Epoch 2300, TL 2.6737499237060547 VL: 52.31924819946289
Epoch 2400, TL 2.32865309715271 VL: 56.26995849609375
Epoch 2500, TL 2.1595070362091064 VL: 60.19451904296875
Epoch 2600, TL 2.235826015472412 VL: 53.08357238769531
Stopping at epoch 2637!
Epoch 2637, Loss 2.036637306213379
tensor([[  62.6798,  141.3915],
        [  68.4154, -164.8867],
        [  53.9853,   59.8275],
        [  31.9432, -179.9884],
        [ 173.9814,   21.4797],
        [  46.0552,  -49.5891],
        [ 123.8873, -126.6256],
        [ -19.2127,   14.2151],
        [-150.5007,  182.4794],
        [ -93.4469, -122.0795]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[  58.,  143.],
        [  65., -163.],
        [  55.,   59.],
        [  32., -180.],
        [ 175.,   20.],
        [  49.,  -52.],
        [ 123., -126.],
        [ -15.,   12.],
        [-149.,  181.],
        [ -93., -122.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 3.942275, Median loss: 1.8895
Best: tensor([ 69.,  35.,  56., -40.,  64.,  52.,  47., 129., -76., 151.,  79.,  -5.,
         55.,  40., 132., -50., -20.,  53., -41.,  31.]) 
Worst: tensor([ -62., -122.,   -1., -226.,   -1., -201., -209.,  -70., -223.,  -86.,
        -229.,  -74.,    3.,  -82.,    3.,  -90.,   -2.,  -89.,    0.,    2.])
tensor([[ 56, 118,  88],
        [ 18, 140, 115],
        [ 69,  70, 173],
        [ 18, 244, 174],
        [104, 105, 189],
        [  8, 209, 191],
        [ 11, 220, 173],
        [ 67, 137, 118],
        [ 25, 248, 224],
        [ 10,  96,  79],
        [ 22, 251, 196],
        [ 33, 107,  73],
        [121, 118, 158],
        [ 21, 103,  81],
        [ 59,  56, 151],
        [  8,  98,  69],
        [ 71,  73,  68],
        [  3,  92,  69],
        [ 42,  42, 199],
        [ 29,  27, 110]], device='cuda:0')
#+end_example
[[./.ob-jupyter/a8aa1a861fad67c9f96828b56d97206fc25181dc.png]]
[[./.ob-jupyter/7d0c1568492492549fec03849e787f041c31e2d2.png]]
:END:

Nice, it performs pretty much the same!

*** Additional changes
This is still very idealized - here are more things we can do to make it look
more real:
- peaks at different amplitudes
- modulate with sine wave
- add noise


Note: frequencies should be the same in each of the channels, phase could be
slightly shifted, but very little. The sine needs to start at the impulse in
each case, so currently this is wrong.
#+begin_src python
def transform_impulse2(
    x, imp, random_phase: bool = False, noise_std=0, sr=96000
):
    n, c, w = x.shape
    ls = torch.linspace(0, x.shape[-1] / sr, x.shape[-1], device=x.device)
    phase = (
        torch.rand(x.shape[0], x.shape[1], 1, device=x.device) * 0.1 * np.pi
        if random_phase
        else 0
    )
    f = torch.randint(300, 1000, (x.shape[0], 1, 1), device=x.device).expand(
        n, c, 1
    )
    sin = torch.sin(2 * np.pi * ls[None, None, :] * f + phase)
    for i in range(len(x)):
        for j in range(c):
            k = w - imp[i, j]
            x[i, j, imp[i, j] :] *= sin[i, j, :k]
    x += torch.randn(x.shape, device=x.device) * noise_std
    return x
#+end_src

#+begin_src python
x = transform_impulse2(x, imp, True, 0.001)
tx = transform_impulse2(tx, timp, True, 0.001)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x,
    y,
    m.to(device),
    lossfun,
    optimizer,
    scheduler,
    3000,
    tx[:100],
    ty[:100],
    500,
)
m.load_state_dict(bm)
bm = m
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 38.41012191772461 VL: 11656.9599609375
Epoch 100, TL 16.59128189086914 VL: 153.88595581054688
Epoch 200, TL 22.921138763427734 VL: 109.77005004882812
Epoch 300, TL 60.49607467651367 VL: 96.41871643066406
Epoch 400, TL 11399.8642578125 VL: 10716.013671875
Epoch 500, TL 3034.529296875 VL: 3443.92236328125
Epoch 600, TL 689.79443359375 VL: 455.908203125
Epoch 700, TL 72.95342254638672 VL: 165.76028442382812
Stopping at epoch 732!
Epoch 732, Loss 80.4583511352539
tensor([[  61.4558,  144.0829],
        [  48.9084, -145.4959],
        [  49.2660,   55.4530],
        [  22.9640, -167.7405],
        [ 166.9901,   23.7873],
        [  45.7351,  -44.0062],
        [ 110.5431, -113.2652],
        [ -17.7397,    7.5596],
        [-141.3242,  174.2570],
        [-105.1589, -120.3260]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[  58.,  143.],
        [  65., -163.],
        [  55.,   59.],
        [  32., -180.],
        [ 175.,   20.],
        [  49.,  -52.],
        [ 123., -126.],
        [ -15.,   12.],
        [-149.,  181.],
        [ -93., -122.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 8.697659, Median loss: 7.2153
Best: tensor([  81., -133.,  -21., -149.,   37.,  -50.,   44.,  -51., -194.,   36.,
         -82., -117.,   -8., -165.,  142.,  133.,  160.,   47.,  -70.,  -55.]) 
Worst: tensor([153., -16.,  13., -25., -11., -15., -20., -24., -18., -32., -24.,  -6.,
        -14.,  11., -21.,  11., -18., 228., 196.,  -2.])
tensor([[186,  33,   2],
        [  9,  25,  26],
        [141, 128, 118],
        [ 29,  54, 162],
        [  8,  19,  37],
        [ 59,  74, 160],
        [ 13,  33, 162],
        [ 13,  37, 124],
        [ 38,  56, 175],
        [ 38,  70,  60],
        [ 19,  43, 106],
        [ 24,  30,  84],
        [ 45,  59, 125],
        [ 69,  58,  46],
        [ 30,  51, 129],
        [ 87,  76,  70],
        [  2,  20,  62],
        [254,  26,  17],
        [208,  12,   8],
        [ 71,  73,  68]], device='cuda:0')
#+end_example
[[./.ob-jupyter/8c75740c54df5a4ef929e0528f428af74278893a.png]]
[[./.ob-jupyter/471d27d84a130b38e16a2cb2baf00a9975c3c161.png]]
:END:


Good sizes appear to be either a few (5) 4-8-size layers with a large kernel size
(e.g. 33) or 10 layers with a moderate kernel size (e.g. 15).
#+begin_src python
m = model.CNN(
    w, c - 1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
).to(device)
m = model.CNNRNN(
    w,
    c-1,
    c,
    layer_sizes=[8],
    kernel_size=2,
    n_hidden=128,
    n_rnn_layers=1,
    dropout_rate=0.6,
).to(device)
m = model.LCCCNN(
    w,
    c-1,
    c,
    layer_sizes=[5] * 7,
    kernel_sizes=[1, 33, 64, 15, 15, 15, 1],
    dropout_rate=0.0,
    batch_norm=True,
    loss=lossfun,
    lr=lr,
    group=False
).to(device)
#m = model.RNN(w, c - 1, c, 64, 2, dropout_rate=0.5).to(device)

x, y, imp = generate_data(w, c, 100, device=device)
x = transform_impulse1(x, 200, 20)
x = transform_impulse2(x, imp, True, 0.001)
tx, ty, timp = generate_data(w, c, 1000, device=device)
tx = transform_impulse1(tx, 200, 20)
tx = transform_impulse2(tx, timp, True, 0.001)
y /= 255
ty /= 255
optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
m.load_state_dict(bm)
bm = m
#+end_src

#+RESULTS:
:RESULTS:
: /home/tim/projects/onset-fingerprinting/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1
:   warnings.warn("dropout option adds dropout after all but last "
: Epoch 0, TL 0.17845021188259125 VL: 0.1758619248867035
: Epoch 100, TL 0.05831901356577873 VL: 0.1305510550737381
: Epoch 200, TL 0.008663039654493332 VL: 0.011927877552807331
: Epoch 300, TL 0.0058522881008684635 VL: 0.009444184601306915
: Epoch 400, TL 0.004826344549655914 VL: 0.008127442561089993
: Epoch 500, TL 0.003857510630041361 VL: 0.008599095046520233


#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 0.006340, Median loss: 0.0044
Best: tensor([ 0.1176, -0.3373,  0.0000,  0.0000, -0.0118, -0.3255,  0.0902,  0.4392,
        -0.0314,  0.4000, -0.3490,  0.2314, -0.3529,  0.2902,  0.3373,  0.1569,
         0.4431, -0.0078, -0.0039,  0.0000]) 
Worst: tensor([ 0.6549,  0.8235,  0.6902, -0.6196,  0.8353,  0.5216,  0.6039,  0.9333,
         0.4118, -0.6627,  0.2392,  0.1137,  0.1569,  0.9529, -0.0353,  0.1020,
         0.7294,  0.5765,  0.0627,  0.3098])
tensor([[ 77, 244, 214],
        [ 36, 246, 164],
        [ 60, 236, 140],
        [219,  61, 155],
        [ 32, 245,  90],
        [109, 242, 180],
        [ 88, 242,  22],
        [  8, 246, 210],
        [140, 245, 144],
        [246,  77, 244],
        [ 92, 153,   0],
        [217, 246, 145],
        [202, 242, 107],
        [  3, 246, 224],
        [253, 244,  48],
        [225, 251, 138],
        [  8, 194,  80],
        [ 96, 243,  97],
        [202, 218, 239],
        [164, 243, 108]], device='cuda:0')
#+end_example
[[file:./.ob-jupyter/8cc13765aac9013ad0e6cb9c0041ccb35b44c2ba.png]]
[[file:./.ob-jupyter/1fea025bbd05a42644bd44a1f731bd1809598207.png]]
:END:

*** Making the data even more real

In its current iteration, the data models an impulse of the fundamental - but
as far as the modelling problem goes, it's different from what we'll see in
realtime: There, we'll always start the window from the first onset on. In the
current data, the first onset may start anywhere.

Let's adapt the data in such a way that our first onset is always close to the
beginning of the buffers.
#+begin_src python
def generate_data2(w: int, c: int, n: int = 10000, max_shift=10, device=None):
    signals = torch.zeros(n, c, w, device=device)
    impulses = torch.randint(0, w - max_shift, (n, c), device=device)
    mini = impulses.min(dim=1, keepdim=True).values
    impulses -= mini
    impulses += torch.maximum(
        torch.tensor(0, device=device),
        torch.minimum(
            w - impulses.max(dim=1, keepdim=True).values - 1,
            torch.randint(max_shift, (len(impulses), 1), device=device),
        ),
    )
    # Force some 0s
    impulses[0] = torch.tensor([0] * c)
    impulses[1] = torch.tensor([w // 2] * c)
    impulses[2] = torch.tensor([w - 1] * c)
    # Force the extremes
    z = torch.zeros((c, c), dtype=torch.long)
    for i in range(c):
        z[i, i] = w - 1
    impulses[3 : 3 + c] = z
    signals.scatter_(2, impulses[:, :, None], 1)
    return signals, torch.diff(impulses).to(torch.float32), impulses
#+end_src


#+begin_src python
w = 256
c = 3
lossfun = F.mse_loss
lr = 0.001 * (5 if lossfun == F.mse_loss else 1)
num_epochs = 2000
print_every = 100

m = model.CNN(
    w, c - 1, c, layer_sizes=[8, 8], kernel_size=8, dropout_rate=0.9
).to(device)
m = model.RNN(
    w,
    c - 1,
    c,
    16,
    1,
    dropout_rate=0.6,
    rnn_type="GRU",
    share_input_weights=True,
).to(device)
# m = model.CNNRNN(
#     w,
#     c - 1,
#     c,
#     layer_sizes=[9, 18, 27],
#     kernel_size=3,
#     n_hidden=64,
#     n_rnn_layers=2,
#     dropout_rate=0.8,
#     groups=1,
# ).to(device)
m = model.LCCCNN(
    w,
    c-1,
    c,
    layer_sizes=[5] * 7,
    kernel_sizes=[33, 15, 15, 15, 15, 15, 15],
    dropout_rate=0.0,
    batch_norm=True,
    loss=lossfun,
    lr=lr,
    group=False
).to(device)
x, y, imp = generate_data2(w, c, 100, 100, device=device)
tx, ty, timp = generate_data2(w, c, 1000, 100, device=device)
y /= 255
ty /= 255

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer, num_epochs / 10
)
errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
m.load_state_dict(bm)
x = transform_impulse1(x, 200, 20)
tx = transform_impulse1(tx, 200, 20)
errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
m.load_state_dict(bm)
x = transform_impulse2(x, imp, True, 0.01)
tx = transform_impulse2(tx, timp, True, 0.01)
errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
m.load_state_dict(bm)
bm = m
#+end_src

#+RESULTS:
#+begin_example
Linear(in_features=921, out_features=2, bias=True)
Epoch 0, TL 0.08475777506828308 VL: 0.08754793554544449
Epoch 100, TL 0.01485474593937397 VL: 0.01592090167105198
Epoch 200, TL 0.01241721399128437 VL: 0.015159914270043373
Epoch 300, TL 0.012139304541051388 VL: 0.014529521577060223
Epoch 400, TL 0.010987206362187862 VL: 0.014583615586161613
Epoch 500, TL 0.008647425100207329 VL: 0.010019618086516857
Epoch 600, TL 0.005193499848246574 VL: 0.006181598640978336
Epoch 700, TL 0.004155826289206743 VL: 0.004997751209884882
Epoch 800, TL 0.00256907450966537 VL: 0.0037851594388484955
Epoch 900, TL 0.0014313417486846447 VL: 0.002068587811663747
Epoch 1000, TL 0.0013457691529765725 VL: 0.0019332673400640488
Epoch 1100, TL 0.0012701700907200575 VL: 0.0018053437815979123
Epoch 1200, TL 0.002579753752797842 VL: 0.0034762013237923384
Epoch 1300, TL 0.0013104581739753485 VL: 0.002046008128672838
Epoch 1400, TL 0.0011142771691083908 VL: 0.001692927093245089
Epoch 1500, TL 0.0009633831214159727 VL: 0.0016256222734227777
Epoch 1600, TL 0.006078013218939304 VL: 0.008876325562596321
Epoch 1700, TL 0.001540356664918363 VL: 0.002366165164858103
Epoch 1800, TL 0.001432583900168538 VL: 0.0022705155424773693
Epoch 1900, TL 0.0013270957861095667 VL: 0.0021359322126954794
Epoch 2000, TL 0.001188366673886776 VL: 0.001900134957395494
Epoch 2100, TL 0.0007377674919553101 VL: 0.001437524682842195
Epoch 2200, TL 0.0007023534853942692 VL: 0.001447712886147201
Epoch 2300, TL 0.0006731817265972495 VL: 0.0014470097376033664
Epoch 2400, TL 0.009344288147985935 VL: 0.010423077270388603
Epoch 2500, TL 0.0011564207961782813 VL: 0.0013829179806634784
Epoch 2600, TL 0.0010829153470695019 VL: 0.0012087036157026887
Epoch 2700, TL 0.001026883372105658 VL: 0.0010872945422306657
Epoch 2800, TL 0.0014713284326717257 VL: 0.0014176551485434175
Epoch 2900, TL 0.0008316895109601319 VL: 0.0010605320567265153
Epoch 2999, Loss 0.0008070043986663222
tensor([[ 0.0035, -0.0077],
        [-0.0043, -0.0016],
        [-0.0033, -0.0145],
        [-0.9725,  0.0091],
        [ 0.9885, -1.0037],
        [-0.0123,  0.9646],
        [ 0.1508, -0.3878],
        [ 0.2871, -0.5588],
        [-0.0532, -0.0446],
        [ 0.1768, -0.4776]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [-1.0000,  0.0000],
        [ 1.0000, -1.0000],
        [ 0.0000,  1.0000],
        [ 0.1255, -0.3608],
        [ 0.2784, -0.5608],
        [-0.0510, -0.0392],
        [ 0.1647, -0.4863]], device='cuda:0')
Epoch 0, TL 0.03753330558538437 VL: 0.042968858033418655
Epoch 100, TL 0.0058810212649405 VL: 0.002938932739198208
Epoch 200, TL 0.0002800497750286013 VL: 0.0006850709323771298
Epoch 300, TL 0.00011543720029294491 VL: 0.00050835229922086
Epoch 400, TL 0.0001120915258070454 VL: 0.0005052877240814269
Epoch 500, TL 0.00010880436457227916 VL: 0.0005032439948990941
Epoch 600, TL 0.0004524064715951681 VL: 0.0007853604620322585
Stopping at epoch 632!
Epoch 632, Loss 0.0002448905725032091
tensor([[-9.2985e-03,  4.1139e-03],
        [-2.6007e-03,  4.9814e-03],
        [ 9.1959e-05,  1.0470e-02],
        [-9.5150e-01,  9.8994e-03],
        [ 9.5525e-01, -9.6181e-01],
        [-2.2256e-02,  9.7061e-01],
        [ 1.1427e-01, -3.5435e-01],
        [ 2.5856e-01, -5.4347e-01],
        [-5.4812e-02, -4.2642e-02],
        [ 1.6266e-01, -4.7050e-01]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [-1.0000,  0.0000],
        [ 1.0000, -1.0000],
        [ 0.0000,  1.0000],
        [ 0.1255, -0.3608],
        [ 0.2784, -0.5608],
        [-0.0510, -0.0392],
        [ 0.1647, -0.4863]], device='cuda:0')
Epoch 0, TL 0.011371043510735035 VL: 0.006753172259777784
Epoch 100, TL 0.0002433540066704154 VL: 0.0006907382630743086
Epoch 200, TL 0.0002263366914121434 VL: 0.0006665968103334308
Epoch 300, TL 0.0003034706460312009 VL: 0.0007080236100591719
Epoch 400, TL 0.0001493444142397493 VL: 0.0003917688154615462
Epoch 500, TL 9.395243250764906e-05 VL: 0.0003871158405672759
Epoch 600, TL 9.156927262665704e-05 VL: 0.00039200318860821426
Epoch 700, TL 0.0005420655361376703 VL: 0.0006499456940218806
Epoch 800, TL 0.0002515842788852751 VL: 0.0005335333989933133
Epoch 900, TL 6.354525248752907e-05 VL: 0.0004634555953089148
Stopping at epoch 925!
Epoch 925, Loss 6.235999899217859e-05
tensor([[ 3.6581e-03, -1.0573e-03],
        [-2.1675e-04,  2.2077e-04],
        [-3.8852e-03, -1.2496e-03],
        [-9.8874e-01,  2.0893e-03],
        [ 9.8458e-01, -9.7127e-01],
        [-7.4014e-03,  9.7661e-01],
        [ 1.1433e-01, -3.5234e-01],
        [ 2.6786e-01, -5.5463e-01],
        [-4.1413e-02, -3.5248e-02],
        [ 1.7238e-01, -4.8157e-01]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [-1.0000,  0.0000],
        [ 1.0000, -1.0000],
        [ 0.0000,  1.0000],
        [ 0.1255, -0.3608],
        [ 0.2784, -0.5608],
        [-0.0510, -0.0392],
        [ 0.1647, -0.4863]], device='cuda:0')
#+end_example


#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 0.010505, Median loss: 0.0083
Best: tensor([ 0.1529, -0.1020,  0.3412, -0.2863, -0.0745, -0.1373, -0.0549,  0.0353,
         0.0118, -0.0235,  0.1804,  0.0941, -0.0431, -0.4157, -0.2275, -0.1804,
         0.3569,  0.0000,  0.0118, -0.0627]) 
Worst: tensor([ 0.4353,  0.4392,  0.1020, -0.3059,  0.4588,  0.1451, -0.2000, -0.4157,
        -0.0863,  0.3961,  0.1098,  0.3922,  0.0980, -0.5686, -0.4353,  0.4588,
        -0.5569,  0.0863, -0.0275, -0.5137])
tensor([[ 15, 126,  43],
        [ 96, 208,  95],
        [ 49,  75,  33],
        [183, 105,  87],
        [ 84, 201, 220],
        [ 94, 131,  58],
        [ 63,  12,  92],
        [106,   0,  35],
        [103,  81, 101],
        [ 17, 118, 108],
        [ 98, 126, 162],
        [ 96, 196,  99],
        [ 99, 124, 203],
        [232,  87, 145],
        [112,   1, 112],
        [ 88, 205, 162],
        [239,  97,  91],
        [ 79, 101,  82],
        [ 77,  70,  66],
        [237, 106,  99]], device='cuda:0')
#+end_example
[[file:./.ob-jupyter/59aa92652e117d78ee6b2e1097c81de45818ff54.png]]
[[file:./.ob-jupyter/50aaacaeb22e8bab8ad5ec79206e828a6ded788c.png]]
:END:

** Real Data

Good results with this and SGD with lr*100 and momentum 0.8 (last layer not
        used due to strides being short):
        layer_sizes=[3] * 4 + [5],
        kernel_sizes=[33, 15, 11, 7, 1],
        # kernel_sizes=[13] * 4,
        strides=[2, 2, 1, 1],
        dropout_rate=0.0,
        batch_norm=True,
        loss=lossfun,
        lr=0.001,

192 and 256 both work as frame sizes. adding one more fc layer at the end with
3 outputs before a nonlinearity might improve things slightly

decent with actual CC implementation (cosine annealing 2000):
m = model.LCCCNN(
        w,
        outdim,
        channels,
        layer_sizes=[6] * 9,
        # kernel_sizes=11,
        kernel_sizes=[15, 15, 11, 7],
        # kernel_sizes=[13] * 4,
        strides=[2, 2] + 10 * [1],
        dropout_rate=0.0,
        batch_norm=True,
        loss=lossfun,
        lr=0.01,
        group=False,
        pool=False,
    )


* Pre-training
Start with impulse data, and epoch-by-epoch morph it into something looking
more like a real signal.



* Idea
Random tone generator based on FM synthesis or just adding different modulated
sines with a huge space. Then feedback the system by saying like/dislike on
single tones to find a space of settings which are pleasing to the ear.

* TODO

** Add loading of pre-trained network, partially
Need to be able to load just the lag part, then bolt an MLP, or multilaterator,
on top.

** Check other dataset

** Check differentiable multilaterator properly
compare to existing multilaterator

#+begin_src python
sr = 96000
c = 82.0
radius = 0.1778
R = 0.142
pos_c = torch.tensor([[0.0, R], [R, 0.0], [0.0, -R], [-R, 0.0]])
pos_s = np.array([multilateration.cartesian_to_polar(x, y, r=0.1778) for (x,y) in pos_c])
pos_cn = pos_c.numpy()
pos_cn
#+end_src

#+RESULTS:
: array([[ 0.   ,  0.142],
:        [ 0.142,  0.   ],
:        [ 0.   , -0.142],
:        [-0.142,  0.   ]], dtype=float32)

#+begin_src python
m = multilateration.MultilateratePaired(pos_cn, radius, sr=sr, scale=1000, c=c)
x = 200
out = m.locate(np.array([x, x]), 0)
out

times = x * np.array([[0, 1, -1, 1]]) / sr
weights = torch.tensor([[1, 1, 0, 1]], dtype=torch.float32)
solver = model.TOAToXY(pos_c, learn_c=False)
solver = model.PairwiseTDOAToXY(pos_c)
solver = PairwiseTDOAToXY(pos_c, c=c)
solver = TrilaterationSolver()
sensor_a = torch.tensor(m.sensor_locs[3])
sensor_b = torch.tensor(m.sensor_locs[1])
sensor_origin = torch.tensor(m.sensor_locs[0])

d_a1 = x * m.c / m.sr
d_b1 = x * m.c / m.sr

weight_a = abs(d_a1) / m.radius
weight_b = abs(d_b1) / m.radius
weight_o = abs(d_a1 + d_b1) / (2 * m.radius)

ig = torch.tensor(
    [
        sensor_a[0] * weight_a
        + sensor_b[0] * weight_b
        + sensor_origin[0] * weight_o,
        sensor_a[1] * weight_a
        + sensor_b[1] * weight_b
        + sensor_origin[1] * weight_o,
    ]
)

out2 = solver(sensor_a, sensor_b, sensor_origin, d_a1, d_b1, ig)
print(out, out2)
#+end_src

#+RESULTS:
: (2.6844359309910622e-20, 0.1241899285231357) tensor([6.9698e-11, 1.2419e-01])

#+begin_src python
plt.imshow(m.lag_maps[0][1]); plt.colorbar()
plt.figure()
_ = plt.imshow(m.lag_maps[0][3]); plt.colorbar()
plt.figure()
plt.imshow((m.lag_maps[0][1] == x) + (m.lag_maps[0][3] == x))
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.image.AxesImage at 0x78da3f2430d0>
[[file:./.ob-jupyter/de79dbc3011805e3fd82726bac5290252ba3656d.png]]
[[file:./.ob-jupyter/cf9fd147d13e84f5e4774a855f1d399d509329a3.png]]
[[file:./.ob-jupyter/1a5de219173a07d3ee8fc885efb9a0139fdc64a5.png]]
:END:


#+begin_src python
x = 200
#+end_src

#+RESULTS:
| -1.1950621603418199e-09 | -0.1027606800198555 |


** On scale
To allow gradients to propagate efficiently, we'd like to always be in
(-1, 1) - for that to be the case, we'd probably like to model the TDoA, but
scaled to be approx. in -1, 1.
Here's how we can achieve that:
- assuming a given window size, that would be the theoretical maximum lag at
  the given sample rate
- this leads to a maximum tdoa, which we can use as the scalor

#+begin_src python
sr = 96000
radius = 0.1778
c = 82.0
w = 256
#+end_src

#+begin_src python
# samples * m/s / samp/s
(w / sr)
#+end_src

#+RESULTS:
: 0.0026666666666666666


#+begin_src python
sum([1270, 1270, 1270, 1270, 1350, 1590, 1590, 1590, 1590, 1590, 2190, 1990, 2390, 1990, 1790, 2087, 1590, 2190, 1590, 3190, 1590]) + 2400 / 1.0479

#+end_src

#+RESULTS:
: 39257.29487546522

#+TITLE: Modelling lags
#+AUTHOR: Tim Loderhose
#+EMAIL: tim@loderhose.com
#+DATE: Wednesday, 12 June 2024
#+STARTUP: showall
#+PROPERTY: header-args :exports both :session lags :kernel lm :cache no
:PROPERTIES:
OPTIONS: ^:nil
#+LATEX_COMPILER: xelatex
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [logo, color, author]
#+LATEX_HEADER: \insertauthor
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry}
:END:

* Imports and Environment Variables
:PROPERTIES:
:visibility: folded
:END:

#+name: imports
#+begin_src python
import json
from importlib import reload
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import sounddevice as sd
import soundfile as sf
import torch
import torch.nn as nn
from onset_fingerprinting import (
    calibration,
    detection,
    model,
    multilateration,
    plots,
)
from torch import optim
from torch.nn import functional as F
#+end_src

#+name: env
#+begin_src python
device = "cuda"
#+end_src

* Introduction
I would like to move towards using NNs on windows of time-correlated audio. For
this, I need to be able to find a network architecture which can learn these
temporal relationships between signals. If the network can figure out the lag
between the different channels, then it should be able to learn the physical
model relating those to the location as well.

To this end, I will generate some impulse data for which I know the lags, and
plug in a number of architectures to see which one can learn this challenge.

* Generate data

The simplest version of this problem finds the lags between impulses occuring
in two signals of a length w.
#+begin_src python
def generate_data(w: int, c: int, n: int = 10000, device=None):
    signals = torch.zeros(n, c, w, device=device)
    impulses = torch.randint(0, w, (n, c), device=device)
    # Force some 0s
    impulses[0] = torch.tensor([0] * c)
    impulses[1] = torch.tensor([w // 2] * c)
    impulses[2] = torch.tensor([w - 1] * c)
    # Force the extremes
    z = torch.zeros((c, c), dtype=torch.long)
    for i in range(c):
        z[i, i] = w - 1
    impulses[3 : 3 + c] = z
    signals.scatter_(2, impulses[:, :, None], 1)
    return signals, torch.diff(impulses).to(torch.float32), impulses
#+end_src


* Learning

#+begin_src python
def train(
    x,
    y,
    model,
    lossfun,
    optimizer,
    scheduler,
    num_epochs=3000,
    x_val=None,
    y_val=None,
    patience=None,
    max_norm: float = 1.0,
    print_every: int = 100,
    print_examples: bool = True,
    device=None,
):
    model.to(device)
    x.to(device)
    y.to(device)
    errors = []
    last_loss = torch.inf
    best_model = None
    counter = 0
    for epoch in range(num_epochs):
        optimizer.zero_grad(set_to_none=True)
        pred = model(x)
        error = lossfun(pred, y)
        loss = error.mean()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)
        optimizer.step()
        scheduler.step()
        if x_val is not None:
            with torch.no_grad():
                vp = model(x_val)
                ve = lossfun(vp, y_val)
            errors.append((error.item(), ve.item()))
            if patience is not None:
                if ve < last_loss:
                    last_loss = ve
                    best_model = model
                    counter = 0
                elif counter < patience:
                    counter += 1
                else:
                    print(f"Stopping at epoch {epoch}!")
                    break
        else:
            errors.append(error.item())
        if epoch % print_every == 0:
            print(
                f"Epoch {epoch}, TL"
                f" {loss.item()} {f'VL: {ve.item()}' if x_val is not None else ''}"
            )
    print(f"Epoch {epoch}, Loss {loss.item()}")
    if print_examples:
        print(pred[:10], "\n", y[:10])
    return errors, best_model


def error_analysis(model, tx, ty, timp, n_samp=100):
    tp = model.cpu()(tx.cpu())
    e = F.l1_loss(tp, ty.cpu(), reduction="none").squeeze()
    print(
        f"Mean loss: {e.mean().item():4f}, Median loss:"
        f" {e.median().item():.4f}"
    )
    fig = plt.figure(figsize=(6, 3))
    fig.suptitle(f"First {n_samp} test samples")
    plt.plot(tp[:n_samp].detach().cpu(), label="Predictions")
    plt.plot(ty[:n_samp].cpu(), label="Truth")
    plt.legend()
    if e.ndim == 2:
        e = e.mean(1)
    sortidx = e.argsort()
    fig = plt.figure(figsize=(6, 3))
    ax = fig.add_subplot(111)
    (a,) = ax.plot(e[sortidx].detach(), label="Sorted test errors")
    (b,) = ax.twinx().plot(
        ty.max(1).values.abs().cpu()[sortidx],
        label="Max lag in prediction",
        color="tab:orange",
        alpha=0.7,
    )
    lines = [a, b]
    labels = [line.get_label() for line in lines]
    plt.legend(lines, labels)
    print(
        "Best:",
        ty.cpu()[sortidx][:20, 0],
        "\nWorst:",
        ty.cpu()[sortidx][-20:, 0],
    )
    print(timp[sortidx][-20:])
#+end_src

** 2 channels
Let's start with the simplest version:
: torch.Size([100, 1, 256, 16])
#+begin_src python
w = 256
c = 2
lossfun = F.mse_loss
lr = 0.002 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 2000
print_every = 100

m = model.CNN(w, c - 1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3).to(
    device
)
m = model.RNN(w, c - 1, c, 16, 2, dropout_rate=0.6, rnn_type="GRU", share_input_weights=False).to(device)
# m = model.CNNRNN(
#     w,
#     c - 1,
#     c,
#     layer_sizes=[64],
#     kernel_size=7,
#     n_hidden=16,
#     n_rnn_layers=2,
#     dropout_rate=0.6,
# ).to(device)
x, y, imp = generate_data(w, c, 100, device=device)
tx, ty, timp = generate_data(w, c, 1000, device=device)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 2000)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 12629.1123046875 VL: 10181.0
Epoch 100, TL 11545.8076171875 VL: 9219.76171875
Epoch 200, TL 11286.2021484375 VL: 9117.2451171875
Epoch 300, TL 14095.796875 VL: 8549.4501953125
Epoch 400, TL 563.5429077148438 VL: 840.6907348632812
Epoch 500, TL 245.21942138671875 VL: 142.2216033935547
Epoch 600, TL 113.48372650146484 VL: 132.77940368652344
Epoch 700, TL 70.09120178222656 VL: 49.918060302734375
Epoch 800, TL 75.74190521240234 VL: 39.53986358642578
Epoch 900, TL 16.750106811523438 VL: 59.48220443725586
Epoch 1000, TL 25.51134490966797 VL: 28.22699737548828
Epoch 1100, TL 19.29466438293457 VL: 28.226224899291992
Epoch 1200, TL 9.669910430908203 VL: 31.680273056030273
Epoch 1300, TL 15.852273941040039 VL: 15.18947982788086
Epoch 1400, TL 11.553351402282715 VL: 14.790739059448242
Epoch 1500, TL 5.849761962890625 VL: 19.517799377441406
Epoch 1600, TL 7.055644512176514 VL: 9.491982460021973
Epoch 1700, TL 5.713776111602783 VL: 8.363473892211914
Epoch 1800, TL 3.3988564014434814 VL: 11.77884292602539
Epoch 1900, TL 4.2292327880859375 VL: 11.061144828796387
Epoch 2000, TL 3.8420867919921875 VL: 11.379828453063965
Epoch 2100, TL 4.417903900146484 VL: 9.659210205078125
Epoch 2200, TL 3.8185272216796875 VL: 10.47231388092041
Epoch 2300, TL 4.547299861907959 VL: 11.110060691833496
Epoch 2400, TL 6.243853569030762 VL: 9.828782081604004
Epoch 2500, TL 4.267889976501465 VL: 9.383955955505371
Epoch 2600, TL 10.083755493164062 VL: 11.63809871673584
Epoch 2700, TL 6.622886657714844 VL: 17.820096969604492
Epoch 2800, TL 9.036847114562988 VL: 18.68136978149414
Epoch 2900, TL 15.907943725585938 VL: 11.536725997924805
Stopping at epoch 2907!
Epoch 2907, Loss 8.081771850585938
tensor([[  -2.4707],
        [   0.8019],
        [  -0.5337],
        [-260.3336],
        [ 251.7035],
        [  86.7222],
        [  50.9186],
        [  -3.5616],
        [  -5.5499],
        [ -28.6621]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.],
        [   0.],
        [   0.],
        [-255.],
        [ 255.],
        [  91.],
        [  58.],
        [  -4.],
        [  -3.],
        [ -28.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 2.188316, Median loss: 1.0464
Best: tensor([ -23., -178.,   41.,  -38.,  -63., -205.,  -42.,  -25.,   31.,  -82.,
        -129., -132., -102.,  -59.,  -92.,  -63., -172.,   41.,  -30.,  -15.]) 
Worst: tensor([188.,   2., 204.,  -4., 178., 167.,   0., 221.,   2., 175., 170.,   2.,
          3.,   2., 245., 246.,   2., -58.,  -3.,  -1.])
tensor([[ 58, 246],
        [ 84,  86],
        [ 48, 252],
        [ 35,  31],
        [ 75, 253],
        [  1, 168],
        [ 23,  23],
        [  1, 222],
        [ 99, 101],
        [  1, 176],
        [  1, 171],
        [131, 133],
        [ 11,  14],
        [ 42,  44],
        [  4, 249],
        [  5, 251],
        [ 69,  71],
        [ 58,   0],
        [ 22,  19],
        [104, 103]], device='cuda:0')
#+end_example
[[./.ob-jupyter/d9964bdb83eaa449b0b62fc837f874893dbf7f47.png]]
[[./.ob-jupyter/0aedf47a76e3b5335b919aa39b76c889116de172.png]]
:END:

Although it doesn't always converge, this works! Both RNN and CNN are able to
do this, in fact.

However, the loss on the full test set is still rather high! It looks like it's
primarily very large or very small/nonexisting lags which cause this issue.
Large lags make sense, as they're at the boundary and thus are closer to
require extrapolation.

Notes RNN:
- I needed to have a hidden size of 128+ to be able to learn this properly, at
  2 layers. More layers, and it becomes harder to learn. With smaller sizes, it
  appears that the lag is limited to the hidden size, showing that it is
  related to how far the network can look to find lags.
- Once I added the attention, it worked also with a hidden size of 64
Notes CNN:
- slightly worse at this than the RNN in convergence - it gets better at larger
  numbers of parameters, but then I'd need to tweak more to get it to converge

** 3 channels
Let's see if it can learn 2 lags at the same time. That's one step closer
towards what we need to learn.

#+begin_src python
w = 256
c = 3
lossfun = F.mse_loss
lr = 0.001 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 3000
print_every = 100

# m = model.CNN(
#     w, c-1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
# ).cuda()
m = model.RNN(w, c - 1, c, 16, 2, dropout_rate=0.6, share_input_weights=True).cuda()
device = m.device
x, y, imp = generate_data(w, c, 100, device=device)
tx, ty, timp = generate_data(w, c, 1000, device=device)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 9797.724609375 VL: 10937.0771484375
Epoch 100, TL 4533.7890625 VL: 9037.7470703125
Epoch 200, TL 2950.878173828125 VL: 3322.52294921875
Epoch 300, TL 356.5895080566406 VL: 1074.657470703125
Epoch 400, TL 202.80323791503906 VL: 867.0380859375
Epoch 500, TL 84.18399047851562 VL: 386.94635009765625
Epoch 600, TL 32.605918884277344 VL: 74.24748229980469
Epoch 700, TL 64.31904602050781 VL: 41.493675231933594
Epoch 800, TL 17.088197708129883 VL: 57.716644287109375
Epoch 900, TL 28.063058853149414 VL: 31.811717987060547
Epoch 1000, TL 13.49834156036377 VL: 28.634328842163086
Epoch 1100, TL 15.28337574005127 VL: 26.30498504638672
Epoch 1200, TL 11.294228553771973 VL: 26.616729736328125
Epoch 1300, TL 10.797918319702148 VL: 16.320541381835938
Epoch 1400, TL 7.7080979347229 VL: 15.624723434448242
Epoch 1500, TL 9.873404502868652 VL: 11.996635437011719
Epoch 1600, TL 5.244534969329834 VL: 13.392248153686523
Epoch 1700, TL 4.024059772491455 VL: 9.139055252075195
Epoch 1800, TL 4.523504257202148 VL: 13.074235916137695
Epoch 1900, TL 4.394941806793213 VL: 9.586922645568848
Epoch 2000, TL 4.473787307739258 VL: 9.338714599609375
Epoch 2100, TL 3.0711374282836914 VL: 10.5660400390625
Epoch 2200, TL 3.194096088409424 VL: 7.816829681396484
Epoch 2300, TL 2.5959553718566895 VL: 6.540218353271484
Epoch 2400, TL 2.9732067584991455 VL: 7.469451904296875
Epoch 2500, TL 2.7218360900878906 VL: 7.070628643035889
Epoch 2600, TL 2.3775062561035156 VL: 7.469150066375732
Epoch 2700, TL 2.0485284328460693 VL: 8.085326194763184
Epoch 2800, TL 2.4743940830230713 VL: 9.536794662475586
Epoch 2900, TL 2.2067036628723145 VL: 7.413653373718262
Epoch 2999, Loss 2.2365968227386475
tensor([[-1.8919e+00, -6.3282e-02],
        [ 1.1337e+00, -9.9705e-01],
        [-8.5596e-02, -1.4792e-01],
        [-2.5889e+02,  2.2042e-01],
        [ 2.5255e+02, -2.5264e+02],
        [ 6.9334e-01,  2.5559e+02],
        [-8.9901e+00,  1.6475e+02],
        [ 3.1594e+01, -5.2260e+01],
        [ 5.1377e+01,  3.8554e+01],
        [ 2.3470e+02, -2.6096e+01]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.,    0.],
        [   0.,    0.],
        [   0.,    0.],
        [-255.,    0.],
        [ 255., -255.],
        [   0.,  255.],
        [  -7.,  164.],
        [  32.,  -53.],
        [  51.,   38.],
        [ 236.,  -28.]], device='cuda:0')
#+end_example

Plot results on the test set:
#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 3.067169, Median loss: 1.9193
Best: tensor([-132.,   95.,    8.,   56.,    8., -208.,  -38.,   -2.,   16.,   43.,
          29., -164.,  -18.,  193.,   14.,   21.,  -48.,    6., -104.,  -59.]) 
Worst: tensor([ 37., 190., 255.,   5.,   0.,   4.,   5.,  -6., -60., 121., -26.,  31.,
        -81.,  73.,  71.,  59.,  43., 119.,   7.,  76.])
tensor([[  9,  46,  31],
        [ 18, 208, 254],
        [  0, 255,   0],
        [ 33,  38, 255],
        [246, 246, 191],
        [215, 219, 151],
        [220, 225, 170],
        [252, 246, 237],
        [163, 103, 254],
        [133, 254, 178],
        [146, 120, 255],
        [222, 253, 254],
        [237, 156, 255],
        [182, 255, 114],
        [184, 255, 242],
        [138, 197, 255],
        [204, 247, 253],
        [ 71, 190, 255],
        [248, 255,  94],
        [165, 241, 255]], device='cuda:0')
#+end_example
[[./.ob-jupyter/f68729cc5000a20cf33bed2d4bf8fb5f0a6d8c10.png]]
[[./.ob-jupyter/9b6d49aadc3afb461346e114ee8a746b8efd775b.png]]
:END:



#+RESULTS:
#+begin_example
Epoch 0, TL 12356.1396484375 VL: 11654.6298828125
Epoch 100, TL 7621.8505859375 VL: 8922.38671875
Epoch 200, TL 4692.791015625 VL: 4432.2724609375
Epoch 300, TL 3617.2890625 VL: 3960.30810546875
Epoch 400, TL 2975.39501953125 VL: 3386.6318359375
Epoch 500, TL 1673.6810302734375 VL: 1782.166015625
Epoch 600, TL 601.9627075195312 VL: 1070.9232177734375
Epoch 700, TL 438.4246826171875 VL: 714.2683715820312
Epoch 800, TL 252.6402130126953 VL: 660.646240234375
Epoch 900, TL 208.8948211669922 VL: 413.8019714355469
Epoch 1000, TL 163.1772918701172 VL: 311.8202819824219
Epoch 1100, TL 128.8693389892578 VL: 320.7862548828125
Epoch 1200, TL 112.0771255493164 VL: 292.47454833984375
Epoch 1300, TL 64.62334442138672 VL: 387.5838317871094
Epoch 1400, TL 86.0174560546875 VL: 215.64512634277344
Epoch 1500, TL 78.3893051147461 VL: 212.8132781982422
Epoch 1600, TL 58.031585693359375 VL: 217.86044311523438
Epoch 1700, TL 39.056209564208984 VL: 220.63156127929688
Epoch 1800, TL 32.34804916381836 VL: 189.09466552734375
Epoch 1900, TL 24.82532501220703 VL: 196.97238159179688
Epoch 2000, TL 24.550607681274414 VL: 175.1767120361328
Epoch 2100, TL 24.274049758911133 VL: 187.39707946777344
Epoch 2200, TL 15.048283576965332 VL: 170.42678833007812
Epoch 2300, TL 14.50401782989502 VL: 155.8015594482422
Epoch 2400, TL 14.956853866577148 VL: 164.1660919189453
Epoch 2500, TL 13.131484985351562 VL: 160.4081573486328
Epoch 2600, TL 11.323251724243164 VL: 155.822998046875
Epoch 2700, TL 11.416837692260742 VL: 158.9982147216797
Epoch 2800, TL 13.83969497680664 VL: 150.00393676757812
Epoch 2900, TL 9.069437980651855 VL: 163.32676696777344
Epoch 2999, Loss 11.212181091308594
tensor([[  -0.2927,   -3.0392],
        [  -0.7276,   -2.8642],
        [   0.6274,    0.3188],
        [-252.9344,   -1.5700],
        [ 256.4276, -252.8566],
        [   5.4303,  249.7804],
        [ 129.4544,  -98.4681],
        [-132.0554,   46.2599],
        [ -14.3961,   92.2857],
        [ -64.0335,    7.8503]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.,    0.],
        [   0.,    0.],
        [   0.,    0.],
        [-255.,    0.],
        [ 255., -255.],
        [   0.,  255.],
        [ 126.,  -96.],
        [-135.,   46.],
        [ -12.,   82.],
        [ -67.,    9.]], device='cuda:0')
#+end_example

#+begin_example
Mean loss: 9.929891, Median loss: 5.3763
Best: tensor([-236.,   86.,    0.,   -8.,   27.,  163.,   71.,  229.,   50.,  126.,
          82.,  -45.,  163.,  128.,    5.,   30.,  -27., -116.,   49.,  176.]) 
Worst: tensor([-178.,  123.,  159.,  162.,  152.,  184.,  195.,  176.,  158.,  178.,
         160.,  150.,  175.,  184.,  182.,  184.,  210.,  201.,  197.,  205.])
tensor([[202,  24,  45],
        [ 91, 214,  98],
        [ 86, 245,  90],
        [ 15, 177,  25],
        [ 51, 203,  55],
        [  7, 191,   6],
        [  5, 200,   2],
        [ 64, 240,  43],
        [ 37, 195,  22],
        [ 10, 188,  16],
        [ 87, 247, 106],
        [ 60, 210,  67],
        [ 40, 215,  29],
        [ 22, 206,  18],
        [ 61, 243,  79],
        [ 58, 242,  44],
        [ 16, 226,   3],
        [ 15, 216,  23],
        [ 51, 248,  65],
        [ 43, 248,  27]], device='cuda:0')
#+end_example
[[./.ob-jupyter/758e66ff4cd77bc94a894c5f05d9ba3ddd4ef35c.png]]
[[./.ob-jupyter/7fcba408499a538dea4778611957b1d615e06577.png]]

Error analysis:
The MSE is still very high on this, possibly because we overfit, having lowered
the dropout.
let's see at which values of lags the model struggles most:
#+begin_src python
e = (tp - ty.cpu()).square().sum(1)
sortidx = e.argsort()
print("Best:\n",ty.cpu()[sortidx][:10].T, "\nWorst:\n", ty.cpu()[sortidx][-10:].T)
#+end_src

#+RESULTS:
: Best:
:  tensor([[ -55., -136.,  -55.,  119., -185.,   88., -182.,  206.,  104., -106.],
:         [ 105.,  115.,  -46., -141.,   88., -140.,  122., -101., -169.,   58.]]) 
: Worst:
:  tensor([[ 254.,  244.,  246.,    5.,  -89.,  240.,   29.,  -76., -187.,  -45.],
:         [ -76.,  -31.,  -53.,    0.,  166.,  -16.,  158.,  201.,  251.,  233.]])

There are somewhat more extreme values at the large errors, but in general I
think it's just overfit.

** Non-binary impulses
This is a contrived case where we learn impulses, but in reality we'll never
have such data. Let's transform these into gaussian impulses for a further
step, and check whether it still works as well.

#+begin_src python
def transform_impulse1(x, n=11, ramp_up: int = 0):
    c = x.shape[1]
    ls = torch.linspace(-3 * np.e, 0, n, device=x.device)
    exp = torch.exp(ls)
    if ramp_up > 0:
        exp[-ramp_up:] = torch.exp(
            torch.linspace(ls[-ramp_up], 2 * -np.e, ramp_up, device=x.device)
        )
    return F.conv1d(F.pad(x, (n - 1, 0)), exp.repeat(c, 1, 1), groups=c)
#+end_src

#+begin_src python
w = 256
c = 3
lossfun = F.mse_loss
lr = 0.001 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 3000
print_every = 100

m = model.CNN(
    w, c-1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
).to(device)
m = model.CNNRNN(
    w,
    c-1,
    c,
    layer_sizes=[8],
    kernel_size=2,
    n_hidden=128,
    n_rnn_layers=1,
    dropout_rate=0.6,
).to(device)
m = model.RNN(w, c - 1, c, 64, 2, dropout_rate=0.5).to(device)
x, y, imp = generate_data(w, c, 100, device=device)
x = transform_impulse1(x, 200, 20)
tx, ty, timp = generate_data(w, c, 1000, device=device)
tx = transform_impulse1(tx, 200, 20)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
/home/tim/projects/onset-fingerprinting/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
Epoch 0, TL 11471.6171875 VL: 10763.947265625
Epoch 100, TL 6300.701171875 VL: 4763.0048828125
Epoch 200, TL 1386.6453857421875 VL: 1241.863037109375
Epoch 300, TL 342.417724609375 VL: 723.0066528320312
Epoch 400, TL 250.0272216796875 VL: 510.8902893066406
Epoch 500, TL 55.00023651123047 VL: 379.0447998046875
Epoch 600, TL 57.27154541015625 VL: 424.559326171875
Epoch 700, TL 43.54613494873047 VL: 150.87136840820312
Epoch 800, TL 31.350616455078125 VL: 146.08096313476562
Epoch 900, TL 37.63465881347656 VL: 210.27972412109375
Epoch 1000, TL 59.4703254699707 VL: 61.12222671508789
Epoch 1100, TL 29.809720993041992 VL: 64.12410736083984
Epoch 1200, TL 15.877347946166992 VL: 97.62782287597656
Epoch 1300, TL 14.474164962768555 VL: 87.64909362792969
Epoch 1400, TL 13.176837921142578 VL: 86.94642639160156
Epoch 1500, TL 7.699976444244385 VL: 81.4412841796875
Epoch 1600, TL 5.240980625152588 VL: 65.48567199707031
Epoch 1700, TL 9.369585037231445 VL: 61.48301315307617
Epoch 1800, TL 11.597272872924805 VL: 55.46167755126953
Epoch 1900, TL 11.893485069274902 VL: 46.76387405395508
Epoch 2000, TL 5.205259323120117 VL: 56.14391326904297
Epoch 2100, TL 6.685842037200928 VL: 60.57660675048828
Epoch 2200, TL 2.979496955871582 VL: 47.39455795288086
Epoch 2300, TL 2.6737499237060547 VL: 52.31924819946289
Epoch 2400, TL 2.32865309715271 VL: 56.26995849609375
Epoch 2500, TL 2.1595070362091064 VL: 60.19451904296875
Epoch 2600, TL 2.235826015472412 VL: 53.08357238769531
Stopping at epoch 2637!
Epoch 2637, Loss 2.036637306213379
tensor([[  62.6798,  141.3915],
        [  68.4154, -164.8867],
        [  53.9853,   59.8275],
        [  31.9432, -179.9884],
        [ 173.9814,   21.4797],
        [  46.0552,  -49.5891],
        [ 123.8873, -126.6256],
        [ -19.2127,   14.2151],
        [-150.5007,  182.4794],
        [ -93.4469, -122.0795]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[  58.,  143.],
        [  65., -163.],
        [  55.,   59.],
        [  32., -180.],
        [ 175.,   20.],
        [  49.,  -52.],
        [ 123., -126.],
        [ -15.,   12.],
        [-149.,  181.],
        [ -93., -122.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 3.942275, Median loss: 1.8895
Best: tensor([ 69.,  35.,  56., -40.,  64.,  52.,  47., 129., -76., 151.,  79.,  -5.,
         55.,  40., 132., -50., -20.,  53., -41.,  31.]) 
Worst: tensor([ -62., -122.,   -1., -226.,   -1., -201., -209.,  -70., -223.,  -86.,
        -229.,  -74.,    3.,  -82.,    3.,  -90.,   -2.,  -89.,    0.,    2.])
tensor([[ 56, 118,  88],
        [ 18, 140, 115],
        [ 69,  70, 173],
        [ 18, 244, 174],
        [104, 105, 189],
        [  8, 209, 191],
        [ 11, 220, 173],
        [ 67, 137, 118],
        [ 25, 248, 224],
        [ 10,  96,  79],
        [ 22, 251, 196],
        [ 33, 107,  73],
        [121, 118, 158],
        [ 21, 103,  81],
        [ 59,  56, 151],
        [  8,  98,  69],
        [ 71,  73,  68],
        [  3,  92,  69],
        [ 42,  42, 199],
        [ 29,  27, 110]], device='cuda:0')
#+end_example
[[./.ob-jupyter/a8aa1a861fad67c9f96828b56d97206fc25181dc.png]]
[[./.ob-jupyter/7d0c1568492492549fec03849e787f041c31e2d2.png]]
:END:

Nice, it performs pretty much the same!

*** Additional changes
This is still very idealized - here are more things we can do to make it look
more real:
- peaks at different amplitudes
- modulate with sine wave
- add noise


Note: frequencies should be the same in each of the channels, phase could be
slightly shifted, but very little. The sine needs to start at the impulse in
each case, so currently this is wrong.
#+begin_src python
def transform_impulse2(
    x, imp, random_phase: bool = False, noise_std=0, sr=96000
):
    n, c, w = x.shape
    ls = torch.linspace(0, x.shape[-1] / sr, x.shape[-1], device=x.device)
    phase = (
        torch.rand(x.shape[0], x.shape[1], 1, device=x.device) * 0.1 * np.pi
        if random_phase
        else 0
    )
    f = torch.randint(300, 1000, (x.shape[0], 1, 1), device=x.device).expand(
        n, c, 1
    )
    sin = torch.sin(2 * np.pi * ls[None, None, :] * f + phase)
    for i in range(len(x)):
        for j in range(c):
            k = w - imp[i, j]
            x[i, j, imp[i, j] :] *= sin[i, j, :k]
    x += torch.randn(x.shape, device=x.device) * noise_std
    return x
#+end_src

#+begin_src python
x = transform_impulse2(x, imp, True, 0.001)
tx = transform_impulse2(tx, timp, True, 0.001)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x,
    y,
    m.to(device),
    lossfun,
    optimizer,
    scheduler,
    3000,
    tx[:100],
    ty[:100],
    500,
)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 38.41012191772461 VL: 11656.9599609375
Epoch 100, TL 16.59128189086914 VL: 153.88595581054688
Epoch 200, TL 22.921138763427734 VL: 109.77005004882812
Epoch 300, TL 60.49607467651367 VL: 96.41871643066406
Epoch 400, TL 11399.8642578125 VL: 10716.013671875
Epoch 500, TL 3034.529296875 VL: 3443.92236328125
Epoch 600, TL 689.79443359375 VL: 455.908203125
Epoch 700, TL 72.95342254638672 VL: 165.76028442382812
Stopping at epoch 732!
Epoch 732, Loss 80.4583511352539
tensor([[  61.4558,  144.0829],
        [  48.9084, -145.4959],
        [  49.2660,   55.4530],
        [  22.9640, -167.7405],
        [ 166.9901,   23.7873],
        [  45.7351,  -44.0062],
        [ 110.5431, -113.2652],
        [ -17.7397,    7.5596],
        [-141.3242,  174.2570],
        [-105.1589, -120.3260]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[  58.,  143.],
        [  65., -163.],
        [  55.,   59.],
        [  32., -180.],
        [ 175.,   20.],
        [  49.,  -52.],
        [ 123., -126.],
        [ -15.,   12.],
        [-149.,  181.],
        [ -93., -122.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 8.697659, Median loss: 7.2153
Best: tensor([  81., -133.,  -21., -149.,   37.,  -50.,   44.,  -51., -194.,   36.,
         -82., -117.,   -8., -165.,  142.,  133.,  160.,   47.,  -70.,  -55.]) 
Worst: tensor([153., -16.,  13., -25., -11., -15., -20., -24., -18., -32., -24.,  -6.,
        -14.,  11., -21.,  11., -18., 228., 196.,  -2.])
tensor([[186,  33,   2],
        [  9,  25,  26],
        [141, 128, 118],
        [ 29,  54, 162],
        [  8,  19,  37],
        [ 59,  74, 160],
        [ 13,  33, 162],
        [ 13,  37, 124],
        [ 38,  56, 175],
        [ 38,  70,  60],
        [ 19,  43, 106],
        [ 24,  30,  84],
        [ 45,  59, 125],
        [ 69,  58,  46],
        [ 30,  51, 129],
        [ 87,  76,  70],
        [  2,  20,  62],
        [254,  26,  17],
        [208,  12,   8],
        [ 71,  73,  68]], device='cuda:0')
#+end_example
[[./.ob-jupyter/8c75740c54df5a4ef929e0528f428af74278893a.png]]
[[./.ob-jupyter/471d27d84a130b38e16a2cb2baf00a9975c3c161.png]]
:END:

#+begin_src python
m = model.CNN(
    w, c - 1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
).to(device)
m = model.CNNRNN(
    w,
    c-1,
    c,
    layer_sizes=[8],
    kernel_size=2,
    n_hidden=128,
    n_rnn_layers=1,
    dropout_rate=0.6,
).to(device)

m = model.RNN(w, c - 1, c, 64, 2, dropout_rate=0.5).to(device)
x, y, imp = generate_data(w, c, 100, device=device)
x = transform_impulse1(x, 200, 20)
x = transform_impulse2(x, imp, True, 0.001)
tx, ty, timp = generate_data(w, c, 1000, device=device)
tx = transform_impulse1(tx, 200, 20)
tx = transform_impulse2(tx, timp, True, 0.001)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
/home/tim/projects/onset-fingerprinting/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
Epoch 0, TL 10969.625 VL: 12308.033203125
Epoch 100, TL 10749.765625 VL: 12646.4658203125
Epoch 200, TL 4539.97216796875 VL: 5462.40478515625
Epoch 300, TL 624.5994873046875 VL: 1375.3243408203125
Epoch 400, TL 196.093505859375 VL: 1062.148681640625
Epoch 500, TL 169.95042419433594 VL: 957.1149291992188
Epoch 600, TL 107.84603881835938 VL: 1028.6390380859375
Epoch 700, TL 121.10030364990234 VL: 681.8544921875
Epoch 800, TL 66.1226806640625 VL: 788.4007568359375
Epoch 900, TL 53.90553665161133 VL: 717.099853515625
Epoch 1000, TL 19.31464958190918 VL: 922.7158203125
Epoch 1100, TL 63.47445297241211 VL: 751.4854736328125
Epoch 1200, TL 15.681598663330078 VL: 738.298095703125
Epoch 1300, TL 38.02914047241211 VL: 744.9343872070312
Epoch 1400, TL 11.976242065429688 VL: 736.5288696289062
Epoch 1500, TL 15.60149097442627 VL: 694.3289184570312
Epoch 1600, TL 11.260603904724121 VL: 674.05029296875
Epoch 1700, TL 14.834748268127441 VL: 657.7704467773438
Epoch 1800, TL 8.437795639038086 VL: 640.6726684570312
Stopping at epoch 1821!
Epoch 1821, Loss 13.305294036865234
tensor([[  77.6080, -134.4793],
        [ 163.3905,  -10.0579],
        [  23.3562,  -91.4870],
        [  14.8176,   32.2623],
        [ -55.5569, -159.4844],
        [-133.6727,  -48.5318],
        [ -54.7022, -147.1461],
        [  36.2426,  -21.0591],
        [-145.1990,  158.6829],
        [  -1.7074,  -85.3992]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[  81., -131.],
        [ 165.,  -16.],
        [  26.,  -93.],
        [  14.,   31.],
        [ -56., -155.],
        [-133.,  -43.],
        [ -55., -142.],
        [  45.,  -27.],
        [-152.,  164.],
        [  -2.,  -83.]], device='cuda:0')
#+end_example


#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 14.786790, Median loss: 9.8132
Best: tensor([ -71.,  156.,  -52.,  -76.,  -22.,   55.,   -2.,  165.,  136.,  100.,
          91.,  169.,  -53.,  -23.,   58., -120., -127.,  -88.,  -96.,  -20.]) 
Worst: tensor([-203., -194., -103.,  144., -217., -187.,   -6.,  -49.,   46.,  -91.,
         -88.,   12., -104.,  -93., -126., -100.,  -98., -103., -122., -106.])
tensor([[ 49, 252, 152],
        [  8, 202, 241],
        [138, 241,  17],
        [244, 100,   6],
        [  0, 217,  16],
        [ 66, 253,  25],
        [235, 241, 106],
        [192, 241,  14],
        [ 65,  19,  65],
        [158, 249,  64],
        [162, 250,   3],
        [ 42,  30,  36],
        [146, 250, 177],
        [161, 254, 159],
        [121, 247,   0],
        [141, 241,  18],
        [155, 253,  14],
        [141, 244, 107],
        [127, 249, 152],
        [137, 243,   7]], device='cuda:0')
#+end_example
[[./.ob-jupyter/610a0161dd8a5a4e1b125dc97f808e91eadb322f.png]]
[[./.ob-jupyter/944c8cfcda49bfc559531f200e50b2b8f4fe07f7.png]]
:END:


*** Making the data even more real

In its current iteration, the data models an impulse of the fundamental - but
as far as the modelling problem goes, it's different from what we'll see in
realtime: There, we'll always start the window from the first onset on. In the
current data, the first onset may start anywhere.

Let's adapt the data in such a way that our first onset is always close to the
beginning of the buffers.
#+begin_src python
def generate_data2(w: int, c: int, n: int = 10000, max_shift=10, device=None):
    signals = torch.zeros(n, c, w, device=device)
    impulses = torch.randint(0, w - max_shift, (n, c), device=device)
    mini = impulses.min(dim=1, keepdim=True).values
    impulses -= mini
    impulses += torch.maximum(
        torch.tensor(0, device=device),
        torch.minimum(
            w - impulses.max(dim=1, keepdim=True).values - 1,
            torch.randint(max_shift, (len(impulses), 1), device=device),
        ),
    )
    # Force some 0s
    impulses[0] = torch.tensor([0] * c)
    impulses[1] = torch.tensor([w // 2] * c)
    impulses[2] = torch.tensor([w - 1] * c)
    # Force the extremes
    z = torch.zeros((c, c), dtype=torch.long)
    for i in range(c):
        z[i, i] = w - 1
    impulses[3 : 3 + c] = z
    signals.scatter_(2, impulses[:, :, None], 1)
    return signals, torch.diff(impulses).to(torch.float32), impulses
#+end_src


#+begin_src python
w = 256
c = 3
lossfun = F.mse_loss
lr = 0.001 * (5 if lossfun == F.mse_loss else 1)
num_epochs = 2000
print_every = 100

m = model.CNN(
    w, c - 1, c, layer_sizes=[8, 8], kernel_size=8, dropout_rate=0.9
).to(device)
m = model.RNN(
    w,
    c - 1,
    c,
    16,
    1,
    dropout_rate=0.6,
    rnn_type="GRU",
    share_input_weights=True,
).to(device)
# m = model.CNNRNN(
#     w,
#     c - 1,
#     c,
#     layer_sizes=[9, 18, 27],
#     kernel_size=3,
#     n_hidden=64,
#     n_rnn_layers=2,
#     dropout_rate=0.8,
#     groups=1,
# ).to(device)
x, y, imp = generate_data2(w, c, 1000, 100, device=device)
tx, ty, timp = generate_data2(w, c, 1000, 100, device=device)
optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer, num_epochs / 10
)
errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
x = transform_impulse1(x, 200, 20)
tx = transform_impulse1(tx, 200, 20)
errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
x = transform_impulse2(x, imp, True, 0.01)
tx = transform_impulse2(tx, timp, True, 0.01)
errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 4395.76611328125 VL: 5299.62255859375
Epoch 100, TL 3365.845703125 VL: 4822.96044921875
Epoch 200, TL 2772.103271484375 VL: 3702.37548828125
Epoch 300, TL 3322.334228515625 VL: 4290.53662109375
Epoch 400, TL 3812.298828125 VL: 3554.98876953125
Epoch 500, TL 2912.2646484375 VL: 2528.25927734375
Epoch 600, TL 1182.7371826171875 VL: 1790.157470703125
Epoch 700, TL 1227.01611328125 VL: 1872.30615234375
Epoch 800, TL 1848.1175537109375 VL: 1960.5078125
Epoch 900, TL 970.9756469726562 VL: 1661.15478515625
Epoch 1000, TL 518.984619140625 VL: 992.01708984375
Epoch 1100, TL 809.7820434570312 VL: 1747.26806640625
Epoch 1200, TL 2681.91357421875 VL: 2803.46337890625
Epoch 1300, TL 477.33197021484375 VL: 802.52294921875
Epoch 1400, TL 267.9732666015625 VL: 652.127197265625
Epoch 1500, TL 286.6626892089844 VL: 884.8186645507812
Epoch 1600, TL 854.4407958984375 VL: 855.2654418945312
Epoch 1700, TL 231.8495635986328 VL: 721.853271484375
Epoch 1800, TL 144.84832763671875 VL: 460.5245361328125
Epoch 1900, TL 169.9160919189453 VL: 735.3161010742188
Epoch 2000, TL 366.41845703125 VL: 978.0071411132812
Epoch 2100, TL 146.53395080566406 VL: 478.1092224121094
Epoch 2200, TL 105.03839874267578 VL: 330.9482421875
Epoch 2300, TL 115.1164779663086 VL: 526.8109741210938
Epoch 2400, TL 149.66419982910156 VL: 749.67724609375
Epoch 2500, TL 174.15863037109375 VL: 391.32769775390625
Epoch 2600, TL 74.22200775146484 VL: 268.6869812011719
Epoch 2700, TL 72.20063018798828 VL: 414.69439697265625
Epoch 2800, TL 97.6591796875 VL: 598.396484375
Epoch 2900, TL 68.07989501953125 VL: 290.2934875488281
Epoch 2999, Loss 51.260860443115234
tensor([[  10.1366,  -17.9054],
        [  13.1774,  -13.3129],
        [  12.9529,  -13.0401],
        [-173.3324,   17.5262],
        [ 157.5206, -155.4530],
        [ -22.7140,  177.0232],
        [  70.3581,  -46.2313],
        [  44.1151, -105.5530],
        [ 122.4708,  -89.5229],
        [  31.2111,  -75.7051]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.,    0.],
        [   0.,    0.],
        [   0.,    0.],
        [-255.,    0.],
        [ 255., -255.],
        [   0.,  255.],
        [  80.,  -49.],
        [  40., -104.],
        [ 128.,  -94.],
        [  33.,  -80.]], device='cuda:0')
Epoch 0, TL 3757.65576171875 VL: 3640.633056640625
Epoch 100, TL 247.66635131835938 VL: 409.28961181640625
Epoch 200, TL 211.8089141845703 VL: 291.97784423828125
Epoch 300, TL 51.52690124511719 VL: 170.4066162109375
Epoch 400, TL 20.654159545898438 VL: 99.1829605102539
Epoch 500, TL 39.93817138671875 VL: 88.76754760742188
Epoch 600, TL 74.1521224975586 VL: 166.62974548339844
Epoch 700, TL 30.708261489868164 VL: 65.65766906738281
Epoch 800, TL 8.916840553283691 VL: 43.72679901123047
Epoch 900, TL 31.219749450683594 VL: 31.562416076660156
Epoch 1000, TL 10.731572151184082 VL: 60.79820251464844
Epoch 1100, TL 8.798493385314941 VL: 25.034931182861328
Epoch 1200, TL 4.425315856933594 VL: 14.026777267456055
Epoch 1300, TL 5.048941135406494 VL: 13.20430850982666
Epoch 1400, TL 17.053970336914062 VL: 29.951086044311523
Epoch 1500, TL 5.24343729019165 VL: 13.691798210144043
Epoch 1600, TL 3.1189658641815186 VL: 9.197158813476562
Epoch 1700, TL 6.30896520614624 VL: 7.787571907043457
Epoch 1800, TL 15.738643646240234 VL: 19.0738582611084
Epoch 1900, TL 7.203464031219482 VL: 7.392098903656006
Epoch 2000, TL 2.2224698066711426 VL: 5.900872707366943
Epoch 2100, TL 3.703397035598755 VL: 4.962874412536621
Epoch 2200, TL 9.485461235046387 VL: 16.46314239501953
Epoch 2300, TL 2.431313991546631 VL: 6.579531192779541
Epoch 2400, TL 1.9502060413360596 VL: 4.203733921051025
Epoch 2500, TL 2.643656015396118 VL: 6.293785095214844
Epoch 2600, TL 4.755863666534424 VL: 22.464324951171875
Epoch 2700, TL 4.248551845550537 VL: 4.106677532196045
Epoch 2800, TL 1.663733720779419 VL: 2.814873695373535
Epoch 2900, TL 2.257847309112549 VL: 3.483154773712158
Epoch 2999, Loss 9.530533790588379
tensor([[  -2.8574,    1.1075],
        [   0.8431,    0.9241],
        [  -5.6148,   -1.9003],
        [-253.5990,   -1.0545],
        [ 251.6201, -247.6473],
        [  -7.9750,  246.4797],
        [  82.5954,  -50.0517],
        [  36.5455, -101.0688],
        [ 131.9486,  -92.9606],
        [  34.7109,  -80.0628]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.,    0.],
        [   0.,    0.],
        [   0.,    0.],
        [-255.,    0.],
        [ 255., -255.],
        [   0.,  255.],
        [  80.,  -49.],
        [  40., -104.],
        [ 128.,  -94.],
        [  33.,  -80.]], device='cuda:0')
Epoch 0, TL 106.94245910644531 VL: 99.25122833251953
Epoch 100, TL 10.359472274780273 VL: 21.093120574951172
Epoch 200, TL 6.979597091674805 VL: 17.06334114074707
Epoch 300, TL 6.004084587097168 VL: 15.146120071411133
Epoch 400, TL 12.52808666229248 VL: 16.590269088745117
Epoch 500, TL 6.083004951477051 VL: 11.449847221374512
Epoch 600, TL 4.390475273132324 VL: 10.803228378295898
Epoch 700, TL 4.0955634117126465 VL: 12.54408073425293
Epoch 800, TL 5.846721172332764 VL: 23.0767822265625
Epoch 900, TL 6.763631820678711 VL: 7.676110744476318
Epoch 1000, TL 3.189301013946533 VL: 5.618921279907227
Epoch 1100, TL 5.026641845703125 VL: 5.327602386474609
Epoch 1200, TL 6.647042274475098 VL: 7.531866073608398
Epoch 1300, TL 4.106977462768555 VL: 5.394028663635254
Epoch 1400, TL 2.40857195854187 VL: 4.836437702178955
Epoch 1500, TL 3.81868052482605 VL: 3.960578441619873
Epoch 1600, TL 4.547883987426758 VL: 9.753561973571777
Epoch 1700, TL 3.478538751602173 VL: 4.64895486831665
Epoch 1800, TL 1.8218472003936768 VL: 4.345370769500732
Epoch 1900, TL 2.1438331604003906 VL: 5.599161148071289
Epoch 2000, TL 3.403980255126953 VL: 10.333402633666992
Epoch 2100, TL 3.355443000793457 VL: 3.6203765869140625
Epoch 2200, TL 1.5254161357879639 VL: 2.8843836784362793
Epoch 2300, TL 2.344771146774292 VL: 2.935321569442749
Epoch 2400, TL 2.844273567199707 VL: 10.029642105102539
Epoch 2500, TL 1.3621636629104614 VL: 3.4204516410827637
Epoch 2600, TL 1.212609887123108 VL: 1.9826327562332153
Epoch 2700, TL 2.069546937942505 VL: 2.834421396255493
Epoch 2800, TL 5.372961521148682 VL: 3.4183897972106934
Epoch 2900, TL 1.7085667848587036 VL: 2.390336513519287
Epoch 2999, Loss 1.0286846160888672
tensor([[-5.6807e-01, -4.9543e-01],
        [ 5.8342e-01,  9.4363e-01],
        [-2.1604e-01,  4.6893e-01],
        [-2.5363e+02,  4.0343e-02],
        [ 2.5675e+02, -2.5548e+02],
        [-2.4753e+00,  2.5302e+02],
        [ 8.1115e+01, -4.9502e+01],
        [ 4.0290e+01, -1.0284e+02],
        [ 1.2700e+02, -9.2850e+01],
        [ 3.2659e+01, -7.8642e+01]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.,    0.],
        [   0.,    0.],
        [   0.,    0.],
        [-255.,    0.],
        [ 255., -255.],
        [   0.,  255.],
        [  80.,  -49.],
        [  40., -104.],
        [ 128.,  -94.],
        [  33.,  -80.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 6.774760, Median loss: 4.7079
Best: tensor([ 20.,  80.,  10., -34.,  36.,  21.,  45.,  62.,  45.,   1., -36.,  25.,
         17.,  23.,  23., -48.,  53.,  17.,   7.,  11.]) 
Worst: tensor([ 144., -107.,  101.,  -89.,  131., -122., -152.,   -7., -109., -109.,
        -108.,  -38.,  133.,  -98.,  -60., -113., -106., -120., -130.,  144.])
tensor([[ 82, 226, 125],
        [200,  93, 100],
        [ 79, 180,  31],
        [158,  69,  31],
        [ 19, 150,  95],
        [150,  28,  15],
        [201,  49, 154],
        [  8,   1, 132],
        [203,  94,  73],
        [201,  92,  64],
        [169,  61,  34],
        [205, 167,  89],
        [ 98, 231, 135],
        [203, 105,  81],
        [136,  76,   0],
        [169,  56,  33],
        [158,  52,  19],
        [218,  98, 237],
        [230, 100,  95],
        [ 96, 240, 174]], device='cuda:0')
#+end_example
[[./.ob-jupyter/d914becde805d32c34eb8ec065320a3ff22f7dc3.png]]
[[./.ob-jupyter/4589c41dc71f8d42729d0dbfc158c589e7c56273.png]]
:END:

** Real Data


* Pre-training
Start with impulse data, and epoch-by-epoch morph it into something looking
more like a real signal.



* Idea
Random tone generator based on FM synthesis or just adding different modulated
sines with a huge space. Then feedback the system by saying like/dislike on
single tones to find a space of settings which are pleasing to the ear.

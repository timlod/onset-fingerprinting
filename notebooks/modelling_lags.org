#+TITLE: Modelling lags
#+AUTHOR: Tim Loderhose
#+EMAIL: tim@loderhose.com
#+DATE: Wednesday, 12 June 2024
#+STARTUP: showall
#+PROPERTY: header-args :exports both :session lags :kernel lm :cache no
:PROPERTIES:
OPTIONS: ^:nil
#+LATEX_COMPILER: xelatex
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [logo, color, author]
#+LATEX_HEADER: \insertauthor
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry}
:END:

* Imports and Environment Variables
:PROPERTIES:
:visibility: folded
:END:

#+name: imports
#+begin_src python
import json
from importlib import reload
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import sounddevice as sd
import soundfile as sf
import torch
import torch.nn as nn
from onset_fingerprinting import (
    calibration,
    detection,
    model,
    multilateration,
    plots,
)
from torch import optim
from torch.nn import functional as F
#+end_src

#+name: env
#+begin_src python
device = "cuda"
#+end_src

* Introduction
I would like to move towards using NNs on windows of time-correlated audio. For
this, I need to be able to find a network architecture which can learn these
temporal relationships between signals. If the network can figure out the lag
between the different channels, then it should be able to learn the physical
model relating those to the location as well.

To this end, I will generate some impulse data for which I know the lags, and
plug in a number of architectures to see which one can learn this challenge.

* Generate data

The simplest version of this problem finds the lags between impulses occuring
in two signals of a length w.
#+begin_src python
def generate_data(w: int, c: int, n: int = 10000, device=None):
    signals = torch.zeros(n, c, w, device=device)
    impulses = torch.randint(0, w, (n, c), device=device)
    # Force some 0s
    impulses[0] = torch.tensor([0] * c)
    impulses[1] = torch.tensor([w // 2] * c)
    impulses[2] = torch.tensor([w - 1] * c)
    # Force the extremes
    z = torch.zeros((c, c), dtype=torch.long)
    for i in range(c):
        z[i, i] = w - 1
    impulses[3 : 3 + c] = z
    signals.scatter_(2, impulses[:, :, None], 1)
    return signals, torch.diff(impulses).to(torch.float32), impulses
#+end_src


* Learning

#+begin_src python
def train(
    x,
    y,
    model,
    lossfun,
    optimizer,
    scheduler,
    num_epochs=3000,
    x_val=None,
    y_val=None,
    patience=None,
    max_norm: float = 1.0,
    print_every: int = 100,
    print_examples: bool = True,
    device=None,
):
    model.to(device)
    x.to(device)
    y.to(device)
    errors = []
    last_loss = torch.inf
    best_model = None
    counter = 0
    for epoch in range(num_epochs):
        optimizer.zero_grad(set_to_none=True)
        pred = model(x)
        error = lossfun(pred, y)
        loss = error.mean()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)
        optimizer.step()
        scheduler.step()
        if x_val is not None:
            with torch.no_grad():
                vp = model(x_val)
                ve = lossfun(vp, y_val)
            errors.append((error.item(), ve.item()))
            if patience is not None:
                if ve < last_loss:
                    last_loss = ve
                    best_model = {
                        k: v.clone() for k, v in model.state_dict().items()
                    }
                    counter = 0
                elif counter < patience:
                    counter += 1
                else:
                    print(f"Stopping at epoch {epoch}!")
                    break
        else:
            errors.append(error.item())
        if epoch % print_every == 0:
            print(
                f"Epoch {epoch}, TL"
                f" {loss.item()} {f'VL: {ve.item()}' if x_val is not None else ''}"
            )
    print(f"Epoch {epoch}, Loss {loss.item()}")
    if print_examples:
        print(pred[:10], "\n", y[:10])
    return errors, best_model


def error_analysis(model, tx, ty, timp, n_samp=100):
    tp = model.cpu()(tx.cpu())
    e = F.l1_loss(tp, ty.cpu(), reduction="none").squeeze()
    print(
        f"Mean loss: {e.mean().item():4f}, Median loss:"
        f" {e.median().item():.4f}"
    )
    fig = plt.figure(figsize=(6, 3))
    fig.suptitle(f"First {n_samp} test samples")
    plt.plot(tp[:n_samp].detach().cpu(), label="Predictions")
    plt.plot(ty[:n_samp].cpu(), label="Truth")
    plt.legend()
    if e.ndim == 2:
        e = e.mean(1)
    sortidx = e.argsort()
    fig = plt.figure(figsize=(6, 3))
    ax = fig.add_subplot(111)
    (a,) = ax.plot(e[sortidx].detach(), label="Sorted test errors")
    ax.set_ylabel("Errors")
    (b,) = ax.twinx().plot(
        ty.max(1).values.abs().cpu()[sortidx],
        label="Max lag in prediction",
        color="tab:orange",
        alpha=0.7,
    )
    lines = [a, b]
    labels = [line.get_label() for line in lines]
    plt.legend(lines, labels)
    print(
        "Best:",
        ty.cpu()[sortidx][:20, 0],
        "\nWorst:",
        ty.cpu()[sortidx][-20:, 0],
    )
    print(timp[sortidx][-20:])
#+end_src

** 2 channels
Let's start with the simplest version:
: torch.Size([100, 1, 256, 16])
#+begin_src python
w = 256
c = 2
lossfun = F.mse_loss
lr = 0.002 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 2000
print_every = 100

m = model.CNN(w, c - 1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3).to(
    device
)
#m = model.RNN(w, c - 1, c, 16, 2, dropout_rate=0.6, rnn_type="GRU", share_input_weights=False).to(device)
# m = model.CNNRNN(
#     w,
#     c - 1,
#     c,
#     layer_sizes=[64],
#     kernel_size=7,
#     n_hidden=16,
#     n_rnn_layers=2,
#     dropout_rate=0.6,
# ).to(device)
x, y, imp = generate_data(w, c, 100, device=device)
tx, ty, timp = generate_data(w, c, 1000, device=device)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 2000)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
m.load_state_dict(bm)
bm = m
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 11923.2119140625 VL: 12653.0439453125
Epoch 100, TL 1250.1591796875 VL: 5643.154296875
Epoch 200, TL 1180.04248046875 VL: 1848.591796875
Epoch 300, TL 402.5008850097656 VL: 1662.59619140625
Epoch 400, TL 459.6202392578125 VL: 677.0028076171875
Epoch 500, TL 296.0764465332031 VL: 779.1265258789062
Epoch 600, TL 307.20916748046875 VL: 510.5166320800781
Epoch 700, TL 285.1921081542969 VL: 574.2542724609375
Epoch 800, TL 324.3214111328125 VL: 477.7702331542969
Epoch 900, TL 214.35459899902344 VL: 506.7640380859375
Epoch 1000, TL 365.494140625 VL: 576.2450561523438
Epoch 1100, TL 319.63641357421875 VL: 414.01129150390625
Epoch 1200, TL 215.15426635742188 VL: 430.5967102050781
Epoch 1300, TL 324.72705078125 VL: 537.046630859375
Epoch 1400, TL 250.90687561035156 VL: 434.5767517089844
Epoch 1500, TL 209.4241485595703 VL: 627.3638916015625
Epoch 1600, TL 233.42921447753906 VL: 457.96502685546875
Epoch 1700, TL 213.8964385986328 VL: 499.7232360839844
Epoch 1800, TL 214.24624633789062 VL: 429.812255859375
Epoch 1900, TL 246.33677673339844 VL: 444.5519714355469
Epoch 2000, TL 217.6715545654297 VL: 416.34075927734375
Epoch 2100, TL 243.9999542236328 VL: 416.56866455078125
Stopping at epoch 2165!
Epoch 2165, Loss 210.11903381347656
tensor([[   1.0917],
        [   1.7738],
        [  -0.6566],
        [-272.9344],
        [ 212.0352],
        [ -17.7385],
        [ 189.7748],
        [ -76.0503],
        [ 142.1835],
        [  32.7605]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.],
        [   0.],
        [   0.],
        [-255.],
        [ 255.],
        [ -27.],
        [ 169.],
        [ -94.],
        [ 148.],
        [  30.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 2.188316, Median loss: 1.0464
Best: tensor([ -23., -178.,   41.,  -38.,  -63., -205.,  -42.,  -25.,   31.,  -82.,
        -129., -132., -102.,  -59.,  -92.,  -63., -172.,   41.,  -30.,  -15.]) 
Worst: tensor([188.,   2., 204.,  -4., 178., 167.,   0., 221.,   2., 175., 170.,   2.,
          3.,   2., 245., 246.,   2., -58.,  -3.,  -1.])
tensor([[ 58, 246],
        [ 84,  86],
        [ 48, 252],
        [ 35,  31],
        [ 75, 253],
        [  1, 168],
        [ 23,  23],
        [  1, 222],
        [ 99, 101],
        [  1, 176],
        [  1, 171],
        [131, 133],
        [ 11,  14],
        [ 42,  44],
        [  4, 249],
        [  5, 251],
        [ 69,  71],
        [ 58,   0],
        [ 22,  19],
        [104, 103]], device='cuda:0')
#+end_example
[[./.ob-jupyter/d9964bdb83eaa449b0b62fc837f874893dbf7f47.png]]
[[./.ob-jupyter/0aedf47a76e3b5335b919aa39b76c889116de172.png]]
:END:

Although it doesn't always converge, this works! Both RNN and CNN are able to
do this, in fact.

However, the loss on the full test set is still rather high! It looks like it's
primarily very large or very small/nonexisting lags which cause this issue.
Large lags make sense, as they're at the boundary and thus are closer to
require extrapolation.

Notes RNN:
- I needed to have a hidden size of 128+ to be able to learn this properly, at
  2 layers. More layers, and it becomes harder to learn. With smaller sizes, it
  appears that the lag is limited to the hidden size, showing that it is
  related to how far the network can look to find lags.
- Once I added the attention, it worked also with a hidden size of 64
Notes CNN:
- slightly worse at this than the RNN in convergence - it gets better at larger
  numbers of parameters, but then I'd need to tweak more to get it to converge

** 3 channels
Let's see if it can learn 2 lags at the same time. That's one step closer
towards what we need to learn.

#+begin_src python
w = 256
c = 3
lossfun = F.mse_loss
lr = 0.001 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 3000
print_every = 100

# m = model.CNN(
#     w, c-1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
# ).cuda()
m = model.RNN(w, c - 1, c, 16, 2, dropout_rate=0.6, share_input_weights=True).cuda()
device = m.device
x, y, imp = generate_data(w, c, 100, device=device)
tx, ty, timp = generate_data(w, c, 1000, device=device)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 9797.724609375 VL: 10937.0771484375
Epoch 100, TL 4533.7890625 VL: 9037.7470703125
Epoch 200, TL 2950.878173828125 VL: 3322.52294921875
Epoch 300, TL 356.5895080566406 VL: 1074.657470703125
Epoch 400, TL 202.80323791503906 VL: 867.0380859375
Epoch 500, TL 84.18399047851562 VL: 386.94635009765625
Epoch 600, TL 32.605918884277344 VL: 74.24748229980469
Epoch 700, TL 64.31904602050781 VL: 41.493675231933594
Epoch 800, TL 17.088197708129883 VL: 57.716644287109375
Epoch 900, TL 28.063058853149414 VL: 31.811717987060547
Epoch 1000, TL 13.49834156036377 VL: 28.634328842163086
Epoch 1100, TL 15.28337574005127 VL: 26.30498504638672
Epoch 1200, TL 11.294228553771973 VL: 26.616729736328125
Epoch 1300, TL 10.797918319702148 VL: 16.320541381835938
Epoch 1400, TL 7.7080979347229 VL: 15.624723434448242
Epoch 1500, TL 9.873404502868652 VL: 11.996635437011719
Epoch 1600, TL 5.244534969329834 VL: 13.392248153686523
Epoch 1700, TL 4.024059772491455 VL: 9.139055252075195
Epoch 1800, TL 4.523504257202148 VL: 13.074235916137695
Epoch 1900, TL 4.394941806793213 VL: 9.586922645568848
Epoch 2000, TL 4.473787307739258 VL: 9.338714599609375
Epoch 2100, TL 3.0711374282836914 VL: 10.5660400390625
Epoch 2200, TL 3.194096088409424 VL: 7.816829681396484
Epoch 2300, TL 2.5959553718566895 VL: 6.540218353271484
Epoch 2400, TL 2.9732067584991455 VL: 7.469451904296875
Epoch 2500, TL 2.7218360900878906 VL: 7.070628643035889
Epoch 2600, TL 2.3775062561035156 VL: 7.469150066375732
Epoch 2700, TL 2.0485284328460693 VL: 8.085326194763184
Epoch 2800, TL 2.4743940830230713 VL: 9.536794662475586
Epoch 2900, TL 2.2067036628723145 VL: 7.413653373718262
Epoch 2999, Loss 2.2365968227386475
tensor([[-1.8919e+00, -6.3282e-02],
        [ 1.1337e+00, -9.9705e-01],
        [-8.5596e-02, -1.4792e-01],
        [-2.5889e+02,  2.2042e-01],
        [ 2.5255e+02, -2.5264e+02],
        [ 6.9334e-01,  2.5559e+02],
        [-8.9901e+00,  1.6475e+02],
        [ 3.1594e+01, -5.2260e+01],
        [ 5.1377e+01,  3.8554e+01],
        [ 2.3470e+02, -2.6096e+01]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.,    0.],
        [   0.,    0.],
        [   0.,    0.],
        [-255.,    0.],
        [ 255., -255.],
        [   0.,  255.],
        [  -7.,  164.],
        [  32.,  -53.],
        [  51.,   38.],
        [ 236.,  -28.]], device='cuda:0')
#+end_example

Plot results on the test set:
#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 3.067169, Median loss: 1.9193
Best: tensor([-132.,   95.,    8.,   56.,    8., -208.,  -38.,   -2.,   16.,   43.,
          29., -164.,  -18.,  193.,   14.,   21.,  -48.,    6., -104.,  -59.]) 
Worst: tensor([ 37., 190., 255.,   5.,   0.,   4.,   5.,  -6., -60., 121., -26.,  31.,
        -81.,  73.,  71.,  59.,  43., 119.,   7.,  76.])
tensor([[  9,  46,  31],
        [ 18, 208, 254],
        [  0, 255,   0],
        [ 33,  38, 255],
        [246, 246, 191],
        [215, 219, 151],
        [220, 225, 170],
        [252, 246, 237],
        [163, 103, 254],
        [133, 254, 178],
        [146, 120, 255],
        [222, 253, 254],
        [237, 156, 255],
        [182, 255, 114],
        [184, 255, 242],
        [138, 197, 255],
        [204, 247, 253],
        [ 71, 190, 255],
        [248, 255,  94],
        [165, 241, 255]], device='cuda:0')
#+end_example
[[./.ob-jupyter/f68729cc5000a20cf33bed2d4bf8fb5f0a6d8c10.png]]
[[./.ob-jupyter/9b6d49aadc3afb461346e114ee8a746b8efd775b.png]]
:END:



#+RESULTS:
#+begin_example
Epoch 0, TL 12356.1396484375 VL: 11654.6298828125
Epoch 100, TL 7621.8505859375 VL: 8922.38671875
Epoch 200, TL 4692.791015625 VL: 4432.2724609375
Epoch 300, TL 3617.2890625 VL: 3960.30810546875
Epoch 400, TL 2975.39501953125 VL: 3386.6318359375
Epoch 500, TL 1673.6810302734375 VL: 1782.166015625
Epoch 600, TL 601.9627075195312 VL: 1070.9232177734375
Epoch 700, TL 438.4246826171875 VL: 714.2683715820312
Epoch 800, TL 252.6402130126953 VL: 660.646240234375
Epoch 900, TL 208.8948211669922 VL: 413.8019714355469
Epoch 1000, TL 163.1772918701172 VL: 311.8202819824219
Epoch 1100, TL 128.8693389892578 VL: 320.7862548828125
Epoch 1200, TL 112.0771255493164 VL: 292.47454833984375
Epoch 1300, TL 64.62334442138672 VL: 387.5838317871094
Epoch 1400, TL 86.0174560546875 VL: 215.64512634277344
Epoch 1500, TL 78.3893051147461 VL: 212.8132781982422
Epoch 1600, TL 58.031585693359375 VL: 217.86044311523438
Epoch 1700, TL 39.056209564208984 VL: 220.63156127929688
Epoch 1800, TL 32.34804916381836 VL: 189.09466552734375
Epoch 1900, TL 24.82532501220703 VL: 196.97238159179688
Epoch 2000, TL 24.550607681274414 VL: 175.1767120361328
Epoch 2100, TL 24.274049758911133 VL: 187.39707946777344
Epoch 2200, TL 15.048283576965332 VL: 170.42678833007812
Epoch 2300, TL 14.50401782989502 VL: 155.8015594482422
Epoch 2400, TL 14.956853866577148 VL: 164.1660919189453
Epoch 2500, TL 13.131484985351562 VL: 160.4081573486328
Epoch 2600, TL 11.323251724243164 VL: 155.822998046875
Epoch 2700, TL 11.416837692260742 VL: 158.9982147216797
Epoch 2800, TL 13.83969497680664 VL: 150.00393676757812
Epoch 2900, TL 9.069437980651855 VL: 163.32676696777344
Epoch 2999, Loss 11.212181091308594
tensor([[  -0.2927,   -3.0392],
        [  -0.7276,   -2.8642],
        [   0.6274,    0.3188],
        [-252.9344,   -1.5700],
        [ 256.4276, -252.8566],
        [   5.4303,  249.7804],
        [ 129.4544,  -98.4681],
        [-132.0554,   46.2599],
        [ -14.3961,   92.2857],
        [ -64.0335,    7.8503]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.,    0.],
        [   0.,    0.],
        [   0.,    0.],
        [-255.,    0.],
        [ 255., -255.],
        [   0.,  255.],
        [ 126.,  -96.],
        [-135.,   46.],
        [ -12.,   82.],
        [ -67.,    9.]], device='cuda:0')
#+end_example

#+begin_example
Mean loss: 9.929891, Median loss: 5.3763
Best: tensor([-236.,   86.,    0.,   -8.,   27.,  163.,   71.,  229.,   50.,  126.,
          82.,  -45.,  163.,  128.,    5.,   30.,  -27., -116.,   49.,  176.]) 
Worst: tensor([-178.,  123.,  159.,  162.,  152.,  184.,  195.,  176.,  158.,  178.,
         160.,  150.,  175.,  184.,  182.,  184.,  210.,  201.,  197.,  205.])
tensor([[202,  24,  45],
        [ 91, 214,  98],
        [ 86, 245,  90],
        [ 15, 177,  25],
        [ 51, 203,  55],
        [  7, 191,   6],
        [  5, 200,   2],
        [ 64, 240,  43],
        [ 37, 195,  22],
        [ 10, 188,  16],
        [ 87, 247, 106],
        [ 60, 210,  67],
        [ 40, 215,  29],
        [ 22, 206,  18],
        [ 61, 243,  79],
        [ 58, 242,  44],
        [ 16, 226,   3],
        [ 15, 216,  23],
        [ 51, 248,  65],
        [ 43, 248,  27]], device='cuda:0')
#+end_example
[[./.ob-jupyter/758e66ff4cd77bc94a894c5f05d9ba3ddd4ef35c.png]]
[[./.ob-jupyter/7fcba408499a538dea4778611957b1d615e06577.png]]

Error analysis:
The MSE is still very high on this, possibly because we overfit, having lowered
the dropout.
let's see at which values of lags the model struggles most:
#+begin_src python
e = (tp - ty.cpu()).square().sum(1)
sortidx = e.argsort()
print("Best:\n",ty.cpu()[sortidx][:10].T, "\nWorst:\n", ty.cpu()[sortidx][-10:].T)
#+end_src

#+RESULTS:
: Best:
:  tensor([[ -55., -136.,  -55.,  119., -185.,   88., -182.,  206.,  104., -106.],
:         [ 105.,  115.,  -46., -141.,   88., -140.,  122., -101., -169.,   58.]]) 
: Worst:
:  tensor([[ 254.,  244.,  246.,    5.,  -89.,  240.,   29.,  -76., -187.,  -45.],
:         [ -76.,  -31.,  -53.,    0.,  166.,  -16.,  158.,  201.,  251.,  233.]])

There are somewhat more extreme values at the large errors, but in general I
think it's just overfit.

** Non-binary impulses
This is a contrived case where we learn impulses, but in reality we'll never
have such data. Let's transform these into gaussian impulses for a further
step, and check whether it still works as well.

#+begin_src python
def transform_impulse1(x, n=11, ramp_up: int = 0):
    c = x.shape[1]
    ls = torch.linspace(-3 * np.e, 0, n, device=x.device)
    exp = torch.exp(ls)
    if ramp_up > 0:
        exp[-ramp_up:] = torch.exp(
            torch.linspace(ls[-ramp_up], 2 * -np.e, ramp_up, device=x.device)
        )
    return F.conv1d(F.pad(x, (n - 1, 0)), exp.repeat(c, 1, 1), groups=c)
#+end_src

#+begin_src python
w = 256
c = 3
lossfun = F.l1_loss
lr = 0.001 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 3000
print_every = 100

# m = model.CNN(
#     w, c-1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
# ).to(device)
# m = model.CNNRNN(
#     w,
#     c-1,
#     c,
#     layer_sizes=[8],
#     kernel_size=2,
#     n_hidden=128,
#     n_rnn_layers=1,
#     dropout_rate=0.6,
# ).to(device)
# m = model.RNN(w, c - 1, c, 64, 2, dropout_rate=0.5).to(device)
m = model.LCCCNN(
    w,
    c-1,
    c,
    layer_sizes=[8, 8, 8, 8],
    kernel_sizes=7,
    dropout_rate=0.0,
    batch_norm=True,
    loss=lossfun,
    lr=lr,
).to(device)
x, y, imp = generate_data(w, c, 100, device=device)
x = transform_impulse1(x, 200, 20)
tx, ty, timp = generate_data(w, c, 1000, device=device)
tx = transform_impulse1(tx, 200, 20)
y /= 255
ty /= 255
optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 5000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
/home/tim/projects/onset-fingerprinting/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
Epoch 0, TL 11471.6171875 VL: 10763.947265625
Epoch 100, TL 6300.701171875 VL: 4763.0048828125
Epoch 200, TL 1386.6453857421875 VL: 1241.863037109375
Epoch 300, TL 342.417724609375 VL: 723.0066528320312
Epoch 400, TL 250.0272216796875 VL: 510.8902893066406
Epoch 500, TL 55.00023651123047 VL: 379.0447998046875
Epoch 600, TL 57.27154541015625 VL: 424.559326171875
Epoch 700, TL 43.54613494873047 VL: 150.87136840820312
Epoch 800, TL 31.350616455078125 VL: 146.08096313476562
Epoch 900, TL 37.63465881347656 VL: 210.27972412109375
Epoch 1000, TL 59.4703254699707 VL: 61.12222671508789
Epoch 1100, TL 29.809720993041992 VL: 64.12410736083984
Epoch 1200, TL 15.877347946166992 VL: 97.62782287597656
Epoch 1300, TL 14.474164962768555 VL: 87.64909362792969
Epoch 1400, TL 13.176837921142578 VL: 86.94642639160156
Epoch 1500, TL 7.699976444244385 VL: 81.4412841796875
Epoch 1600, TL 5.240980625152588 VL: 65.48567199707031
Epoch 1700, TL 9.369585037231445 VL: 61.48301315307617
Epoch 1800, TL 11.597272872924805 VL: 55.46167755126953
Epoch 1900, TL 11.893485069274902 VL: 46.76387405395508
Epoch 2000, TL 5.205259323120117 VL: 56.14391326904297
Epoch 2100, TL 6.685842037200928 VL: 60.57660675048828
Epoch 2200, TL 2.979496955871582 VL: 47.39455795288086
Epoch 2300, TL 2.6737499237060547 VL: 52.31924819946289
Epoch 2400, TL 2.32865309715271 VL: 56.26995849609375
Epoch 2500, TL 2.1595070362091064 VL: 60.19451904296875
Epoch 2600, TL 2.235826015472412 VL: 53.08357238769531
Stopping at epoch 2637!
Epoch 2637, Loss 2.036637306213379
tensor([[  62.6798,  141.3915],
        [  68.4154, -164.8867],
        [  53.9853,   59.8275],
        [  31.9432, -179.9884],
        [ 173.9814,   21.4797],
        [  46.0552,  -49.5891],
        [ 123.8873, -126.6256],
        [ -19.2127,   14.2151],
        [-150.5007,  182.4794],
        [ -93.4469, -122.0795]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[  58.,  143.],
        [  65., -163.],
        [  55.,   59.],
        [  32., -180.],
        [ 175.,   20.],
        [  49.,  -52.],
        [ 123., -126.],
        [ -15.,   12.],
        [-149.,  181.],
        [ -93., -122.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 3.942275, Median loss: 1.8895
Best: tensor([ 69.,  35.,  56., -40.,  64.,  52.,  47., 129., -76., 151.,  79.,  -5.,
         55.,  40., 132., -50., -20.,  53., -41.,  31.]) 
Worst: tensor([ -62., -122.,   -1., -226.,   -1., -201., -209.,  -70., -223.,  -86.,
        -229.,  -74.,    3.,  -82.,    3.,  -90.,   -2.,  -89.,    0.,    2.])
tensor([[ 56, 118,  88],
        [ 18, 140, 115],
        [ 69,  70, 173],
        [ 18, 244, 174],
        [104, 105, 189],
        [  8, 209, 191],
        [ 11, 220, 173],
        [ 67, 137, 118],
        [ 25, 248, 224],
        [ 10,  96,  79],
        [ 22, 251, 196],
        [ 33, 107,  73],
        [121, 118, 158],
        [ 21, 103,  81],
        [ 59,  56, 151],
        [  8,  98,  69],
        [ 71,  73,  68],
        [  3,  92,  69],
        [ 42,  42, 199],
        [ 29,  27, 110]], device='cuda:0')
#+end_example
[[./.ob-jupyter/a8aa1a861fad67c9f96828b56d97206fc25181dc.png]]
[[./.ob-jupyter/7d0c1568492492549fec03849e787f041c31e2d2.png]]
:END:

Nice, it performs pretty much the same!

*** Additional changes
This is still very idealized - here are more things we can do to make it look
more real:
- peaks at different amplitudes
- modulate with sine wave
- add noise


Note: frequencies should be the same in each of the channels, phase could be
slightly shifted, but very little. The sine needs to start at the impulse in
each case, so currently this is wrong.
#+begin_src python
def transform_impulse2(
    x, imp, random_phase: bool = False, noise_std=0, sr=96000
):
    n, c, w = x.shape
    ls = torch.linspace(0, x.shape[-1] / sr, x.shape[-1], device=x.device)
    phase = (
        torch.rand(x.shape[0], x.shape[1], 1, device=x.device) * 0.1 * np.pi
        if random_phase
        else 0
    )
    f = torch.randint(300, 1000, (x.shape[0], 1, 1), device=x.device).expand(
        n, c, 1
    )
    sin = torch.sin(2 * np.pi * ls[None, None, :] * f + phase)
    for i in range(len(x)):
        for j in range(c):
            k = w - imp[i, j]
            x[i, j, imp[i, j] :] *= sin[i, j, :k]
    x += torch.randn(x.shape, device=x.device) * noise_std
    return x
#+end_src

#+begin_src python
x = transform_impulse2(x, imp, True, 0.001)
tx = transform_impulse2(tx, timp, True, 0.001)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x,
    y,
    m.to(device),
    lossfun,
    optimizer,
    scheduler,
    3000,
    tx[:100],
    ty[:100],
    500,
)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 38.41012191772461 VL: 11656.9599609375
Epoch 100, TL 16.59128189086914 VL: 153.88595581054688
Epoch 200, TL 22.921138763427734 VL: 109.77005004882812
Epoch 300, TL 60.49607467651367 VL: 96.41871643066406
Epoch 400, TL 11399.8642578125 VL: 10716.013671875
Epoch 500, TL 3034.529296875 VL: 3443.92236328125
Epoch 600, TL 689.79443359375 VL: 455.908203125
Epoch 700, TL 72.95342254638672 VL: 165.76028442382812
Stopping at epoch 732!
Epoch 732, Loss 80.4583511352539
tensor([[  61.4558,  144.0829],
        [  48.9084, -145.4959],
        [  49.2660,   55.4530],
        [  22.9640, -167.7405],
        [ 166.9901,   23.7873],
        [  45.7351,  -44.0062],
        [ 110.5431, -113.2652],
        [ -17.7397,    7.5596],
        [-141.3242,  174.2570],
        [-105.1589, -120.3260]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[  58.,  143.],
        [  65., -163.],
        [  55.,   59.],
        [  32., -180.],
        [ 175.,   20.],
        [  49.,  -52.],
        [ 123., -126.],
        [ -15.,   12.],
        [-149.,  181.],
        [ -93., -122.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 8.697659, Median loss: 7.2153
Best: tensor([  81., -133.,  -21., -149.,   37.,  -50.,   44.,  -51., -194.,   36.,
         -82., -117.,   -8., -165.,  142.,  133.,  160.,   47.,  -70.,  -55.]) 
Worst: tensor([153., -16.,  13., -25., -11., -15., -20., -24., -18., -32., -24.,  -6.,
        -14.,  11., -21.,  11., -18., 228., 196.,  -2.])
tensor([[186,  33,   2],
        [  9,  25,  26],
        [141, 128, 118],
        [ 29,  54, 162],
        [  8,  19,  37],
        [ 59,  74, 160],
        [ 13,  33, 162],
        [ 13,  37, 124],
        [ 38,  56, 175],
        [ 38,  70,  60],
        [ 19,  43, 106],
        [ 24,  30,  84],
        [ 45,  59, 125],
        [ 69,  58,  46],
        [ 30,  51, 129],
        [ 87,  76,  70],
        [  2,  20,  62],
        [254,  26,  17],
        [208,  12,   8],
        [ 71,  73,  68]], device='cuda:0')
#+end_example
[[./.ob-jupyter/8c75740c54df5a4ef929e0528f428af74278893a.png]]
[[./.ob-jupyter/471d27d84a130b38e16a2cb2baf00a9975c3c161.png]]
:END:


Good sizes appear to be either a few (5) 4-8-size layers with a large kernel size
(e.g. 33) or 10 layers with a moderate kernel size (e.g. 15).
#+begin_src python
m = model.CNN(
    w, c - 1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
).to(device)
m = model.CNNRNN(
    w,
    c-1,
    c,
    layer_sizes=[8],
    kernel_size=2,
    n_hidden=128,
    n_rnn_layers=1,
    dropout_rate=0.6,
).to(device)
m = model.LCCCNN(
    w,
    c-1,
    c,
    layer_sizes=[5] * 7,
    kernel_sizes=[1, 33, 64, 15, 15, 15, 1],
    dropout_rate=0.0,
    batch_norm=True,
    loss=lossfun,
    lr=lr,
    group=False
).to(device)
#m = model.RNN(w, c - 1, c, 64, 2, dropout_rate=0.5).to(device)

x, y, imp = generate_data(w, c, 100, device=device)
x = transform_impulse1(x, 200, 20)
x = transform_impulse2(x, imp, True, 0.001)
tx, ty, timp = generate_data(w, c, 1000, device=device)
tx = transform_impulse1(tx, 200, 20)
tx = transform_impulse2(tx, timp, True, 0.001)
y /= 255
ty /= 255
optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
:RESULTS:
: /home/tim/projects/onset-fingerprinting/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1
:   warnings.warn("dropout option adds dropout after all but last "
: Epoch 0, TL 0.17845021188259125 VL: 0.1758619248867035
: Epoch 100, TL 0.05831901356577873 VL: 0.1305510550737381
: Epoch 200, TL 0.008663039654493332 VL: 0.011927877552807331
: Epoch 300, TL 0.0058522881008684635 VL: 0.009444184601306915
: Epoch 400, TL 0.004826344549655914 VL: 0.008127442561089993
: Epoch 500, TL 0.003857510630041361 VL: 0.008599095046520233


#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 0.051738, Median loss: 0.0324
Best: tensor([ 0.1059,  0.1686, -0.6157, -0.2627,  0.1882,  0.6039,  0.5961,  0.0196,
        -0.5059,  0.6078, -0.3333, -0.5333,  0.0745, -0.6627, -0.3647,  0.4863,
         0.2118, -0.7451, -0.3098, -0.7569]) 
Worst: tensor([0.3490, 0.4784, 0.4157, 0.4588, 0.5686, 0.2784, 0.4118, 0.5686, 0.4353,
        0.5020, 0.5294, 0.5059, 0.3843, 0.4941, 0.2902, 0.4196, 0.2745, 0.3961,
        0.2941, 0.3490])
tensor([[114, 203, 167],
        [ 35, 157,  21],
        [133, 239, 230],
        [ 98, 215, 151],
        [ 79, 224, 128],
        [175, 246, 199],
        [150, 255, 214],
        [ 83, 228, 127],
        [110, 221, 160],
        [124, 252, 190],
        [ 99, 234, 173],
        [116, 245, 151],
        [102, 200, 134],
        [113, 239, 186],
        [139, 213, 182],
        [138, 245, 188],
        [135, 205, 159],
        [114, 215, 129],
        [166, 241, 184],
        [164, 253, 206]], device='cuda:0')
#+end_example
[[file:./.ob-jupyter/8dd0e3f72555fafb6e9aada4736d071235470ace.png]]
[[file:./.ob-jupyter/b697d9a14a82cd517e7a50738cd23bb2233ae5a0.png]]
:END:


*** Making the data even more real

In its current iteration, the data models an impulse of the fundamental - but
as far as the modelling problem goes, it's different from what we'll see in
realtime: There, we'll always start the window from the first onset on. In the
current data, the first onset may start anywhere.

Let's adapt the data in such a way that our first onset is always close to the
beginning of the buffers.
#+begin_src python
def generate_data2(w: int, c: int, n: int = 10000, max_shift=10, device=None):
    signals = torch.zeros(n, c, w, device=device)
    impulses = torch.randint(0, w - max_shift, (n, c), device=device)
    mini = impulses.min(dim=1, keepdim=True).values
    impulses -= mini
    impulses += torch.maximum(
        torch.tensor(0, device=device),
        torch.minimum(
            w - impulses.max(dim=1, keepdim=True).values - 1,
            torch.randint(max_shift, (len(impulses), 1), device=device),
        ),
    )
    # Force some 0s
    impulses[0] = torch.tensor([0] * c)
    impulses[1] = torch.tensor([w // 2] * c)
    impulses[2] = torch.tensor([w - 1] * c)
    # Force the extremes
    z = torch.zeros((c, c), dtype=torch.long)
    for i in range(c):
        z[i, i] = w - 1
    impulses[3 : 3 + c] = z
    signals.scatter_(2, impulses[:, :, None], 1)
    return signals, torch.diff(impulses).to(torch.float32), impulses
#+end_src


#+begin_src python
w = 256
c = 3
lossfun = F.mse_loss
lr = 0.001 * (5 if lossfun == F.mse_loss else 1)
num_epochs = 2000
print_every = 100

m = model.CNN(
    w, c - 1, c, layer_sizes=[8, 8], kernel_size=8, dropout_rate=0.9
).to(device)
m = model.RNN(
    w,
    c - 1,
    c,
    16,
    1,
    dropout_rate=0.6,
    rnn_type="GRU",
    share_input_weights=True,
).to(device)
# m = model.CNNRNN(
#     w,
#     c - 1,
#     c,
#     layer_sizes=[9, 18, 27],
#     kernel_size=3,
#     n_hidden=64,
#     n_rnn_layers=2,
#     dropout_rate=0.8,
#     groups=1,
# ).to(device)
m = model.LCCCNN(
    w,
    c-1,
    c,
    layer_sizes=[5] * 7,
    kernel_sizes=[33, 15, 15, 15, 15, 15, 15],
    dropout_rate=0.0,
    batch_norm=True,
    loss=lossfun,
    lr=lr,
    group=False
).to(device)
x, y, imp = generate_data2(w, c, 100, 100, device=device)
tx, ty, timp = generate_data2(w, c, 1000, 100, device=device)
y /= 255
ty /= 255

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer, num_epochs / 10
)
errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
m.load_state_dict(bm)
x = transform_impulse1(x, 200, 20)
tx = transform_impulse1(tx, 200, 20)
errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
m.load_state_dict(bm)
x = transform_impulse2(x, imp, True, 0.01)
tx = transform_impulse2(tx, timp, True, 0.01)
errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
m.load_state_dict(bm)
bm = m
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 0.08087802678346634 VL: 0.07934799045324326
Epoch 100, TL 0.03380775824189186 VL: 0.04018889367580414
Epoch 200, TL 0.02407645620405674 VL: 0.028941133990883827
Epoch 300, TL 0.008892912417650223 VL: 0.011478347703814507
Epoch 400, TL 0.003165166825056076 VL: 0.0047147623263299465
Epoch 500, TL 0.0009923753095790744 VL: 0.0029194748494774103
Epoch 600, TL 0.0008884998969733715 VL: 0.002720307558774948
Epoch 700, TL 0.001316841458901763 VL: 0.0025911356788128614
Epoch 800, TL 0.03624872863292694 VL: 0.04414212703704834
Epoch 900, TL 0.02246553637087345 VL: 0.02752538211643696
Epoch 1000, TL 0.02182730659842491 VL: 0.026686204597353935
Epoch 1100, TL 0.021617760881781578 VL: 0.026547187939286232
Stopping at epoch 1191!
Epoch 1191, Loss 0.021718434989452362
tensor([[ 0.0126,  0.0055],
        [-0.0077,  0.0038],
        [ 0.0126,  0.0055],
        [ 0.0126,  0.0055],
        [ 0.0126,  0.0055],
        [ 0.0126,  0.0055],
        [ 0.2258,  0.1441],
        [-0.0250, -0.4420],
        [-0.3886,  0.3164],
        [ 0.0089,  0.0052]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [-1.0000,  0.0000],
        [ 1.0000, -1.0000],
        [ 0.0000,  1.0000],
        [ 0.1961,  0.0824],
        [-0.0314, -0.4157],
        [-0.3373,  0.2902],
        [-0.0235, -0.0196]], device='cuda:0')
Epoch 0, TL 0.035685740411281586 VL: 0.05122639611363411
Epoch 100, TL 0.002199514303356409 VL: 0.0032703315373510122
Epoch 200, TL 0.0014857406495139003 VL: 0.002283372450619936
Epoch 300, TL 0.01081795897334814 VL: 0.013887200504541397
Epoch 400, TL 0.0006396473618224263 VL: 0.0006364354630932212
Epoch 500, TL 9.95611771941185e-05 VL: 0.00015752037870697677
Epoch 600, TL 8.945749868871644e-05 VL: 0.00014106027083471417
Epoch 700, TL 8.428044384345412e-05 VL: 0.00013271182251628488
Epoch 800, TL 0.0005619106814265251 VL: 0.0005731481360271573
Epoch 900, TL 5.6660286645637825e-05 VL: 9.412155486643314e-05
Epoch 1000, TL 4.93933075631503e-05 VL: 8.625171176390722e-05
Epoch 1100, TL 4.627715679816902e-05 VL: 8.177101699402556e-05
Epoch 1200, TL 0.0016436141449958086 VL: 0.0009297601645812392
Epoch 1300, TL 4.061164872837253e-05 VL: 6.445775943575427e-05
Epoch 1400, TL 3.6159282899461687e-05 VL: 5.9807363868458197e-05
Epoch 1500, TL 3.4087628591805696e-05 VL: 5.7553181250113994e-05
Epoch 1600, TL 0.0016071037389338017 VL: 0.0016198698431253433
Epoch 1700, TL 3.472207026788965e-05 VL: 5.556411997531541e-05
Epoch 1800, TL 3.0796683859080076e-05 VL: 5.1477127271937206e-05
Epoch 1900, TL 2.895273246394936e-05 VL: 4.938800702802837e-05
Epoch 2000, TL 0.0006749182939529419 VL: 0.0006107676308602095
Epoch 2100, TL 3.25986766256392e-05 VL: 6.346028385451064e-05
Epoch 2200, TL 2.880105603253469e-05 VL: 5.7735047448659316e-05
Epoch 2300, TL 2.6852067094296217e-05 VL: 5.471035547088832e-05
Epoch 2400, TL 0.01343555934727192 VL: 0.015943404287099838
Stopping at epoch 2420!
Epoch 2420, Loss 0.02312537468969822
tensor([[-0.0094, -0.0041],
        [-0.0144, -0.0302],
        [-0.0107, -0.0153],
        [-0.1571, -0.0157],
        [ 0.1523, -0.1705],
        [-0.0246,  0.1627],
        [ 0.1210,  0.1562],
        [ 0.0244, -0.5176],
        [-0.2459,  0.1053],
        [-0.0090, -0.0033]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [-1.0000,  0.0000],
        [ 1.0000, -1.0000],
        [ 0.0000,  1.0000],
        [ 0.1961,  0.0824],
        [-0.0314, -0.4157],
        [-0.3373,  0.2902],
        [-0.0235, -0.0196]], device='cuda:0')
Epoch 0, TL 0.021432919427752495 VL: 0.08101560175418854
Epoch 100, TL 0.0036493721418082714 VL: 0.004541181027889252
Epoch 200, TL 0.002540953690186143 VL: 0.0031288694590330124
Epoch 300, TL 0.007076134905219078 VL: 0.008043921552598476
Epoch 400, TL 0.0006569731631316245 VL: 0.0011403820244595408
Epoch 500, TL 0.00034866592613980174 VL: 0.0007735317922197282
Epoch 600, TL 0.0003336231457069516 VL: 0.0007605931023135781
Epoch 700, TL 0.0010365666821599007 VL: 0.0013632207410410047
Epoch 800, TL 0.0009184795198962092 VL: 0.0009189538541249931
Epoch 900, TL 0.0002280801418237388 VL: 0.0005973450024612248
Epoch 1000, TL 0.00021671599824912846 VL: 0.0005863357800990343
Epoch 1100, TL 0.0008232325199060142 VL: 0.001102584763430059
Epoch 1200, TL 0.0007445004885084927 VL: 0.0008708311361260712
Epoch 1300, TL 0.00017671874957159162 VL: 0.0005196444690227509
Epoch 1400, TL 0.00016767386114224792 VL: 0.0005088361212983727
Epoch 1500, TL 0.00038920907536521554 VL: 0.0007322330493479967
Epoch 1600, TL 0.0012570965336635709 VL: 0.001303480938076973
Epoch 1700, TL 0.00017935606592800468 VL: 0.00031930237310007215
Epoch 1800, TL 0.00016581981617491692 VL: 0.00029948659357614815
Epoch 1900, TL 0.0001435872254660353 VL: 0.0002654595591593534
Epoch 2000, TL 0.00012760216486640275 VL: 0.0002605627232696861
Epoch 2100, TL 9.076630522031337e-05 VL: 0.00021249987185001373
Epoch 2200, TL 8.649242954561487e-05 VL: 0.00020773393043782562
Epoch 2300, TL 0.0005187861388549209 VL: 0.0006141355843283236
Epoch 2400, TL 0.00017662941536400467 VL: 0.00031908327946439385
Epoch 2500, TL 7.648561586393043e-05 VL: 0.00020447249698918313
Epoch 2600, TL 7.337908755289391e-05 VL: 0.00020022812532261014
Epoch 2700, TL 0.005187611561268568 VL: 0.006116336677223444
Epoch 2800, TL 0.00035623853909783065 VL: 0.0004336120036896318
Epoch 2900, TL 0.00014824926620349288 VL: 0.0002640486927703023
Epoch 2999, Loss 0.00013945273531135172
tensor([[ 4.1100e-03, -3.0724e-03],
        [-4.6631e-03,  6.7191e-03],
        [ 4.7224e-03, -6.0300e-03],
        [-9.6831e-01, -6.1598e-04],
        [ 9.7543e-01, -9.7066e-01],
        [-5.8558e-03,  9.8743e-01],
        [ 1.9285e-01,  7.2564e-02],
        [-2.5508e-02, -4.1168e-01],
        [-3.4215e-01,  2.8668e-01],
        [-1.7098e-02, -1.6409e-02]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [ 0.0000,  0.0000],
        [-1.0000,  0.0000],
        [ 1.0000, -1.0000],
        [ 0.0000,  1.0000],
        [ 0.1961,  0.0824],
        [-0.0314, -0.4157],
        [-0.3373,  0.2902],
        [-0.0235, -0.0196]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 0.010505, Median loss: 0.0083
Best: tensor([ 0.1529, -0.1020,  0.3412, -0.2863, -0.0745, -0.1373, -0.0549,  0.0353,
         0.0118, -0.0235,  0.1804,  0.0941, -0.0431, -0.4157, -0.2275, -0.1804,
         0.3569,  0.0000,  0.0118, -0.0627]) 
Worst: tensor([ 0.4353,  0.4392,  0.1020, -0.3059,  0.4588,  0.1451, -0.2000, -0.4157,
        -0.0863,  0.3961,  0.1098,  0.3922,  0.0980, -0.5686, -0.4353,  0.4588,
        -0.5569,  0.0863, -0.0275, -0.5137])
tensor([[ 15, 126,  43],
        [ 96, 208,  95],
        [ 49,  75,  33],
        [183, 105,  87],
        [ 84, 201, 220],
        [ 94, 131,  58],
        [ 63,  12,  92],
        [106,   0,  35],
        [103,  81, 101],
        [ 17, 118, 108],
        [ 98, 126, 162],
        [ 96, 196,  99],
        [ 99, 124, 203],
        [232,  87, 145],
        [112,   1, 112],
        [ 88, 205, 162],
        [239,  97,  91],
        [ 79, 101,  82],
        [ 77,  70,  66],
        [237, 106,  99]], device='cuda:0')
#+end_example
[[file:./.ob-jupyter/59aa92652e117d78ee6b2e1097c81de45818ff54.png]]
[[file:./.ob-jupyter/50aaacaeb22e8bab8ad5ec79206e828a6ded788c.png]]
:END:

** Real Data


* Pre-training
Start with impulse data, and epoch-by-epoch morph it into something looking
more like a real signal.



* Idea
Random tone generator based on FM synthesis or just adding different modulated
sines with a huge space. Then feedback the system by saying like/dislike on
single tones to find a space of settings which are pleasing to the ear.

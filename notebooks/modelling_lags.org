#+TITLE: Modelling lags
#+AUTHOR: Tim Loderhose
#+EMAIL: tim@loderhose.com
#+DATE: Wednesday, 12 June 2024
#+STARTUP: showall
#+PROPERTY: header-args :exports both :session lags :kernel lm :cache no
:PROPERTIES:
OPTIONS: ^:nil
#+LATEX_COMPILER: xelatex
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [logo, color, author]
#+LATEX_HEADER: \insertauthor
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry}
:END:

* Imports and Environment Variables
:PROPERTIES:
:visibility: folded
:END:

#+name: imports
#+begin_src python
import json
from importlib import reload
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import sounddevice as sd
import soundfile as sf
import torch
import torch.nn as nn
from onset_fingerprinting import (
    calibration,
    data,
    detection,
    model,
    multilateration,
    plots,
)
from torch import optim
from torch.nn import functional as F
#+end_src

#+name: env
#+begin_src python
data_dir = Path("../data/demo2")
device = "cuda"
#+end_src

* Introduction
I would like to move towards using NNs on windows of time-correlated audio. For
this, I need to be able to find a network architecture which can learn these
temporal relationships between signals. If the network can figure out the lag
between the different channels, then it should be able to learn the physical
model relating those to the location as well.

To this end, I will generate some impulse data for which I know the lags, and
plug in a number of architectures to see which one can learn this challenge.

* Generate data

The simplest version of this problem finds the lags between impulses occuring
in two signals of a length w.
#+begin_src python
def generate_data(w: int, c: int, n: int = 10000, device=None):
    signals = torch.zeros(n, c, w, device=device)
    impulses = torch.randint(0, w, (n, c), device=device)
    # Force some 0s
    impulses[0] = torch.tensor([0] * c)
    impulses[1] = torch.tensor([w // 2] * c)
    impulses[2] = torch.tensor([w - 1] * c)
    # Force the extremes
    z = torch.zeros((c, c), dtype=torch.long)
    for i in range(c):
        z[i, i] = w - 1
    impulses[3 : 3 + c] = z
    signals.scatter_(2, impulses[:, :, None], 1)
    return signals, torch.diff(impulses).to(torch.float32), impulses
#+end_src


* Learning

#+begin_src python
def train(
    x,
    y,
    model,
    lossfun,
    optimizer,
    scheduler,
    num_epochs=3000,
    x_val=None,
    y_val=None,
    patience=None,
    max_norm: float = 1.0,
    print_every: int = 100,
    print_examples: bool = True,
    device=None,
):
    model.to(device)
    x.to(device)
    y.to(device)
    errors = []
    last_loss = torch.inf
    best_model = None
    counter = 0
    for epoch in range(num_epochs):
        optimizer.zero_grad(set_to_none=True)
        pred = model(x)
        error = lossfun(pred, y)
        loss = error.mean()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)
        optimizer.step()
        scheduler.step()
        if x_val is not None:
            with torch.no_grad():
                vp = model(x_val)
                ve = lossfun(vp, y_val)
            errors.append((error.item(), ve.item()))
            if patience is not None:
                if ve < last_loss:
                    last_loss = ve
                    best_model = model
                    counter = 0
                elif counter < patience:
                    counter += 1
                else:
                    print(f"Stopping at epoch {epoch}!")
                    break
        else:
            errors.append(error.item())
        if epoch % print_every == 0:
            print(
                f"Epoch {epoch}, TL"
                f" {loss.item()} {f'VL: {ve.item()}' if x_val is not None else ''}"
            )
    print(f"Epoch {epoch}, Loss {loss.item()}")
    if print_examples:
        print(pred[:10], "\n", y[:10])
    return errors, best_model


def error_analysis(model, tx, ty, timp, n_samp=100):
    tp = model.cpu()(tx.cpu())
    e = F.l1_loss(tp, ty.cpu(), reduction="none").squeeze()
    print(
        f"Mean loss: {e.mean().item():4f}, Median loss:"
        f" {e.median().item():.4f}"
    )
    fig = plt.figure(figsize=(6, 3))
    fig.suptitle(f"First {n_samp} test samples")
    plt.plot(tp[:n_samp].detach().cpu(), label="Predictions")
    plt.plot(ty[:n_samp].cpu(), label="Truth")
    plt.legend()
    if e.ndim == 2:
        e = e.mean(1)
    sortidx = e.argsort()
    fig = plt.figure(figsize=(6, 3))
    ax = fig.add_subplot(111)
    (a,) = ax.plot(e[sortidx].detach(), label="Sorted test errors")
    (b,) = ax.twinx().plot(
        ty.max(1).values.abs().cpu()[sortidx],
        label="Max lag in prediction",
        color="tab:orange",
        alpha=0.7,
    )
    lines = [a, b]
    labels = [line.get_label() for line in lines]
    plt.legend(lines, labels)
    print(
        "Best:",
        ty.cpu()[sortidx][:20, 0],
        "\nWorst:",
        ty.cpu()[sortidx][-20:, 0],
    )
    print(timp[sortidx][-20:])
#+end_src

** 2 channels
Let's start with the simplest version:
: torch.Size([100, 1, 256, 16])
#+begin_src python
w = 256
c = 2
lossfun = F.mse_loss
lr = 0.002 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 2000
print_every = 100

m = model.CNN(w, c - 1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3).to(
    device
)
m = model.RNN(w, c - 1, c, 16, 2, dropout_rate=0.6, rnn_type="GRU", share_input_weights=False).to(device)
# m = model.CNNRNN(
#     w,
#     c - 1,
#     c,
#     layer_sizes=[64],
#     kernel_size=7,
#     n_hidden=16,
#     n_rnn_layers=2,
#     dropout_rate=0.6,
# ).to(device)
x, y, imp = generate_data(w, c, 100, device=device)
tx, ty, timp = generate_data(w, c, 1000, device=device)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 2000)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 12629.1123046875 VL: 10181.0
Epoch 100, TL 11545.8076171875 VL: 9219.76171875
Epoch 200, TL 11286.2021484375 VL: 9117.2451171875
Epoch 300, TL 14095.796875 VL: 8549.4501953125
Epoch 400, TL 563.5429077148438 VL: 840.6907348632812
Epoch 500, TL 245.21942138671875 VL: 142.2216033935547
Epoch 600, TL 113.48372650146484 VL: 132.77940368652344
Epoch 700, TL 70.09120178222656 VL: 49.918060302734375
Epoch 800, TL 75.74190521240234 VL: 39.53986358642578
Epoch 900, TL 16.750106811523438 VL: 59.48220443725586
Epoch 1000, TL 25.51134490966797 VL: 28.22699737548828
Epoch 1100, TL 19.29466438293457 VL: 28.226224899291992
Epoch 1200, TL 9.669910430908203 VL: 31.680273056030273
Epoch 1300, TL 15.852273941040039 VL: 15.18947982788086
Epoch 1400, TL 11.553351402282715 VL: 14.790739059448242
Epoch 1500, TL 5.849761962890625 VL: 19.517799377441406
Epoch 1600, TL 7.055644512176514 VL: 9.491982460021973
Epoch 1700, TL 5.713776111602783 VL: 8.363473892211914
Epoch 1800, TL 3.3988564014434814 VL: 11.77884292602539
Epoch 1900, TL 4.2292327880859375 VL: 11.061144828796387
Epoch 2000, TL 3.8420867919921875 VL: 11.379828453063965
Epoch 2100, TL 4.417903900146484 VL: 9.659210205078125
Epoch 2200, TL 3.8185272216796875 VL: 10.47231388092041
Epoch 2300, TL 4.547299861907959 VL: 11.110060691833496
Epoch 2400, TL 6.243853569030762 VL: 9.828782081604004
Epoch 2500, TL 4.267889976501465 VL: 9.383955955505371
Epoch 2600, TL 10.083755493164062 VL: 11.63809871673584
Epoch 2700, TL 6.622886657714844 VL: 17.820096969604492
Epoch 2800, TL 9.036847114562988 VL: 18.68136978149414
Epoch 2900, TL 15.907943725585938 VL: 11.536725997924805
Stopping at epoch 2907!
Epoch 2907, Loss 8.081771850585938
tensor([[  -2.4707],
        [   0.8019],
        [  -0.5337],
        [-260.3336],
        [ 251.7035],
        [  86.7222],
        [  50.9186],
        [  -3.5616],
        [  -5.5499],
        [ -28.6621]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.],
        [   0.],
        [   0.],
        [-255.],
        [ 255.],
        [  91.],
        [  58.],
        [  -4.],
        [  -3.],
        [ -28.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 2.188316, Median loss: 1.0464
Best: tensor([ -23., -178.,   41.,  -38.,  -63., -205.,  -42.,  -25.,   31.,  -82.,
        -129., -132., -102.,  -59.,  -92.,  -63., -172.,   41.,  -30.,  -15.]) 
Worst: tensor([188.,   2., 204.,  -4., 178., 167.,   0., 221.,   2., 175., 170.,   2.,
          3.,   2., 245., 246.,   2., -58.,  -3.,  -1.])
tensor([[ 58, 246],
        [ 84,  86],
        [ 48, 252],
        [ 35,  31],
        [ 75, 253],
        [  1, 168],
        [ 23,  23],
        [  1, 222],
        [ 99, 101],
        [  1, 176],
        [  1, 171],
        [131, 133],
        [ 11,  14],
        [ 42,  44],
        [  4, 249],
        [  5, 251],
        [ 69,  71],
        [ 58,   0],
        [ 22,  19],
        [104, 103]], device='cuda:0')
#+end_example
[[./.ob-jupyter/d9964bdb83eaa449b0b62fc837f874893dbf7f47.png]]
[[./.ob-jupyter/0aedf47a76e3b5335b919aa39b76c889116de172.png]]
:END:

Although it doesn't always converge, this works! Both RNN and CNN are able to
do this, in fact.

However, the loss on the full test set is still rather high! It looks like it's
primarily very large or very small/nonexisting lags which cause this issue.
Large lags make sense, as they're at the boundary and thus are closer to
require extrapolation.

Notes RNN:
- I needed to have a hidden size of 128+ to be able to learn this properly, at
  2 layers. More layers, and it becomes harder to learn. With smaller sizes, it
  appears that the lag is limited to the hidden size, showing that it is
  related to how far the network can look to find lags.
- Once I added the attention, it worked also with a hidden size of 64
Notes CNN:
- slightly worse at this than the RNN in convergence - it gets better at larger
  numbers of parameters, but then I'd need to tweak more to get it to converge

** 3 channels
Let's see if it can learn 2 lags at the same time. That's one step closer
towards what we need to learn.

#+begin_src python
w = 256
c = 3
lossfun = F.mse_loss
lr = 0.001 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 3000
print_every = 100

# m = model.CNN(
#     w, c-1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
# ).cuda()
m = model.RNN(w, c - 1, c, 16, 2, dropout_rate=0.6, share_input_weights=True).cuda()
device = m.device
x, y, imp = generate_data(w, c, 100, device=device)
tx, ty, timp = generate_data(w, c, 1000, device=device)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 9797.724609375 VL: 10937.0771484375
Epoch 100, TL 4533.7890625 VL: 9037.7470703125
Epoch 200, TL 2950.878173828125 VL: 3322.52294921875
Epoch 300, TL 356.5895080566406 VL: 1074.657470703125
Epoch 400, TL 202.80323791503906 VL: 867.0380859375
Epoch 500, TL 84.18399047851562 VL: 386.94635009765625
Epoch 600, TL 32.605918884277344 VL: 74.24748229980469
Epoch 700, TL 64.31904602050781 VL: 41.493675231933594
Epoch 800, TL 17.088197708129883 VL: 57.716644287109375
Epoch 900, TL 28.063058853149414 VL: 31.811717987060547
Epoch 1000, TL 13.49834156036377 VL: 28.634328842163086
Epoch 1100, TL 15.28337574005127 VL: 26.30498504638672
Epoch 1200, TL 11.294228553771973 VL: 26.616729736328125
Epoch 1300, TL 10.797918319702148 VL: 16.320541381835938
Epoch 1400, TL 7.7080979347229 VL: 15.624723434448242
Epoch 1500, TL 9.873404502868652 VL: 11.996635437011719
Epoch 1600, TL 5.244534969329834 VL: 13.392248153686523
Epoch 1700, TL 4.024059772491455 VL: 9.139055252075195
Epoch 1800, TL 4.523504257202148 VL: 13.074235916137695
Epoch 1900, TL 4.394941806793213 VL: 9.586922645568848
Epoch 2000, TL 4.473787307739258 VL: 9.338714599609375
Epoch 2100, TL 3.0711374282836914 VL: 10.5660400390625
Epoch 2200, TL 3.194096088409424 VL: 7.816829681396484
Epoch 2300, TL 2.5959553718566895 VL: 6.540218353271484
Epoch 2400, TL 2.9732067584991455 VL: 7.469451904296875
Epoch 2500, TL 2.7218360900878906 VL: 7.070628643035889
Epoch 2600, TL 2.3775062561035156 VL: 7.469150066375732
Epoch 2700, TL 2.0485284328460693 VL: 8.085326194763184
Epoch 2800, TL 2.4743940830230713 VL: 9.536794662475586
Epoch 2900, TL 2.2067036628723145 VL: 7.413653373718262
Epoch 2999, Loss 2.2365968227386475
tensor([[-1.8919e+00, -6.3282e-02],
        [ 1.1337e+00, -9.9705e-01],
        [-8.5596e-02, -1.4792e-01],
        [-2.5889e+02,  2.2042e-01],
        [ 2.5255e+02, -2.5264e+02],
        [ 6.9334e-01,  2.5559e+02],
        [-8.9901e+00,  1.6475e+02],
        [ 3.1594e+01, -5.2260e+01],
        [ 5.1377e+01,  3.8554e+01],
        [ 2.3470e+02, -2.6096e+01]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.,    0.],
        [   0.,    0.],
        [   0.,    0.],
        [-255.,    0.],
        [ 255., -255.],
        [   0.,  255.],
        [  -7.,  164.],
        [  32.,  -53.],
        [  51.,   38.],
        [ 236.,  -28.]], device='cuda:0')
#+end_example

Plot results on the test set:
#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 3.067169, Median loss: 1.9193
Best: tensor([-132.,   95.,    8.,   56.,    8., -208.,  -38.,   -2.,   16.,   43.,
          29., -164.,  -18.,  193.,   14.,   21.,  -48.,    6., -104.,  -59.]) 
Worst: tensor([ 37., 190., 255.,   5.,   0.,   4.,   5.,  -6., -60., 121., -26.,  31.,
        -81.,  73.,  71.,  59.,  43., 119.,   7.,  76.])
tensor([[  9,  46,  31],
        [ 18, 208, 254],
        [  0, 255,   0],
        [ 33,  38, 255],
        [246, 246, 191],
        [215, 219, 151],
        [220, 225, 170],
        [252, 246, 237],
        [163, 103, 254],
        [133, 254, 178],
        [146, 120, 255],
        [222, 253, 254],
        [237, 156, 255],
        [182, 255, 114],
        [184, 255, 242],
        [138, 197, 255],
        [204, 247, 253],
        [ 71, 190, 255],
        [248, 255,  94],
        [165, 241, 255]], device='cuda:0')
#+end_example
[[./.ob-jupyter/f68729cc5000a20cf33bed2d4bf8fb5f0a6d8c10.png]]
[[./.ob-jupyter/9b6d49aadc3afb461346e114ee8a746b8efd775b.png]]
:END:


Error analysis:
The MSE is still very high on this, possibly because we overfit, having lowered
the dropout.
let's see at which values of lags the model struggles most:
#+begin_src python
e = (tp - ty.cpu()).square().sum(1)
sortidx = e.argsort()
print("Best:\n",ty.cpu()[sortidx][:10].T, "\nWorst:\n", ty.cpu()[sortidx][-10:].T)
#+end_src

#+RESULTS:
: Best:
:  tensor([[ -55., -136.,  -55.,  119., -185.,   88., -182.,  206.,  104., -106.],
:         [ 105.,  115.,  -46., -141.,   88., -140.,  122., -101., -169.,   58.]]) 
: Worst:
:  tensor([[ 254.,  244.,  246.,    5.,  -89.,  240.,   29.,  -76., -187.,  -45.],
:         [ -76.,  -31.,  -53.,    0.,  166.,  -16.,  158.,  201.,  251.,  233.]])

There are somewhat more extreme values at the large errors, but in general I
think it's just overfit.

** Non-binary impulses
This is a contrived case where we learn impulses, but in reality we'll never
have such data. Let's transform these into gaussian impulses for a further
step, and check whether it still works as well.

#+begin_src python
def transform_impulse1(x, n=11, ramp_up: int = 0):
    c = x.shape[1]
    ls = torch.linspace(-3 * np.e, 0, n, device=x.device)
    exp = torch.exp(ls)
    if ramp_up > 0:
        exp[-ramp_up:] = torch.exp(
            torch.linspace(ls[-ramp_up], 2 * -np.e, ramp_up, device=x.device)
        )
    return F.conv1d(F.pad(x, (n - 1, 0)), exp.repeat(c, 1, 1), groups=c)
#+end_src

#+begin_src python
w = 256
c = 3
lossfun = F.mse_loss
lr = 0.001 * (10 if lossfun == F.mse_loss else 1)
num_epochs = 3000
print_every = 100

m = model.CNN(
    w, c-1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
).to(device)
m = model.CNNRNN(
    w,
    c-1,
    c,
    layer_sizes=[8],
    kernel_size=2,
    n_hidden=128,
    n_rnn_layers=1,
    dropout_rate=0.6,
).to(device)
m = model.RNN(w, c - 1, c, 64, 2, dropout_rate=0.5).to(device)
x, y, imp = generate_data(w, c, 100, device=device)
x = transform_impulse1(x, 200, 20)
tx, ty, timp = generate_data(w, c, 1000, device=device)
tx = transform_impulse1(tx, 200, 20)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
/home/tim/projects/onset-fingerprinting/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
Epoch 0, TL 11471.6171875 VL: 10763.947265625
Epoch 100, TL 6300.701171875 VL: 4763.0048828125
Epoch 200, TL 1386.6453857421875 VL: 1241.863037109375
Epoch 300, TL 342.417724609375 VL: 723.0066528320312
Epoch 400, TL 250.0272216796875 VL: 510.8902893066406
Epoch 500, TL 55.00023651123047 VL: 379.0447998046875
Epoch 600, TL 57.27154541015625 VL: 424.559326171875
Epoch 700, TL 43.54613494873047 VL: 150.87136840820312
Epoch 800, TL 31.350616455078125 VL: 146.08096313476562
Epoch 900, TL 37.63465881347656 VL: 210.27972412109375
Epoch 1000, TL 59.4703254699707 VL: 61.12222671508789
Epoch 1100, TL 29.809720993041992 VL: 64.12410736083984
Epoch 1200, TL 15.877347946166992 VL: 97.62782287597656
Epoch 1300, TL 14.474164962768555 VL: 87.64909362792969
Epoch 1400, TL 13.176837921142578 VL: 86.94642639160156
Epoch 1500, TL 7.699976444244385 VL: 81.4412841796875
Epoch 1600, TL 5.240980625152588 VL: 65.48567199707031
Epoch 1700, TL 9.369585037231445 VL: 61.48301315307617
Epoch 1800, TL 11.597272872924805 VL: 55.46167755126953
Epoch 1900, TL 11.893485069274902 VL: 46.76387405395508
Epoch 2000, TL 5.205259323120117 VL: 56.14391326904297
Epoch 2100, TL 6.685842037200928 VL: 60.57660675048828
Epoch 2200, TL 2.979496955871582 VL: 47.39455795288086
Epoch 2300, TL 2.6737499237060547 VL: 52.31924819946289
Epoch 2400, TL 2.32865309715271 VL: 56.26995849609375
Epoch 2500, TL 2.1595070362091064 VL: 60.19451904296875
Epoch 2600, TL 2.235826015472412 VL: 53.08357238769531
Stopping at epoch 2637!
Epoch 2637, Loss 2.036637306213379
tensor([[  62.6798,  141.3915],
        [  68.4154, -164.8867],
        [  53.9853,   59.8275],
        [  31.9432, -179.9884],
        [ 173.9814,   21.4797],
        [  46.0552,  -49.5891],
        [ 123.8873, -126.6256],
        [ -19.2127,   14.2151],
        [-150.5007,  182.4794],
        [ -93.4469, -122.0795]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[  58.,  143.],
        [  65., -163.],
        [  55.,   59.],
        [  32., -180.],
        [ 175.,   20.],
        [  49.,  -52.],
        [ 123., -126.],
        [ -15.,   12.],
        [-149.,  181.],
        [ -93., -122.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 3.942275, Median loss: 1.8895
Best: tensor([ 69.,  35.,  56., -40.,  64.,  52.,  47., 129., -76., 151.,  79.,  -5.,
         55.,  40., 132., -50., -20.,  53., -41.,  31.]) 
Worst: tensor([ -62., -122.,   -1., -226.,   -1., -201., -209.,  -70., -223.,  -86.,
        -229.,  -74.,    3.,  -82.,    3.,  -90.,   -2.,  -89.,    0.,    2.])
tensor([[ 56, 118,  88],
        [ 18, 140, 115],
        [ 69,  70, 173],
        [ 18, 244, 174],
        [104, 105, 189],
        [  8, 209, 191],
        [ 11, 220, 173],
        [ 67, 137, 118],
        [ 25, 248, 224],
        [ 10,  96,  79],
        [ 22, 251, 196],
        [ 33, 107,  73],
        [121, 118, 158],
        [ 21, 103,  81],
        [ 59,  56, 151],
        [  8,  98,  69],
        [ 71,  73,  68],
        [  3,  92,  69],
        [ 42,  42, 199],
        [ 29,  27, 110]], device='cuda:0')
#+end_example
[[./.ob-jupyter/a8aa1a861fad67c9f96828b56d97206fc25181dc.png]]
[[./.ob-jupyter/7d0c1568492492549fec03849e787f041c31e2d2.png]]
:END:

Nice, it performs pretty much the same!

*** Additional changes
This is still very idealized - here are more things we can do to make it look
more real:
- peaks at different amplitudes
- modulate with sine wave
- add noise


Note: frequencies should be the same in each of the channels, phase could be
slightly shifted, but very little. The sine needs to start at the impulse in
each case, so currently this is wrong.
#+begin_src python
def transform_impulse2(
    x, imp, random_phase: bool = False, noise_std=0, sr=96000
):
    n, c, w = x.shape
    ls = torch.linspace(0, x.shape[-1] / sr, x.shape[-1], device=x.device)
    phase = (
        torch.rand(x.shape[0], x.shape[1], 1, device=x.device) * 0.1 * np.pi
        if random_phase
        else 0
    )
    f = torch.randint(300, 1000, (x.shape[0], 1, 1), device=x.device).expand(
        n, c, 1
    )
    sin = torch.sin(2 * np.pi * ls[None, None, :] * f + phase)
    for i in range(len(x)):
        for j in range(c):
            k = w - imp[i, j]
            x[i, j, imp[i, j] :] *= sin[i, j, :k]
    x += torch.randn(x.shape, device=x.device) * noise_std
    return x
#+end_src

#+begin_src python
x = transform_impulse2(x, imp, True, 0.001)
tx = transform_impulse2(tx, timp, True, 0.001)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x,
    y,
    m.to(device),
    lossfun,
    optimizer,
    scheduler,
    3000,
    tx[:100],
    ty[:100],
    500,
)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 38.41012191772461 VL: 11656.9599609375
Epoch 100, TL 16.59128189086914 VL: 153.88595581054688
Epoch 200, TL 22.921138763427734 VL: 109.77005004882812
Epoch 300, TL 60.49607467651367 VL: 96.41871643066406
Epoch 400, TL 11399.8642578125 VL: 10716.013671875
Epoch 500, TL 3034.529296875 VL: 3443.92236328125
Epoch 600, TL 689.79443359375 VL: 455.908203125
Epoch 700, TL 72.95342254638672 VL: 165.76028442382812
Stopping at epoch 732!
Epoch 732, Loss 80.4583511352539
tensor([[  61.4558,  144.0829],
        [  48.9084, -145.4959],
        [  49.2660,   55.4530],
        [  22.9640, -167.7405],
        [ 166.9901,   23.7873],
        [  45.7351,  -44.0062],
        [ 110.5431, -113.2652],
        [ -17.7397,    7.5596],
        [-141.3242,  174.2570],
        [-105.1589, -120.3260]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[  58.,  143.],
        [  65., -163.],
        [  55.,   59.],
        [  32., -180.],
        [ 175.,   20.],
        [  49.,  -52.],
        [ 123., -126.],
        [ -15.,   12.],
        [-149.,  181.],
        [ -93., -122.]], device='cuda:0')
#+end_example

#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 8.697659, Median loss: 7.2153
Best: tensor([  81., -133.,  -21., -149.,   37.,  -50.,   44.,  -51., -194.,   36.,
         -82., -117.,   -8., -165.,  142.,  133.,  160.,   47.,  -70.,  -55.]) 
Worst: tensor([153., -16.,  13., -25., -11., -15., -20., -24., -18., -32., -24.,  -6.,
        -14.,  11., -21.,  11., -18., 228., 196.,  -2.])
tensor([[186,  33,   2],
        [  9,  25,  26],
        [141, 128, 118],
        [ 29,  54, 162],
        [  8,  19,  37],
        [ 59,  74, 160],
        [ 13,  33, 162],
        [ 13,  37, 124],
        [ 38,  56, 175],
        [ 38,  70,  60],
        [ 19,  43, 106],
        [ 24,  30,  84],
        [ 45,  59, 125],
        [ 69,  58,  46],
        [ 30,  51, 129],
        [ 87,  76,  70],
        [  2,  20,  62],
        [254,  26,  17],
        [208,  12,   8],
        [ 71,  73,  68]], device='cuda:0')
#+end_example
[[./.ob-jupyter/8c75740c54df5a4ef929e0528f428af74278893a.png]]
[[./.ob-jupyter/471d27d84a130b38e16a2cb2baf00a9975c3c161.png]]
:END:

#+begin_src python
m = model.CNN(
    w, c - 1, c, layer_sizes=[8, 16, 32, 16, 8], kernel_size=3, dilation=1
).to(device)
m = model.CNNRNN(
    w,
    c-1,
    c,
    layer_sizes=[8],
    kernel_size=2,
    n_hidden=128,
    n_rnn_layers=1,
    dropout_rate=0.6,
).to(device)

m = model.RNN(w, c - 1, c, 64, 2, dropout_rate=0.5).to(device)
x, y, imp = generate_data(w, c, 100, device=device)
x = transform_impulse1(x, 200, 20)
x = transform_impulse2(x, imp, True, 0.001)
tx, ty, timp = generate_data(w, c, 1000, device=device)
tx = transform_impulse1(tx, 200, 20)
tx = transform_impulse2(tx, timp, True, 0.001)

optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)

errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
/home/tim/projects/onset-fingerprinting/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
Epoch 0, TL 10969.625 VL: 12308.033203125
Epoch 100, TL 10749.765625 VL: 12646.4658203125
Epoch 200, TL 4539.97216796875 VL: 5462.40478515625
Epoch 300, TL 624.5994873046875 VL: 1375.3243408203125
Epoch 400, TL 196.093505859375 VL: 1062.148681640625
Epoch 500, TL 169.95042419433594 VL: 957.1149291992188
Epoch 600, TL 107.84603881835938 VL: 1028.6390380859375
Epoch 700, TL 121.10030364990234 VL: 681.8544921875
Epoch 800, TL 66.1226806640625 VL: 788.4007568359375
Epoch 900, TL 53.90553665161133 VL: 717.099853515625
Epoch 1000, TL 19.31464958190918 VL: 922.7158203125
Epoch 1100, TL 63.47445297241211 VL: 751.4854736328125
Epoch 1200, TL 15.681598663330078 VL: 738.298095703125
Epoch 1300, TL 38.02914047241211 VL: 744.9343872070312
Epoch 1400, TL 11.976242065429688 VL: 736.5288696289062
Epoch 1500, TL 15.60149097442627 VL: 694.3289184570312
Epoch 1600, TL 11.260603904724121 VL: 674.05029296875
Epoch 1700, TL 14.834748268127441 VL: 657.7704467773438
Epoch 1800, TL 8.437795639038086 VL: 640.6726684570312
Stopping at epoch 1821!
Epoch 1821, Loss 13.305294036865234
tensor([[  77.6080, -134.4793],
        [ 163.3905,  -10.0579],
        [  23.3562,  -91.4870],
        [  14.8176,   32.2623],
        [ -55.5569, -159.4844],
        [-133.6727,  -48.5318],
        [ -54.7022, -147.1461],
        [  36.2426,  -21.0591],
        [-145.1990,  158.6829],
        [  -1.7074,  -85.3992]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[  81., -131.],
        [ 165.,  -16.],
        [  26.,  -93.],
        [  14.,   31.],
        [ -56., -155.],
        [-133.,  -43.],
        [ -55., -142.],
        [  45.,  -27.],
        [-152.,  164.],
        [  -2.,  -83.]], device='cuda:0')
#+end_example


#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 14.786790, Median loss: 9.8132
Best: tensor([ -71.,  156.,  -52.,  -76.,  -22.,   55.,   -2.,  165.,  136.,  100.,
          91.,  169.,  -53.,  -23.,   58., -120., -127.,  -88.,  -96.,  -20.]) 
Worst: tensor([-203., -194., -103.,  144., -217., -187.,   -6.,  -49.,   46.,  -91.,
         -88.,   12., -104.,  -93., -126., -100.,  -98., -103., -122., -106.])
tensor([[ 49, 252, 152],
        [  8, 202, 241],
        [138, 241,  17],
        [244, 100,   6],
        [  0, 217,  16],
        [ 66, 253,  25],
        [235, 241, 106],
        [192, 241,  14],
        [ 65,  19,  65],
        [158, 249,  64],
        [162, 250,   3],
        [ 42,  30,  36],
        [146, 250, 177],
        [161, 254, 159],
        [121, 247,   0],
        [141, 241,  18],
        [155, 253,  14],
        [141, 244, 107],
        [127, 249, 152],
        [137, 243,   7]], device='cuda:0')
#+end_example
[[./.ob-jupyter/610a0161dd8a5a4e1b125dc97f808e91eadb322f.png]]
[[./.ob-jupyter/944c8cfcda49bfc559531f200e50b2b8f4fe07f7.png]]
:END:


*** Making the data even more real

In its current iteration, the data models an impulse of the fundamental - but
as far as the modelling problem goes, it's different from what we'll see in
realtime: There, we'll always start the window from the first onset on. In the
current data, the first onset may start anywhere.

Let's adapt the data in such a way that our first onset is always close to the
beginning of the buffers.
#+begin_src python
def generate_data2(w: int, c: int, n: int = 10000, max_shift=10, device=None):
    signals = torch.zeros(n, c, w, device=device)
    impulses = torch.randint(0, w - max_shift, (n, c), device=device)
    mini = impulses.min(dim=1, keepdim=True).values
    impulses -= mini
    impulses += torch.maximum(
        torch.tensor(0, device=device),
        torch.minimum(
            w - impulses.max(dim=1, keepdim=True).values - 1,
            torch.randint(max_shift, (len(impulses), 1), device=device),
        ),
    )
    # Force some 0s
    impulses[0] = torch.tensor([0] * c)
    impulses[1] = torch.tensor([w // 2] * c)
    impulses[2] = torch.tensor([w - 1] * c)
    # Force the extremes
    z = torch.zeros((c, c), dtype=torch.long)
    for i in range(c):
        z[i, i] = w - 1
    impulses[3 : 3 + c] = z
    signals.scatter_(2, impulses[:, :, None], -1)
    signals *= torch.rand((*signals.shape[:2], 1), device=device) ** 2
    return signals, torch.diff(impulses).to(torch.float32), impulses


def generate_data2(w: int, c: int, n: int = 10000, max_shift=10, device=None):
    signals = torch.zeros(n, c, w, device=device)
    impulses = torch.stack(
        (
            torch.randint(170, 300, (n,)),
            torch.randint(170, 300, (n,)),
            torch.randint(0, max_shift, (n,)),
        ),
        1,
    ).to(device)
    mini = impulses.min(dim=1, keepdim=True).values
    impulses -= mini
    impulses += torch.maximum(
        torch.tensor(0, device=device),
        torch.minimum(
            w - impulses.max(dim=1, keepdim=True).values - 1,
            torch.randint(max_shift, (len(impulses), 1), device=device),
        ),
    )
    # Force some 0s
    impulses[0] = torch.tensor([0] * c)
    impulses[1] = torch.tensor([w // 2] * c)
    impulses[2] = torch.tensor([w - 1] * c)
    # Force the extremes
    z = torch.zeros((c, c), dtype=torch.long)
    for i in range(c):
        z[i, i] = w - 1
    impulses[3 : 3 + c] = z
    signals.scatter_(2, impulses[:, :, None], -1)
    signals *= torch.rand((*signals.shape[:2], 1), device=device) ** 2
    return signals, torch.diff(impulses).to(torch.float32), impulses


def standardize(x):
    # return (x - x.mean(-1, keepdim=True)) / x.std(-1, keepdim=True)
    return x / x.std(-1, keepdim=True)
#+end_src


#+begin_src python
w = 384
c = 3
lossfun = F.mse_loss
lr = 0.001 * (5 if lossfun == F.mse_loss else 1)
num_epochs = 2000
print_every = 100

m = model.CNN(
    w, c - 1, c, layer_sizes=[8, 8], kernel_size=8, dropout_rate=0.9
).to(device)
m = model.RNN(
    w,
    c - 1,
    c,
    16,
    1,
    dropout_rate=0.6,
    rnn_type="GRU",
    share_input_weights=True,
).to(device)
# m = model.CNNRNN(
#     w,
#     c - 1,
#     c,
#     layer_sizes=[9, 18, 27],
#     kernel_size=3,
#     n_hidden=64,
#     n_rnn_layers=2,
#     dropout_rate=0.8,
#     groups=1,
# ).to(device)
x, y, imp = generate_data2(w, c, 1000, 50, device=device)
tx, ty, timp = generate_data2(w, c, 1000, 50, device=device)
optimizer = optim.NAdam(m.parameters(), lr=lr, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer, num_epochs / 10
)
# errors, bm = train(
#     x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
# )
x = transform_impulse1(x, 300, 20)
tx = transform_impulse1(tx, 300, 20)
# errors, bm = train(
#     x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
# )
x = standardize(transform_impulse2(x, imp, True, 0.0001))
tx = standardize(transform_impulse2(tx, timp, True, 0.0001))
errors, bm = train(
    x, y, m, lossfun, optimizer, scheduler, 3000, tx[:100], ty[:100], 500
)
#+end_src

#+RESULTS:
#+begin_example
Epoch 0, TL 24670.58203125 VL: 26087.013671875
Epoch 100, TL 2461.189208984375 VL: 5351.8681640625
Epoch 200, TL 2203.37158203125 VL: 5030.26025390625
Epoch 300, TL 2162.49365234375 VL: 4887.7470703125
Epoch 400, TL 2077.96044921875 VL: 4716.88916015625
Epoch 500, TL 1571.4285888671875 VL: 4083.708740234375
Epoch 600, TL 1218.01513671875 VL: 3636.88427734375
Epoch 700, TL 1093.2430419921875 VL: 3658.283935546875
Epoch 800, TL 1058.1771240234375 VL: 3627.931884765625
Epoch 900, TL 746.5901489257812 VL: 3157.840576171875
Epoch 1000, TL 624.857177734375 VL: 3025.976806640625
Epoch 1100, TL 600.8016357421875 VL: 3095.292236328125
Epoch 1200, TL 505.534912109375 VL: 3549.07470703125
Epoch 1300, TL 401.6212158203125 VL: 3290.194580078125
Epoch 1400, TL 338.54364013671875 VL: 3120.701171875
Epoch 1500, TL 343.5242614746094 VL: 3208.28369140625
Epoch 1600, TL 293.17352294921875 VL: 3387.800537109375
Stopping at epoch 1614!
Epoch 1614, Loss 294.9203186035156
tensor([[-2.5625e+01, -9.6391e-02],
        [ 1.7103e+00, -9.9122e+01],
        [-7.7437e+01, -2.5574e+01],
        [-1.9695e+02,  3.1331e+01],
        [ 1.4379e+02, -2.8706e+02],
        [-1.1384e+02,  1.3179e+02],
        [-6.9554e+01, -1.6796e+02],
        [-1.6394e+01, -1.8120e+02],
        [ 4.2526e+01, -2.5560e+02],
        [ 2.2885e+00, -2.1050e+02]], device='cuda:0', grad_fn=<SliceBackward0>) 
 tensor([[   0.,    0.],
        [   0.,    0.],
        [   0.,    0.],
        [-383.,    0.],
        [ 383., -383.],
        [   0.,  383.],
        [ -70., -165.],
        [ -38., -158.],
        [  42., -251.],
        [  28., -215.]], device='cuda:0')
#+end_example


#+begin_src python :async no
error_analysis(bm, tx, ty, timp)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Mean loss: 14.548420, Median loss: 6.8894
Best: tensor([ -27.,  -89.,   80.,  -71., -131.,  -72.,  -18.,  -68.,   44.,    3.,
         -50.,  106.,   44.,  -15.,  104.,  105.,   45.,    3.,  135.,  -11.]) 
Worst: tensor([  20.,    6., -178.,    0.,   85.,  131.,   99., -148., -114.,    0.,
        -158.,    0., -123., -132.,  145.,   72., -100.,  151.,  179.,  255.])
tensor([[ 17,  37, 113],
        [  6,  12,  57],
        [209,  31,  92],
        [ 14,  14,  42],
        [ 30, 115,  75],
        [  6, 137,  58],
        [ 41, 140,  12],
        [177,  29, 157],
        [176,  62,  28],
        [ 22,  22, 190],
        [182,  24,  52],
        [  0,   0, 255],
        [141,  18, 132],
        [150,  18, 184],
        [ 49, 194,  68],
        [138, 210,  21],
        [105,   5,  41],
        [ 36, 187, 111],
        [ 30, 209, 197],
        [  0, 255,   0]], device='cuda:0')
#+end_example
[[./.ob-jupyter/3cf144b25f22818ddbecc7966b97e9ea556a84b7.png]]
[[./.ob-jupyter/47c4afee29b4a93be41aa98f7035d2acc134abe8.png]]
:END:


** Real Data
Let's load real data and see if this can translate:
#+begin_src python
audio = []
x, sr = sf.read(data_dir / "calib_snare0.wav", dtype=np.float32)
audio.append(x)
x, sr = sf.read(data_dir / "calib_snare1.wav", dtype=np.float32)
audio.append(x)
x, sr = sf.read(data_dir / "calib_snare2.wav", dtype=np.float32)
audio.append(x)
audio = np.stack(audio).T[12*sr:-10*sr]
audio = np.ascontiguousarray(audio)
#+end_src

#+begin_src python
cf, of, rel = detection.detect_onsets_amplitude(
    audio,
    128,
    hipass_freq=1000,
    fast_ar=(0.4, 100),
    slow_ar=(8000, 8000),
    on_threshold=[0.3, 0.3, 0.151],
    off_threshold=0.3,
    cooldown=9000,
    sr=sr,
    backtrack=False,
    backtrack_buffer_size=256,
    backtrack_smooth_size=1,
)
oc = detection.find_onset_groups(of, cf, 700)
occ = detection.fix_onsets(
    audio, oc, onset_tolerance=50, take_abs=True
)
plots.plot_onsets(audio, oc)
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: >
[[./.ob-jupyter/e13d2b29265f9f8865d3827c8adee8ac5a5b6055.png]]
:END:

#+begin_src python
fe = data.FastFrameExtractor(audio, occ.min(1), 256, 10, 20)
X = fe()
#+end_src

* Pre-training
Start with impulse data, and epoch-by-epoch morph it into something looking
more like a real signal.



* Idea
Random tone generator based on FM synthesis or just adding different modulated
sines with a huge space. Then feedback the system by saying like/dislike on
single tones to find a space of settings which are pleasing to the ear.
